{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read all videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np,pandas as pd\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] C3D model loaded ...\n"
     ]
    }
   ],
   "source": [
    "import all_in_one_utils as ao_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_cat = pd.read_csv('video-category.csv')\n",
    "mapping = OrderedDict(zip(vid_cat.iloc[:,0],vid_cat.iloc[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate c3d encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "def get_3d_encoding(all_paths):\n",
    "    all_ = pd.DataFrame()\n",
    "    total_embeds = 0\n",
    "    for idx,vid in enumerate(all_paths):   \n",
    "        name = str(vid.absolute())\n",
    "        vid_id = vid.stem\n",
    "        num = ao_util.get_3d_feature(name,batch_size)\n",
    "        feat_cols = [ 'pixel'+str(i) for i in range(num.shape[1]) ] \n",
    "        feat_data = pd.DataFrame(num,columns=feat_cols)\n",
    "        feat_data['video_id'] = pd.Series(np.tile(int(vid_id),len(num)))\n",
    "        feat_data['label'] = pd.Series(np.tile(mapping[int(vid_id)],len(num)))\n",
    "        all_ = all_.append(feat_data,ignore_index=True)\n",
    "        total_embeds+=len(num)\n",
    "    assert len(all_) == total_embeds , \"error in reading embeddings\"\n",
    "    return all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_afresh = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional : save the above info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3_encoded_data_path = (Path.home() / '.cbvr' )\n",
    "c3_encoded_data_path.mkdir(parents=True, exist_ok=True)\n",
    "c3_encoded_data_file = str(c3_encoded_data_path / 'c3_encoding.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_afresh:\n",
    "    video_dir = 'Videos/'\n",
    "    all_paths = sorted(Path(video_dir).glob('*.mp4'))\n",
    "    df = get_3d_encoding(all_paths)\n",
    "    df.to_pickle(c3_encoded_data_file)\n",
    "else:\n",
    "    df = pd.read_pickle(c3_encoded_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel4091</th>\n",
       "      <th>pixel4092</th>\n",
       "      <th>pixel4093</th>\n",
       "      <th>pixel4094</th>\n",
       "      <th>pixel4095</th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>pca-one</th>\n",
       "      <th>pca-two</th>\n",
       "      <th>pca-three</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.218057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.574213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.132048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12069887</td>\n",
       "      <td>FUNNY</td>\n",
       "      <td>33.493016</td>\n",
       "      <td>7.100074</td>\n",
       "      <td>-5.642242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.084609</td>\n",
       "      <td>2.115129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.295232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.698915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12069887</td>\n",
       "      <td>FUNNY</td>\n",
       "      <td>26.614904</td>\n",
       "      <td>2.632102</td>\n",
       "      <td>-4.060029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.240896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12069887</td>\n",
       "      <td>FUNNY</td>\n",
       "      <td>20.847944</td>\n",
       "      <td>-1.839365</td>\n",
       "      <td>-6.114331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.132195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.906395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.319211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12069887</td>\n",
       "      <td>FUNNY</td>\n",
       "      <td>33.281023</td>\n",
       "      <td>0.585274</td>\n",
       "      <td>0.518931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.709773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12069887</td>\n",
       "      <td>FUNNY</td>\n",
       "      <td>37.347069</td>\n",
       "      <td>1.153552</td>\n",
       "      <td>-1.343067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pixel0  pixel1    pixel2    pixel3  pixel4  pixel5    pixel6    pixel7  \\\n",
       "0  0.000000     0.0  0.000000  1.218057     0.0     0.0  6.574213  0.000000   \n",
       "1  0.000000     0.0  1.084609  2.115129     0.0     0.0  2.295232  0.000000   \n",
       "2  0.000000     0.0  0.000000  0.000000     0.0     0.0  0.917292  0.000000   \n",
       "3  0.132195     0.0  3.906395  0.000000     0.0     0.0  0.000000  0.586866   \n",
       "4  0.000000     0.0  3.709773  0.000000     0.0     0.0  0.000000  0.138456   \n",
       "\n",
       "   pixel8  pixel9    ...      pixel4091  pixel4092  pixel4093  pixel4094  \\\n",
       "0     0.0     0.0    ...       1.132048        0.0        0.0        0.0   \n",
       "1     0.0     0.0    ...       6.698915        0.0        0.0        0.0   \n",
       "2     0.0     0.0    ...       5.240896        0.0        0.0        0.0   \n",
       "3     0.0     0.0    ...       2.319211        0.0        0.0        0.0   \n",
       "4     0.0     0.0    ...       0.000000        0.0        0.0        0.0   \n",
       "\n",
       "   pixel4095  video_id  label    pca-one   pca-two  pca-three  \n",
       "0        0.0  12069887  FUNNY  33.493016  7.100074  -5.642242  \n",
       "1        0.0  12069887  FUNNY  26.614904  2.632102  -4.060029  \n",
       "2        0.0  12069887  FUNNY  20.847944 -1.839365  -6.114331  \n",
       "3        0.0  12069887  FUNNY  33.281023  0.585274   0.518931  \n",
       "4        0.0  12069887  FUNNY  37.347069  1.153552  -1.343067  \n",
       "\n",
       "[5 rows x 4101 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mark all feature cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = df.columns[:4096]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the encodings once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndperm = np.random.permutation(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variation per principal component: [0.08674966 0.04609506 0.02766531]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(df[feat_cols].values)\n",
    "\n",
    "df['pca-one'] = pca_result[:,0]\n",
    "df['pca-two'] = pca_result[:,1] \n",
    "df['pca-three'] = pca_result[:,2]\n",
    "\n",
    "print ('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deep-vision/.virtualenvs/video-works/lib/python3.5/site-packages/ggplot/utils.py:81: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access Timestamp as pandas.Timestamp\n",
      "  pd.tslib.Timestamp,\n"
     ]
    }
   ],
   "source": [
    "from ggplot import *\n",
    "\n",
    "chart = ggplot( df.loc[rndperm[:3000],:], aes(x='pca-one', y='pca-two' , color='label') ) \\\n",
    "        + geom_point(size=75,alpha=0.8) \\\n",
    "        + ggtitle(\"First and Second Principal Components \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (-9223363301759474684)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce the dimension to have 90% variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variation per principal component: 0.923388873507738\n"
     ]
    }
   ],
   "source": [
    "pca_90 = PCA(n_components=784)\n",
    "pca_result_90 = pca_90.fit_transform(df[feat_cols].values)\n",
    "\n",
    "print ('Explained variation per principal component: {}'.format(np.sum(pca_90.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19315, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_result_90.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attach the id , class and class id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pca_result_90\n",
    "ids,text_labels = df.label.factorize()\n",
    "Y = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(Y))\n",
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier to check accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# test_size: what proportion of original data is used for test set\n",
    "train_X, test_X, train_ids, test_ids = train_test_split(\n",
    "    X, Y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1932,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import all_classifiers as cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls.train_and_report(train_X, train_ids,test_X,test_ids,algo_name='logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls.train_and_report(train_X, train_ids,test_X,test_ids,algo_name='mlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the data encodings and train a siamese network with triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CBVR.train_triplet_v2 as tpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (17383, 28, 28, 1)\n",
      "17383 train samples\n",
      "1932 test samples\n",
      "y_train shape: (17383,)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_ids, test_X, test_ids = tpl.reshape_and_process(train_X, train_ids, test_X, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17383, 28, 28, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  0 global step 1   Batch #:  0 loss:  0.9997587\n",
      "Epoch #:  0 global step 11   Batch #:  10 loss:  0.99986005\n",
      "Epoch #:  0 global step 21   Batch #:  20 loss:  0.99997383\n",
      "Epoch #:  0 global step 31   Batch #:  30 loss:  0.99996173\n",
      "Epoch #:  0 global step 41   Batch #:  40 loss:  0.9999475\n",
      "Epoch #:  0 global step 51   Batch #:  50 loss:  0.99990916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/500 [00:02<20:40,  2.49s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  0 global step 61   Batch #:  60 loss:  0.9998319\n",
      "Epoch #:  1 global step 68   Batch #:  0 loss:  0.99878556\n",
      "Epoch #:  1 global step 78   Batch #:  10 loss:  0.9961428\n",
      "Epoch #:  1 global step 88   Batch #:  20 loss:  0.9970382\n",
      "Epoch #:  1 global step 98   Batch #:  30 loss:  0.9284939\n",
      "Epoch #:  1 global step 108   Batch #:  40 loss:  0.9200776\n",
      "Epoch #:  1 global step 118   Batch #:  50 loss:  0.6739046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 2/500 [00:04<18:15,  2.20s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  1 global step 128   Batch #:  60 loss:  0.7990896\n",
      "Epoch #:  2 global step 135   Batch #:  0 loss:  0.52774704\n",
      "Epoch #:  2 global step 145   Batch #:  10 loss:  0.66335446\n",
      "Epoch #:  2 global step 155   Batch #:  20 loss:  0.6490323\n",
      "Epoch #:  2 global step 165   Batch #:  30 loss:  0.6119638\n",
      "Epoch #:  2 global step 175   Batch #:  40 loss:  0.8264837\n",
      "Epoch #:  2 global step 185   Batch #:  50 loss:  0.5738453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  1%|          | 3/500 [00:06<17:32,  2.12s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  2 global step 195   Batch #:  60 loss:  0.95482963\n",
      "Epoch #:  3 global step 202   Batch #:  0 loss:  0.5217387\n",
      "Epoch #:  3 global step 212   Batch #:  10 loss:  0.5911489\n",
      "Epoch #:  3 global step 222   Batch #:  20 loss:  0.61617315\n",
      "Epoch #:  3 global step 232   Batch #:  30 loss:  0.46588472\n",
      "Epoch #:  3 global step 242   Batch #:  40 loss:  0.50065404\n",
      "Epoch #:  3 global step 252   Batch #:  50 loss:  0.48581505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  1%|          | 4/500 [00:08<17:19,  2.10s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  3 global step 262   Batch #:  60 loss:  0.54952246\n",
      "Epoch #:  4 global step 269   Batch #:  0 loss:  0.5216256\n",
      "Epoch #:  4 global step 279   Batch #:  10 loss:  0.57121885\n",
      "Epoch #:  4 global step 289   Batch #:  20 loss:  0.6078109\n",
      "Epoch #:  4 global step 299   Batch #:  30 loss:  0.47512454\n",
      "Epoch #:  4 global step 309   Batch #:  40 loss:  0.49709153\n",
      "Epoch #:  4 global step 319   Batch #:  50 loss:  0.4873914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  1%|          | 5/500 [00:10<17:12,  2.09s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  4 global step 329   Batch #:  60 loss:  0.52039564\n",
      "Epoch #:  5 global step 336   Batch #:  0 loss:  0.5197305\n",
      "Epoch #:  5 global step 346   Batch #:  10 loss:  0.5547112\n",
      "Epoch #:  5 global step 356   Batch #:  20 loss:  0.59366626\n",
      "Epoch #:  5 global step 366   Batch #:  30 loss:  0.47506952\n",
      "Epoch #:  5 global step 376   Batch #:  40 loss:  0.54187316\n",
      "Epoch #:  5 global step 386   Batch #:  50 loss:  0.47572538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  1%|          | 6/500 [00:12<17:06,  2.08s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  5 global step 396   Batch #:  60 loss:  0.5197434\n",
      "Epoch #:  6 global step 403   Batch #:  0 loss:  0.5193415\n",
      "Epoch #:  6 global step 413   Batch #:  10 loss:  0.5471263\n",
      "Epoch #:  6 global step 423   Batch #:  20 loss:  0.6001856\n",
      "Epoch #:  6 global step 433   Batch #:  30 loss:  0.45270818\n",
      "Epoch #:  6 global step 443   Batch #:  40 loss:  0.48566908\n",
      "Epoch #:  6 global step 453   Batch #:  50 loss:  0.4715685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  1%|▏         | 7/500 [00:14<17:01,  2.07s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  6 global step 463   Batch #:  60 loss:  0.51970947\n",
      "Epoch #:  7 global step 470   Batch #:  0 loss:  0.51191485\n",
      "Epoch #:  7 global step 480   Batch #:  10 loss:  0.52837044\n",
      "Epoch #:  7 global step 490   Batch #:  20 loss:  0.58019805\n",
      "Epoch #:  7 global step 500   Batch #:  30 loss:  0.43716004\n",
      "Epoch #:  7 global step 510   Batch #:  40 loss:  0.4849182\n",
      "Epoch #:  7 global step 520   Batch #:  50 loss:  0.47109154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 8/500 [00:16<16:58,  2.07s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  7 global step 530   Batch #:  60 loss:  0.5190421\n",
      "Epoch #:  8 global step 537   Batch #:  0 loss:  0.5110646\n",
      "Epoch #:  8 global step 547   Batch #:  10 loss:  0.5358747\n",
      "Epoch #:  8 global step 557   Batch #:  20 loss:  0.5900016\n",
      "Epoch #:  8 global step 567   Batch #:  30 loss:  0.45906383\n",
      "Epoch #:  8 global step 577   Batch #:  40 loss:  0.4838548\n",
      "Epoch #:  8 global step 587   Batch #:  50 loss:  0.47649175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 9/500 [00:18<16:54,  2.07s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  8 global step 597   Batch #:  60 loss:  0.5233982\n",
      "Epoch #:  9 global step 604   Batch #:  0 loss:  0.5096474\n",
      "Epoch #:  9 global step 614   Batch #:  10 loss:  0.5460147\n",
      "Epoch #:  9 global step 624   Batch #:  20 loss:  0.5899862\n",
      "Epoch #:  9 global step 634   Batch #:  30 loss:  0.4646322\n",
      "Epoch #:  9 global step 644   Batch #:  40 loss:  0.4973222\n",
      "Epoch #:  9 global step 654   Batch #:  50 loss:  0.47004604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 10/500 [00:20<16:50,  2.06s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  9 global step 664   Batch #:  60 loss:  0.52027357\n",
      "Epoch #:  10 global step 671   Batch #:  0 loss:  0.5294874\n",
      "Epoch #:  10 global step 681   Batch #:  10 loss:  0.5433142\n",
      "Epoch #:  10 global step 691   Batch #:  20 loss:  0.6038304\n",
      "Epoch #:  10 global step 701   Batch #:  30 loss:  0.44840607\n",
      "Epoch #:  10 global step 711   Batch #:  40 loss:  0.4913712\n",
      "Epoch #:  10 global step 721   Batch #:  50 loss:  0.47187543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 11/500 [00:22<16:47,  2.06s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  10 global step 731   Batch #:  60 loss:  0.51813847\n",
      "Epoch #:  11 global step 738   Batch #:  0 loss:  0.50513947\n",
      "Epoch #:  11 global step 748   Batch #:  10 loss:  0.5251727\n",
      "Epoch #:  11 global step 758   Batch #:  20 loss:  0.57379955\n",
      "Epoch #:  11 global step 768   Batch #:  30 loss:  0.43503064\n",
      "Epoch #:  11 global step 778   Batch #:  40 loss:  0.47865668\n",
      "Epoch #:  11 global step 788   Batch #:  50 loss:  0.49914962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 12/500 [00:24<16:44,  2.06s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  11 global step 798   Batch #:  60 loss:  0.5164109\n",
      "Epoch #:  12 global step 805   Batch #:  0 loss:  0.5076544\n",
      "Epoch #:  12 global step 815   Batch #:  10 loss:  0.52983826\n",
      "Epoch #:  12 global step 825   Batch #:  20 loss:  0.56961775\n",
      "Epoch #:  12 global step 835   Batch #:  30 loss:  0.4867155\n",
      "Epoch #:  12 global step 845   Batch #:  40 loss:  0.49731138\n",
      "Epoch #:  12 global step 855   Batch #:  50 loss:  0.47070128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 13/500 [00:26<16:42,  2.06s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  12 global step 865   Batch #:  60 loss:  0.5159131\n",
      "Epoch #:  13 global step 872   Batch #:  0 loss:  0.5068168\n",
      "Epoch #:  13 global step 882   Batch #:  10 loss:  0.5253678\n",
      "Epoch #:  13 global step 892   Batch #:  20 loss:  0.5757267\n",
      "Epoch #:  13 global step 902   Batch #:  30 loss:  0.42856267\n",
      "Epoch #:  13 global step 912   Batch #:  40 loss:  0.46968418\n",
      "Epoch #:  13 global step 922   Batch #:  50 loss:  0.46187377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 14/500 [00:28<16:40,  2.06s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  13 global step 932   Batch #:  60 loss:  0.51196116\n",
      "Epoch #:  14 global step 939   Batch #:  0 loss:  0.49376702\n",
      "Epoch #:  14 global step 949   Batch #:  10 loss:  0.51052016\n",
      "Epoch #:  14 global step 959   Batch #:  20 loss:  0.5699501\n",
      "Epoch #:  14 global step 969   Batch #:  30 loss:  0.42247382\n",
      "Epoch #:  14 global step 979   Batch #:  40 loss:  0.46403363\n",
      "Epoch #:  14 global step 989   Batch #:  50 loss:  0.5359899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 15/500 [00:30<16:37,  2.06s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  14 global step 999   Batch #:  60 loss:  0.51594955\n",
      "Epoch #:  15 global step 1006   Batch #:  0 loss:  0.5012647\n",
      "Epoch #:  15 global step 1016   Batch #:  10 loss:  0.523792\n",
      "Epoch #:  15 global step 1026   Batch #:  20 loss:  0.6151781\n",
      "Epoch #:  15 global step 1036   Batch #:  30 loss:  0.4517575\n",
      "Epoch #:  15 global step 1046   Batch #:  40 loss:  0.46715754\n",
      "Epoch #:  15 global step 1056   Batch #:  50 loss:  0.47636375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 16/500 [00:32<16:34,  2.06s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  15 global step 1066   Batch #:  60 loss:  0.5095817\n",
      "Epoch #:  16 global step 1073   Batch #:  0 loss:  0.491535\n",
      "Epoch #:  16 global step 1083   Batch #:  10 loss:  0.51430094\n",
      "Epoch #:  16 global step 1093   Batch #:  20 loss:  0.5707067\n",
      "Epoch #:  16 global step 1103   Batch #:  30 loss:  0.4469942\n",
      "Epoch #:  16 global step 1113   Batch #:  40 loss:  0.4567101\n",
      "Epoch #:  16 global step 1123   Batch #:  50 loss:  0.43978474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 17/500 [00:34<16:32,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  16 global step 1133   Batch #:  60 loss:  0.51642483\n",
      "Epoch #:  17 global step 1140   Batch #:  0 loss:  0.48137474\n",
      "Epoch #:  17 global step 1150   Batch #:  10 loss:  0.5136504\n",
      "Epoch #:  17 global step 1160   Batch #:  20 loss:  0.58732814\n",
      "Epoch #:  17 global step 1170   Batch #:  30 loss:  0.43207258\n",
      "Epoch #:  17 global step 1180   Batch #:  40 loss:  0.44600067\n",
      "Epoch #:  17 global step 1190   Batch #:  50 loss:  0.42833295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  4%|▎         | 18/500 [00:36<16:29,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  17 global step 1200   Batch #:  60 loss:  0.52505195\n",
      "Epoch #:  18 global step 1207   Batch #:  0 loss:  0.49005854\n",
      "Epoch #:  18 global step 1217   Batch #:  10 loss:  0.506535\n",
      "Epoch #:  18 global step 1227   Batch #:  20 loss:  0.54178053\n",
      "Epoch #:  18 global step 1237   Batch #:  30 loss:  0.34711993\n",
      "Epoch #:  18 global step 1247   Batch #:  40 loss:  0.40677387\n",
      "Epoch #:  18 global step 1257   Batch #:  50 loss:  0.38250282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 19/500 [00:39<16:27,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  18 global step 1267   Batch #:  60 loss:  0.47029877\n",
      "Epoch #:  19 global step 1274   Batch #:  0 loss:  0.4167009\n",
      "Epoch #:  19 global step 1284   Batch #:  10 loss:  0.45404842\n",
      "Epoch #:  19 global step 1294   Batch #:  20 loss:  0.5209878\n",
      "Epoch #:  19 global step 1304   Batch #:  30 loss:  0.35541192\n",
      "Epoch #:  19 global step 1314   Batch #:  40 loss:  0.38029888\n",
      "Epoch #:  19 global step 1324   Batch #:  50 loss:  0.36328077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 20/500 [00:41<16:25,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  19 global step 1334   Batch #:  60 loss:  0.4335905\n",
      "Epoch #:  20 global step 1341   Batch #:  0 loss:  0.40610453\n",
      "Epoch #:  20 global step 1351   Batch #:  10 loss:  0.5030876\n",
      "Epoch #:  20 global step 1361   Batch #:  20 loss:  0.5309735\n",
      "Epoch #:  20 global step 1371   Batch #:  30 loss:  0.41514274\n",
      "Epoch #:  20 global step 1381   Batch #:  40 loss:  0.36582905\n",
      "Epoch #:  20 global step 1391   Batch #:  50 loss:  0.3547749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 21/500 [00:43<16:22,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  20 global step 1401   Batch #:  60 loss:  0.45451504\n",
      "Epoch #:  21 global step 1408   Batch #:  0 loss:  0.47898266\n",
      "Epoch #:  21 global step 1418   Batch #:  10 loss:  0.4991209\n",
      "Epoch #:  21 global step 1428   Batch #:  20 loss:  0.4817934\n",
      "Epoch #:  21 global step 1438   Batch #:  30 loss:  0.4829074\n",
      "Epoch #:  21 global step 1448   Batch #:  40 loss:  0.41407594\n",
      "Epoch #:  21 global step 1458   Batch #:  50 loss:  0.35572538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 22/500 [00:45<16:20,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  21 global step 1468   Batch #:  60 loss:  0.49366376\n",
      "Epoch #:  22 global step 1475   Batch #:  0 loss:  0.3977769\n",
      "Epoch #:  22 global step 1485   Batch #:  10 loss:  0.4625154\n",
      "Epoch #:  22 global step 1495   Batch #:  20 loss:  0.50196624\n",
      "Epoch #:  22 global step 1505   Batch #:  30 loss:  0.38788438\n",
      "Epoch #:  22 global step 1515   Batch #:  40 loss:  0.34184927\n",
      "Epoch #:  22 global step 1525   Batch #:  50 loss:  0.35043195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  5%|▍         | 23/500 [00:47<16:17,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  22 global step 1535   Batch #:  60 loss:  0.4254116\n",
      "Epoch #:  23 global step 1542   Batch #:  0 loss:  0.36132902\n",
      "Epoch #:  23 global step 1552   Batch #:  10 loss:  0.4505716\n",
      "Epoch #:  23 global step 1562   Batch #:  20 loss:  0.4432423\n",
      "Epoch #:  23 global step 1572   Batch #:  30 loss:  0.40178838\n",
      "Epoch #:  23 global step 1582   Batch #:  40 loss:  0.28052163\n",
      "Epoch #:  23 global step 1592   Batch #:  50 loss:  0.3706586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  5%|▍         | 24/500 [00:49<16:15,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  23 global step 1602   Batch #:  60 loss:  0.42759788\n",
      "Epoch #:  24 global step 1609   Batch #:  0 loss:  0.3648207\n",
      "Epoch #:  24 global step 1619   Batch #:  10 loss:  0.46151313\n",
      "Epoch #:  24 global step 1629   Batch #:  20 loss:  0.42963248\n",
      "Epoch #:  24 global step 1639   Batch #:  30 loss:  0.3197235\n",
      "Epoch #:  24 global step 1649   Batch #:  40 loss:  0.24934593\n",
      "Epoch #:  24 global step 1659   Batch #:  50 loss:  0.30429858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 25/500 [00:51<16:13,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  24 global step 1669   Batch #:  60 loss:  0.41713998\n",
      "Epoch #:  25 global step 1676   Batch #:  0 loss:  0.45202604\n",
      "Epoch #:  25 global step 1686   Batch #:  10 loss:  0.49035642\n",
      "Epoch #:  25 global step 1696   Batch #:  20 loss:  0.49713996\n",
      "Epoch #:  25 global step 1706   Batch #:  30 loss:  0.33243048\n",
      "Epoch #:  25 global step 1716   Batch #:  40 loss:  0.29253063\n",
      "Epoch #:  25 global step 1726   Batch #:  50 loss:  0.33909544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 26/500 [00:53<16:11,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  25 global step 1736   Batch #:  60 loss:  0.38488862\n",
      "Epoch #:  26 global step 1743   Batch #:  0 loss:  0.48832664\n",
      "Epoch #:  26 global step 1753   Batch #:  10 loss:  0.41998866\n",
      "Epoch #:  26 global step 1763   Batch #:  20 loss:  0.4311371\n",
      "Epoch #:  26 global step 1773   Batch #:  30 loss:  0.32490125\n",
      "Epoch #:  26 global step 1783   Batch #:  40 loss:  0.33124933\n",
      "Epoch #:  26 global step 1793   Batch #:  50 loss:  0.3067824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 27/500 [00:55<16:08,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  26 global step 1803   Batch #:  60 loss:  0.38629672\n",
      "Epoch #:  27 global step 1810   Batch #:  0 loss:  0.33774456\n",
      "Epoch #:  27 global step 1820   Batch #:  10 loss:  0.38713378\n",
      "Epoch #:  27 global step 1830   Batch #:  20 loss:  0.44413975\n",
      "Epoch #:  27 global step 1840   Batch #:  30 loss:  0.3456943\n",
      "Epoch #:  27 global step 1850   Batch #:  40 loss:  0.32902235\n",
      "Epoch #:  27 global step 1860   Batch #:  50 loss:  0.31941506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 28/500 [00:57<16:06,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  27 global step 1870   Batch #:  60 loss:  0.37686437\n",
      "Epoch #:  28 global step 1877   Batch #:  0 loss:  0.2971904\n",
      "Epoch #:  28 global step 1887   Batch #:  10 loss:  0.3323705\n",
      "Epoch #:  28 global step 1897   Batch #:  20 loss:  0.3933149\n",
      "Epoch #:  28 global step 1907   Batch #:  30 loss:  0.32031465\n",
      "Epoch #:  28 global step 1917   Batch #:  40 loss:  0.2828832\n",
      "Epoch #:  28 global step 1927   Batch #:  50 loss:  0.2914054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 29/500 [00:59<16:04,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  28 global step 1937   Batch #:  60 loss:  0.35374373\n",
      "Epoch #:  29 global step 1944   Batch #:  0 loss:  0.384464\n",
      "Epoch #:  29 global step 1954   Batch #:  10 loss:  0.33397928\n",
      "Epoch #:  29 global step 1964   Batch #:  20 loss:  0.57405406\n",
      "Epoch #:  29 global step 1974   Batch #:  30 loss:  0.3369489\n",
      "Epoch #:  29 global step 1984   Batch #:  40 loss:  0.35829303\n",
      "Epoch #:  29 global step 1994   Batch #:  50 loss:  0.31092703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 30/500 [01:01<16:02,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  29 global step 2004   Batch #:  60 loss:  0.33569527\n",
      "Epoch #:  30 global step 2011   Batch #:  0 loss:  0.331381\n",
      "Epoch #:  30 global step 2021   Batch #:  10 loss:  0.4122416\n",
      "Epoch #:  30 global step 2031   Batch #:  20 loss:  0.416642\n",
      "Epoch #:  30 global step 2041   Batch #:  30 loss:  0.3122468\n",
      "Epoch #:  30 global step 2051   Batch #:  40 loss:  0.31870022\n",
      "Epoch #:  30 global step 2061   Batch #:  50 loss:  0.27765608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 31/500 [01:03<16:00,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  30 global step 2071   Batch #:  60 loss:  0.33672312\n",
      "Epoch #:  31 global step 2078   Batch #:  0 loss:  0.28443125\n",
      "Epoch #:  31 global step 2088   Batch #:  10 loss:  0.3188561\n",
      "Epoch #:  31 global step 2098   Batch #:  20 loss:  0.4153188\n",
      "Epoch #:  31 global step 2108   Batch #:  30 loss:  0.28247556\n",
      "Epoch #:  31 global step 2118   Batch #:  40 loss:  0.23405203\n",
      "Epoch #:  31 global step 2128   Batch #:  50 loss:  0.2677037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  6%|▋         | 32/500 [01:05<15:58,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  31 global step 2138   Batch #:  60 loss:  0.32305816\n",
      "Epoch #:  32 global step 2145   Batch #:  0 loss:  0.27485752\n",
      "Epoch #:  32 global step 2155   Batch #:  10 loss:  0.2749761\n",
      "Epoch #:  32 global step 2165   Batch #:  20 loss:  0.39558387\n",
      "Epoch #:  32 global step 2175   Batch #:  30 loss:  0.27972248\n",
      "Epoch #:  32 global step 2185   Batch #:  40 loss:  0.23161505\n",
      "Epoch #:  32 global step 2195   Batch #:  50 loss:  0.2690942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 33/500 [01:07<15:56,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  32 global step 2205   Batch #:  60 loss:  0.3200447\n",
      "Epoch #:  33 global step 2212   Batch #:  0 loss:  0.2656793\n",
      "Epoch #:  33 global step 2222   Batch #:  10 loss:  0.30229756\n",
      "Epoch #:  33 global step 2232   Batch #:  20 loss:  0.4150471\n",
      "Epoch #:  33 global step 2242   Batch #:  30 loss:  0.28744635\n",
      "Epoch #:  33 global step 2252   Batch #:  40 loss:  0.230815\n",
      "Epoch #:  33 global step 2262   Batch #:  50 loss:  0.2674156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 34/500 [01:09<15:54,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  33 global step 2272   Batch #:  60 loss:  0.31249067\n",
      "Epoch #:  34 global step 2279   Batch #:  0 loss:  0.2570016\n",
      "Epoch #:  34 global step 2289   Batch #:  10 loss:  0.2797979\n",
      "Epoch #:  34 global step 2299   Batch #:  20 loss:  0.39697647\n",
      "Epoch #:  34 global step 2309   Batch #:  30 loss:  0.27180064\n",
      "Epoch #:  34 global step 2319   Batch #:  40 loss:  0.22959259\n",
      "Epoch #:  34 global step 2329   Batch #:  50 loss:  0.28529474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 35/500 [01:11<15:52,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  34 global step 2339   Batch #:  60 loss:  0.32984197\n",
      "Epoch #:  35 global step 2346   Batch #:  0 loss:  0.28042892\n",
      "Epoch #:  35 global step 2356   Batch #:  10 loss:  0.3303385\n",
      "Epoch #:  35 global step 2366   Batch #:  20 loss:  0.42009676\n",
      "Epoch #:  35 global step 2376   Batch #:  30 loss:  0.31119418\n",
      "Epoch #:  35 global step 2386   Batch #:  40 loss:  0.23629192\n",
      "Epoch #:  35 global step 2396   Batch #:  50 loss:  0.31391233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 36/500 [01:13<15:50,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  35 global step 2406   Batch #:  60 loss:  0.3243681\n",
      "Epoch #:  36 global step 2413   Batch #:  0 loss:  0.2575179\n",
      "Epoch #:  36 global step 2423   Batch #:  10 loss:  0.38460028\n",
      "Epoch #:  36 global step 2433   Batch #:  20 loss:  0.53414184\n",
      "Epoch #:  36 global step 2443   Batch #:  30 loss:  0.30601582\n",
      "Epoch #:  36 global step 2453   Batch #:  40 loss:  0.2720266\n",
      "Epoch #:  36 global step 2463   Batch #:  50 loss:  0.3369727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 37/500 [01:15<15:47,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  36 global step 2473   Batch #:  60 loss:  0.44106072\n",
      "Epoch #:  37 global step 2480   Batch #:  0 loss:  0.36233607\n",
      "Epoch #:  37 global step 2490   Batch #:  10 loss:  0.3164453\n",
      "Epoch #:  37 global step 2500   Batch #:  20 loss:  0.39798275\n",
      "Epoch #:  37 global step 2510   Batch #:  30 loss:  0.31132668\n",
      "Epoch #:  37 global step 2520   Batch #:  40 loss:  0.45389348\n",
      "Epoch #:  37 global step 2530   Batch #:  50 loss:  0.30444014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 38/500 [01:17<15:45,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  37 global step 2540   Batch #:  60 loss:  0.33318308\n",
      "Epoch #:  38 global step 2547   Batch #:  0 loss:  0.29239026\n",
      "Epoch #:  38 global step 2557   Batch #:  10 loss:  0.41073215\n",
      "Epoch #:  38 global step 2567   Batch #:  20 loss:  0.37792796\n",
      "Epoch #:  38 global step 2577   Batch #:  30 loss:  0.31722707\n",
      "Epoch #:  38 global step 2587   Batch #:  40 loss:  0.29615292\n",
      "Epoch #:  38 global step 2597   Batch #:  50 loss:  0.3260411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 39/500 [01:19<15:43,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  38 global step 2607   Batch #:  60 loss:  0.26902533\n",
      "Epoch #:  39 global step 2614   Batch #:  0 loss:  0.26384813\n",
      "Epoch #:  39 global step 2624   Batch #:  10 loss:  0.34178713\n",
      "Epoch #:  39 global step 2634   Batch #:  20 loss:  0.35807657\n",
      "Epoch #:  39 global step 2644   Batch #:  30 loss:  0.24364933\n",
      "Epoch #:  39 global step 2654   Batch #:  40 loss:  0.22816506\n",
      "Epoch #:  39 global step 2664   Batch #:  50 loss:  0.2449504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 40/500 [01:21<15:41,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  39 global step 2674   Batch #:  60 loss:  0.22993553\n",
      "Epoch #:  40 global step 2681   Batch #:  0 loss:  0.23629327\n",
      "Epoch #:  40 global step 2691   Batch #:  10 loss:  0.20567541\n",
      "Epoch #:  40 global step 2701   Batch #:  20 loss:  0.32088572\n",
      "Epoch #:  40 global step 2711   Batch #:  30 loss:  0.25431737\n",
      "Epoch #:  40 global step 2721   Batch #:  40 loss:  0.22105986\n",
      "Epoch #:  40 global step 2731   Batch #:  50 loss:  0.40051666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 41/500 [01:23<15:39,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  40 global step 2741   Batch #:  60 loss:  0.26516122\n",
      "Epoch #:  41 global step 2748   Batch #:  0 loss:  0.21911326\n",
      "Epoch #:  41 global step 2758   Batch #:  10 loss:  0.21890126\n",
      "Epoch #:  41 global step 2768   Batch #:  20 loss:  0.3045263\n",
      "Epoch #:  41 global step 2778   Batch #:  30 loss:  0.22857897\n",
      "Epoch #:  41 global step 2788   Batch #:  40 loss:  0.20660889\n",
      "Epoch #:  41 global step 2798   Batch #:  50 loss:  0.23659715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 42/500 [01:25<15:37,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  41 global step 2808   Batch #:  60 loss:  0.2428447\n",
      "Epoch #:  42 global step 2815   Batch #:  0 loss:  0.21494302\n",
      "Epoch #:  42 global step 2825   Batch #:  10 loss:  0.18916127\n",
      "Epoch #:  42 global step 2835   Batch #:  20 loss:  0.31089756\n",
      "Epoch #:  42 global step 2845   Batch #:  30 loss:  0.22074312\n",
      "Epoch #:  42 global step 2855   Batch #:  40 loss:  0.21988393\n",
      "Epoch #:  42 global step 2865   Batch #:  50 loss:  0.2516419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  9%|▊         | 43/500 [01:27<15:35,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  42 global step 2875   Batch #:  60 loss:  0.23178054\n",
      "Epoch #:  43 global step 2882   Batch #:  0 loss:  0.21182753\n",
      "Epoch #:  43 global step 2892   Batch #:  10 loss:  0.20977703\n",
      "Epoch #:  43 global step 2902   Batch #:  20 loss:  0.32632563\n",
      "Epoch #:  43 global step 2912   Batch #:  30 loss:  0.24464568\n",
      "Epoch #:  43 global step 2922   Batch #:  40 loss:  0.21625315\n",
      "Epoch #:  43 global step 2932   Batch #:  50 loss:  0.23944975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 44/500 [01:30<15:32,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  43 global step 2942   Batch #:  60 loss:  0.22194272\n",
      "Epoch #:  44 global step 2949   Batch #:  0 loss:  0.20480964\n",
      "Epoch #:  44 global step 2959   Batch #:  10 loss:  0.18321922\n",
      "Epoch #:  44 global step 2969   Batch #:  20 loss:  0.2644775\n",
      "Epoch #:  44 global step 2979   Batch #:  30 loss:  0.21249487\n",
      "Epoch #:  44 global step 2989   Batch #:  40 loss:  0.19501206\n",
      "Epoch #:  44 global step 2999   Batch #:  50 loss:  0.2476132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 45/500 [01:32<15:30,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  44 global step 3009   Batch #:  60 loss:  0.21334204\n",
      "Epoch #:  45 global step 3016   Batch #:  0 loss:  0.20106459\n",
      "Epoch #:  45 global step 3026   Batch #:  10 loss:  0.17406076\n",
      "Epoch #:  45 global step 3036   Batch #:  20 loss:  0.27039006\n",
      "Epoch #:  45 global step 3046   Batch #:  30 loss:  0.21030131\n",
      "Epoch #:  45 global step 3056   Batch #:  40 loss:  0.19737145\n",
      "Epoch #:  45 global step 3066   Batch #:  50 loss:  0.23393491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 46/500 [01:34<15:28,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  45 global step 3076   Batch #:  60 loss:  0.20759867\n",
      "Epoch #:  46 global step 3083   Batch #:  0 loss:  0.19914825\n",
      "Epoch #:  46 global step 3093   Batch #:  10 loss:  0.20350373\n",
      "Epoch #:  46 global step 3103   Batch #:  20 loss:  0.26157686\n",
      "Epoch #:  46 global step 3113   Batch #:  30 loss:  0.20889518\n",
      "Epoch #:  46 global step 3123   Batch #:  40 loss:  0.19326916\n",
      "Epoch #:  46 global step 3133   Batch #:  50 loss:  0.23191187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 47/500 [01:36<15:26,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  46 global step 3143   Batch #:  60 loss:  0.20985371\n",
      "Epoch #:  47 global step 3150   Batch #:  0 loss:  0.1956153\n",
      "Epoch #:  47 global step 3160   Batch #:  10 loss:  0.16584806\n",
      "Epoch #:  47 global step 3170   Batch #:  20 loss:  0.27348614\n",
      "Epoch #:  47 global step 3180   Batch #:  30 loss:  0.22906332\n",
      "Epoch #:  47 global step 3190   Batch #:  40 loss:  0.18933187\n",
      "Epoch #:  47 global step 3200   Batch #:  50 loss:  0.24127871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 10%|▉         | 48/500 [01:38<15:24,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  47 global step 3210   Batch #:  60 loss:  0.21920876\n",
      "Epoch #:  48 global step 3217   Batch #:  0 loss:  0.20751433\n",
      "Epoch #:  48 global step 3227   Batch #:  10 loss:  0.17482798\n",
      "Epoch #:  48 global step 3237   Batch #:  20 loss:  0.31091005\n",
      "Epoch #:  48 global step 3247   Batch #:  30 loss:  0.2191306\n",
      "Epoch #:  48 global step 3257   Batch #:  40 loss:  0.20086743\n",
      "Epoch #:  48 global step 3267   Batch #:  50 loss:  0.23785394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 10%|▉         | 49/500 [01:40<15:22,  2.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  48 global step 3277   Batch #:  60 loss:  0.22315277\n",
      "Epoch #:  49 global step 3284   Batch #:  0 loss:  0.21444397\n",
      "Epoch #:  49 global step 3294   Batch #:  10 loss:  0.1945753\n",
      "Epoch #:  49 global step 3304   Batch #:  20 loss:  0.27457792\n",
      "Epoch #:  49 global step 3314   Batch #:  30 loss:  0.22409286\n",
      "Epoch #:  49 global step 3324   Batch #:  40 loss:  0.20484\n",
      "Epoch #:  49 global step 3334   Batch #:  50 loss:  0.24257034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 10%|█         | 50/500 [01:42<15:20,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  49 global step 3344   Batch #:  60 loss:  0.25992265\n",
      "Epoch #:  50 global step 3351   Batch #:  0 loss:  0.21125422\n",
      "Epoch #:  50 global step 3361   Batch #:  10 loss:  0.287403\n",
      "Epoch #:  50 global step 3371   Batch #:  20 loss:  0.35052782\n",
      "Epoch #:  50 global step 3381   Batch #:  30 loss:  0.28089267\n",
      "Epoch #:  50 global step 3391   Batch #:  40 loss:  0.22030021\n",
      "Epoch #:  50 global step 3401   Batch #:  50 loss:  0.24082775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 10%|█         | 51/500 [01:44<15:18,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  50 global step 3411   Batch #:  60 loss:  0.21911524\n",
      "Epoch #:  51 global step 3418   Batch #:  0 loss:  0.20621638\n",
      "Epoch #:  51 global step 3428   Batch #:  10 loss:  0.16200271\n",
      "Epoch #:  51 global step 3438   Batch #:  20 loss:  0.30715203\n",
      "Epoch #:  51 global step 3448   Batch #:  30 loss:  0.21263826\n",
      "Epoch #:  51 global step 3458   Batch #:  40 loss:  0.19316748\n",
      "Epoch #:  51 global step 3468   Batch #:  50 loss:  0.2301327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 10%|█         | 52/500 [01:46<15:16,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  51 global step 3478   Batch #:  60 loss:  0.21487468\n",
      "Epoch #:  52 global step 3485   Batch #:  0 loss:  0.19887954\n",
      "Epoch #:  52 global step 3495   Batch #:  10 loss:  0.13900356\n",
      "Epoch #:  52 global step 3505   Batch #:  20 loss:  0.25611225\n",
      "Epoch #:  52 global step 3515   Batch #:  30 loss:  0.28734085\n",
      "Epoch #:  52 global step 3525   Batch #:  40 loss:  0.23989356\n",
      "Epoch #:  52 global step 3535   Batch #:  50 loss:  0.23173788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 11%|█         | 53/500 [01:48<15:13,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  52 global step 3545   Batch #:  60 loss:  0.21160263\n",
      "Epoch #:  53 global step 3552   Batch #:  0 loss:  0.20194344\n",
      "Epoch #:  53 global step 3562   Batch #:  10 loss:  0.21050438\n",
      "Epoch #:  53 global step 3572   Batch #:  20 loss:  0.25831026\n",
      "Epoch #:  53 global step 3582   Batch #:  30 loss:  0.22458263\n",
      "Epoch #:  53 global step 3592   Batch #:  40 loss:  0.1987219\n",
      "Epoch #:  53 global step 3602   Batch #:  50 loss:  0.22921668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 11%|█         | 54/500 [01:50<15:11,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  53 global step 3612   Batch #:  60 loss:  0.2092148\n",
      "Epoch #:  54 global step 3619   Batch #:  0 loss:  0.19058402\n",
      "Epoch #:  54 global step 3629   Batch #:  10 loss:  0.18222909\n",
      "Epoch #:  54 global step 3639   Batch #:  20 loss:  0.26479444\n",
      "Epoch #:  54 global step 3649   Batch #:  30 loss:  0.23166926\n",
      "Epoch #:  54 global step 3659   Batch #:  40 loss:  0.19570751\n",
      "Epoch #:  54 global step 3669   Batch #:  50 loss:  0.2420661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 11%|█         | 55/500 [01:52<15:09,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  54 global step 3679   Batch #:  60 loss:  0.21244168\n",
      "Epoch #:  55 global step 3686   Batch #:  0 loss:  0.24305612\n",
      "Epoch #:  55 global step 3696   Batch #:  10 loss:  0.16298687\n",
      "Epoch #:  55 global step 3706   Batch #:  20 loss:  0.28162634\n",
      "Epoch #:  55 global step 3716   Batch #:  30 loss:  0.20900343\n",
      "Epoch #:  55 global step 3726   Batch #:  40 loss:  0.19973196\n",
      "Epoch #:  55 global step 3736   Batch #:  50 loss:  0.24236575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 11%|█         | 56/500 [01:54<15:07,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  55 global step 3746   Batch #:  60 loss:  0.20352705\n",
      "Epoch #:  56 global step 3753   Batch #:  0 loss:  0.22251794\n",
      "Epoch #:  56 global step 3763   Batch #:  10 loss:  0.1669889\n",
      "Epoch #:  56 global step 3773   Batch #:  20 loss:  0.28114098\n",
      "Epoch #:  56 global step 3783   Batch #:  30 loss:  0.22733195\n",
      "Epoch #:  56 global step 3793   Batch #:  40 loss:  0.20419697\n",
      "Epoch #:  56 global step 3803   Batch #:  50 loss:  0.23510589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 11%|█▏        | 57/500 [01:56<15:05,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  56 global step 3813   Batch #:  60 loss:  0.20686631\n",
      "Epoch #:  57 global step 3820   Batch #:  0 loss:  0.19707136\n",
      "Epoch #:  57 global step 3830   Batch #:  10 loss:  0.19487923\n",
      "Epoch #:  57 global step 3840   Batch #:  20 loss:  0.2683537\n",
      "Epoch #:  57 global step 3850   Batch #:  30 loss:  0.22453442\n",
      "Epoch #:  57 global step 3860   Batch #:  40 loss:  0.19793592\n",
      "Epoch #:  57 global step 3870   Batch #:  50 loss:  0.23340759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 58/500 [01:58<15:03,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  57 global step 3880   Batch #:  60 loss:  0.21671523\n",
      "Epoch #:  58 global step 3887   Batch #:  0 loss:  0.19428521\n",
      "Epoch #:  58 global step 3897   Batch #:  10 loss:  0.15668602\n",
      "Epoch #:  58 global step 3907   Batch #:  20 loss:  0.25478935\n",
      "Epoch #:  58 global step 3917   Batch #:  30 loss:  0.20309891\n",
      "Epoch #:  58 global step 3927   Batch #:  40 loss:  0.18793795\n",
      "Epoch #:  58 global step 3937   Batch #:  50 loss:  0.22726822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 59/500 [02:00<15:01,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  58 global step 3947   Batch #:  60 loss:  0.20655613\n",
      "Epoch #:  59 global step 3954   Batch #:  0 loss:  0.19284827\n",
      "Epoch #:  59 global step 3964   Batch #:  10 loss:  0.15635034\n",
      "Epoch #:  59 global step 3974   Batch #:  20 loss:  0.23156196\n",
      "Epoch #:  59 global step 3984   Batch #:  30 loss:  0.1826575\n",
      "Epoch #:  59 global step 3994   Batch #:  40 loss:  0.18207842\n",
      "Epoch #:  59 global step 4004   Batch #:  50 loss:  0.21186955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 60/500 [02:02<14:59,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  59 global step 4014   Batch #:  60 loss:  0.19771782\n",
      "Epoch #:  60 global step 4021   Batch #:  0 loss:  0.21382828\n",
      "Epoch #:  60 global step 4031   Batch #:  10 loss:  0.17032333\n",
      "Epoch #:  60 global step 4041   Batch #:  20 loss:  0.24612667\n",
      "Epoch #:  60 global step 4051   Batch #:  30 loss:  0.19548337\n",
      "Epoch #:  60 global step 4061   Batch #:  40 loss:  0.18884934\n",
      "Epoch #:  60 global step 4071   Batch #:  50 loss:  0.28114083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 61/500 [02:04<14:57,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  60 global step 4081   Batch #:  60 loss:  0.22815967\n",
      "Epoch #:  61 global step 4088   Batch #:  0 loss:  0.20058876\n",
      "Epoch #:  61 global step 4098   Batch #:  10 loss:  0.39433\n",
      "Epoch #:  61 global step 4108   Batch #:  20 loss:  0.2930477\n",
      "Epoch #:  61 global step 4118   Batch #:  30 loss:  0.21226047\n",
      "Epoch #:  61 global step 4128   Batch #:  40 loss:  0.20839497\n",
      "Epoch #:  61 global step 4138   Batch #:  50 loss:  0.23196168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 62/500 [02:06<14:55,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  61 global step 4148   Batch #:  60 loss:  0.23589955\n",
      "Epoch #:  62 global step 4155   Batch #:  0 loss:  0.23933357\n",
      "Epoch #:  62 global step 4165   Batch #:  10 loss:  0.21231951\n",
      "Epoch #:  62 global step 4175   Batch #:  20 loss:  0.263289\n",
      "Epoch #:  62 global step 4185   Batch #:  30 loss:  0.22152522\n",
      "Epoch #:  62 global step 4195   Batch #:  40 loss:  0.20213242\n",
      "Epoch #:  62 global step 4205   Batch #:  50 loss:  0.228516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 63/500 [02:08<14:53,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  62 global step 4215   Batch #:  60 loss:  0.2099356\n",
      "Epoch #:  63 global step 4222   Batch #:  0 loss:  0.21730714\n",
      "Epoch #:  63 global step 4232   Batch #:  10 loss:  0.22507867\n",
      "Epoch #:  63 global step 4242   Batch #:  20 loss:  0.23272136\n",
      "Epoch #:  63 global step 4252   Batch #:  30 loss:  0.19338593\n",
      "Epoch #:  63 global step 4262   Batch #:  40 loss:  0.19174007\n",
      "Epoch #:  63 global step 4272   Batch #:  50 loss:  0.22743678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 64/500 [02:10<14:50,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  63 global step 4282   Batch #:  60 loss:  0.20389098\n",
      "Epoch #:  64 global step 4289   Batch #:  0 loss:  0.17984192\n",
      "Epoch #:  64 global step 4299   Batch #:  10 loss:  0.15258211\n",
      "Epoch #:  64 global step 4309   Batch #:  20 loss:  0.21676698\n",
      "Epoch #:  64 global step 4319   Batch #:  30 loss:  0.15244696\n",
      "Epoch #:  64 global step 4329   Batch #:  40 loss:  0.18018475\n",
      "Epoch #:  64 global step 4339   Batch #:  50 loss:  0.19956271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 65/500 [02:12<14:48,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  64 global step 4349   Batch #:  60 loss:  0.19670261\n",
      "Epoch #:  65 global step 4356   Batch #:  0 loss:  0.2567856\n",
      "Epoch #:  65 global step 4366   Batch #:  10 loss:  0.20754935\n",
      "Epoch #:  65 global step 4376   Batch #:  20 loss:  0.22231162\n",
      "Epoch #:  65 global step 4386   Batch #:  30 loss:  0.16790849\n",
      "Epoch #:  65 global step 4396   Batch #:  40 loss:  0.19470191\n",
      "Epoch #:  65 global step 4406   Batch #:  50 loss:  0.20539017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 66/500 [02:14<14:46,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  65 global step 4416   Batch #:  60 loss:  0.19403434\n",
      "Epoch #:  66 global step 4423   Batch #:  0 loss:  0.12820537\n",
      "Epoch #:  66 global step 4433   Batch #:  10 loss:  0.13822185\n",
      "Epoch #:  66 global step 4443   Batch #:  20 loss:  0.19759844\n",
      "Epoch #:  66 global step 4453   Batch #:  30 loss:  0.09728467\n",
      "Epoch #:  66 global step 4463   Batch #:  40 loss:  0.17764293\n",
      "Epoch #:  66 global step 4473   Batch #:  50 loss:  0.19576812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 67/500 [02:16<14:44,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  66 global step 4483   Batch #:  60 loss:  0.15515697\n",
      "Epoch #:  67 global step 4490   Batch #:  0 loss:  0.114824235\n",
      "Epoch #:  67 global step 4500   Batch #:  10 loss:  0.1481739\n",
      "Epoch #:  67 global step 4510   Batch #:  20 loss:  0.26147458\n",
      "Epoch #:  67 global step 4520   Batch #:  30 loss:  0.18778345\n",
      "Epoch #:  67 global step 4530   Batch #:  40 loss:  0.20182933\n",
      "Epoch #:  67 global step 4540   Batch #:  50 loss:  0.19378923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 14%|█▎        | 68/500 [02:18<14:42,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  67 global step 4550   Batch #:  60 loss:  0.16822493\n",
      "Epoch #:  68 global step 4557   Batch #:  0 loss:  0.13702703\n",
      "Epoch #:  68 global step 4567   Batch #:  10 loss:  0.13882665\n",
      "Epoch #:  68 global step 4577   Batch #:  20 loss:  0.21162201\n",
      "Epoch #:  68 global step 4587   Batch #:  30 loss:  0.091482215\n",
      "Epoch #:  68 global step 4597   Batch #:  40 loss:  0.16112942\n",
      "Epoch #:  68 global step 4607   Batch #:  50 loss:  0.18104675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 69/500 [02:20<14:40,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  68 global step 4617   Batch #:  60 loss:  0.17461668\n",
      "Epoch #:  69 global step 4624   Batch #:  0 loss:  0.10484781\n",
      "Epoch #:  69 global step 4634   Batch #:  10 loss:  0.17249773\n",
      "Epoch #:  69 global step 4644   Batch #:  20 loss:  0.17987563\n",
      "Epoch #:  69 global step 4654   Batch #:  30 loss:  0.25058892\n",
      "Epoch #:  69 global step 4664   Batch #:  40 loss:  0.21182786\n",
      "Epoch #:  69 global step 4674   Batch #:  50 loss:  0.28670532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 70/500 [02:23<14:38,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  69 global step 4684   Batch #:  60 loss:  0.2230181\n",
      "Epoch #:  70 global step 4691   Batch #:  0 loss:  0.16653329\n",
      "Epoch #:  70 global step 4701   Batch #:  10 loss:  0.1429367\n",
      "Epoch #:  70 global step 4711   Batch #:  20 loss:  0.2138863\n",
      "Epoch #:  70 global step 4721   Batch #:  30 loss:  0.10381477\n",
      "Epoch #:  70 global step 4731   Batch #:  40 loss:  0.17227538\n",
      "Epoch #:  70 global step 4741   Batch #:  50 loss:  0.18136476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 71/500 [02:25<14:36,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  70 global step 4751   Batch #:  60 loss:  0.16207191\n",
      "Epoch #:  71 global step 4758   Batch #:  0 loss:  0.12960236\n",
      "Epoch #:  71 global step 4768   Batch #:  10 loss:  0.122488424\n",
      "Epoch #:  71 global step 4778   Batch #:  20 loss:  0.15045555\n",
      "Epoch #:  71 global step 4788   Batch #:  30 loss:  0.07215076\n",
      "Epoch #:  71 global step 4798   Batch #:  40 loss:  0.12962212\n",
      "Epoch #:  71 global step 4808   Batch #:  50 loss:  0.16176488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 72/500 [02:27<14:34,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  71 global step 4818   Batch #:  60 loss:  0.17337826\n",
      "Epoch #:  72 global step 4825   Batch #:  0 loss:  0.121269554\n",
      "Epoch #:  72 global step 4835   Batch #:  10 loss:  0.094841436\n",
      "Epoch #:  72 global step 4845   Batch #:  20 loss:  0.13102996\n",
      "Epoch #:  72 global step 4855   Batch #:  30 loss:  0.06243048\n",
      "Epoch #:  72 global step 4865   Batch #:  40 loss:  0.12224123\n",
      "Epoch #:  72 global step 4875   Batch #:  50 loss:  0.12494381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 15%|█▍        | 73/500 [02:29<14:32,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  72 global step 4885   Batch #:  60 loss:  0.16127011\n",
      "Epoch #:  73 global step 4892   Batch #:  0 loss:  0.10280209\n",
      "Epoch #:  73 global step 4902   Batch #:  10 loss:  0.08159272\n",
      "Epoch #:  73 global step 4912   Batch #:  20 loss:  0.13822867\n",
      "Epoch #:  73 global step 4922   Batch #:  30 loss:  0.05759767\n",
      "Epoch #:  73 global step 4932   Batch #:  40 loss:  0.11536601\n",
      "Epoch #:  73 global step 4942   Batch #:  50 loss:  0.12346439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 15%|█▍        | 74/500 [02:31<14:30,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  73 global step 4952   Batch #:  60 loss:  0.17072856\n",
      "Epoch #:  74 global step 4959   Batch #:  0 loss:  0.11068074\n",
      "Epoch #:  74 global step 4969   Batch #:  10 loss:  0.11488282\n",
      "Epoch #:  74 global step 4979   Batch #:  20 loss:  0.17144175\n",
      "Epoch #:  74 global step 4989   Batch #:  30 loss:  0.08527869\n",
      "Epoch #:  74 global step 4999   Batch #:  40 loss:  0.12739226\n",
      "Epoch #:  74 global step 5009   Batch #:  50 loss:  0.11804181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 75/500 [02:33<14:28,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  74 global step 5019   Batch #:  60 loss:  0.19804767\n",
      "Epoch #:  75 global step 5026   Batch #:  0 loss:  0.16093871\n",
      "Epoch #:  75 global step 5036   Batch #:  10 loss:  0.14983425\n",
      "Epoch #:  75 global step 5046   Batch #:  20 loss:  0.20445044\n",
      "Epoch #:  75 global step 5056   Batch #:  30 loss:  0.09460606\n",
      "Epoch #:  75 global step 5066   Batch #:  40 loss:  0.1912814\n",
      "Epoch #:  75 global step 5076   Batch #:  50 loss:  0.1479641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 76/500 [02:35<14:26,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  75 global step 5086   Batch #:  60 loss:  0.1826912\n",
      "Epoch #:  76 global step 5093   Batch #:  0 loss:  0.16591395\n",
      "Epoch #:  76 global step 5103   Batch #:  10 loss:  0.16002253\n",
      "Epoch #:  76 global step 5113   Batch #:  20 loss:  0.23215665\n",
      "Epoch #:  76 global step 5123   Batch #:  30 loss:  0.09872209\n",
      "Epoch #:  76 global step 5133   Batch #:  40 loss:  0.14718266\n",
      "Epoch #:  76 global step 5143   Batch #:  50 loss:  0.14556368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 77/500 [02:37<14:24,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  76 global step 5153   Batch #:  60 loss:  0.15907302\n",
      "Epoch #:  77 global step 5160   Batch #:  0 loss:  0.12730706\n",
      "Epoch #:  77 global step 5170   Batch #:  10 loss:  0.1350643\n",
      "Epoch #:  77 global step 5180   Batch #:  20 loss:  0.1734438\n",
      "Epoch #:  77 global step 5190   Batch #:  30 loss:  0.06350764\n",
      "Epoch #:  77 global step 5200   Batch #:  40 loss:  0.1163919\n",
      "Epoch #:  77 global step 5210   Batch #:  50 loss:  0.120751284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 16%|█▌        | 78/500 [02:39<14:22,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  77 global step 5220   Batch #:  60 loss:  0.13027832\n",
      "Epoch #:  78 global step 5227   Batch #:  0 loss:  0.103858754\n",
      "Epoch #:  78 global step 5237   Batch #:  10 loss:  0.12044529\n",
      "Epoch #:  78 global step 5247   Batch #:  20 loss:  0.14593875\n",
      "Epoch #:  78 global step 5257   Batch #:  30 loss:  0.0741761\n",
      "Epoch #:  78 global step 5267   Batch #:  40 loss:  0.12499051\n",
      "Epoch #:  78 global step 5277   Batch #:  50 loss:  0.11317841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 16%|█▌        | 79/500 [02:41<14:19,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  78 global step 5287   Batch #:  60 loss:  0.12385226\n",
      "Epoch #:  79 global step 5294   Batch #:  0 loss:  0.10210076\n",
      "Epoch #:  79 global step 5304   Batch #:  10 loss:  0.11975994\n",
      "Epoch #:  79 global step 5314   Batch #:  20 loss:  0.20437306\n",
      "Epoch #:  79 global step 5324   Batch #:  30 loss:  0.09713231\n",
      "Epoch #:  79 global step 5334   Batch #:  40 loss:  0.1561189\n",
      "Epoch #:  79 global step 5344   Batch #:  50 loss:  0.114379235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 16%|█▌        | 80/500 [02:43<14:17,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  79 global step 5354   Batch #:  60 loss:  0.14739725\n",
      "Epoch #:  80 global step 5361   Batch #:  0 loss:  0.10446215\n",
      "Epoch #:  80 global step 5371   Batch #:  10 loss:  0.082055435\n",
      "Epoch #:  80 global step 5381   Batch #:  20 loss:  0.11501837\n",
      "Epoch #:  80 global step 5391   Batch #:  30 loss:  0.12029041\n",
      "Epoch #:  80 global step 5401   Batch #:  40 loss:  0.11663655\n",
      "Epoch #:  80 global step 5411   Batch #:  50 loss:  0.14078858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 16%|█▌        | 81/500 [02:45<14:15,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  80 global step 5421   Batch #:  60 loss:  0.11426296\n",
      "Epoch #:  81 global step 5428   Batch #:  0 loss:  0.1273955\n",
      "Epoch #:  81 global step 5438   Batch #:  10 loss:  0.10784098\n",
      "Epoch #:  81 global step 5448   Batch #:  20 loss:  0.13843584\n",
      "Epoch #:  81 global step 5458   Batch #:  30 loss:  0.05753056\n",
      "Epoch #:  81 global step 5468   Batch #:  40 loss:  0.10149898\n",
      "Epoch #:  81 global step 5478   Batch #:  50 loss:  0.10729352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 16%|█▋        | 82/500 [02:47<14:13,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  81 global step 5488   Batch #:  60 loss:  0.10175047\n",
      "Epoch #:  82 global step 5495   Batch #:  0 loss:  0.10706891\n",
      "Epoch #:  82 global step 5505   Batch #:  10 loss:  0.09227007\n",
      "Epoch #:  82 global step 5515   Batch #:  20 loss:  0.13634443\n",
      "Epoch #:  82 global step 5525   Batch #:  30 loss:  0.060926598\n",
      "Epoch #:  82 global step 5535   Batch #:  40 loss:  0.1257497\n",
      "Epoch #:  82 global step 5545   Batch #:  50 loss:  0.11075603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 83/500 [02:49<14:11,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  82 global step 5555   Batch #:  60 loss:  0.10650999\n",
      "Epoch #:  83 global step 5562   Batch #:  0 loss:  0.09670602\n",
      "Epoch #:  83 global step 5572   Batch #:  10 loss:  0.07651991\n",
      "Epoch #:  83 global step 5582   Batch #:  20 loss:  0.12849171\n",
      "Epoch #:  83 global step 5592   Batch #:  30 loss:  0.055253267\n",
      "Epoch #:  83 global step 5602   Batch #:  40 loss:  0.1498691\n",
      "Epoch #:  83 global step 5612   Batch #:  50 loss:  0.10902623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 84/500 [02:51<14:09,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  83 global step 5622   Batch #:  60 loss:  0.09210468\n",
      "Epoch #:  84 global step 5629   Batch #:  0 loss:  0.10756965\n",
      "Epoch #:  84 global step 5639   Batch #:  10 loss:  0.07816301\n",
      "Epoch #:  84 global step 5649   Batch #:  20 loss:  0.12644632\n",
      "Epoch #:  84 global step 5659   Batch #:  30 loss:  0.061063226\n",
      "Epoch #:  84 global step 5669   Batch #:  40 loss:  0.113785975\n",
      "Epoch #:  84 global step 5679   Batch #:  50 loss:  0.11152091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 85/500 [02:53<14:07,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  84 global step 5689   Batch #:  60 loss:  0.08436326\n",
      "Epoch #:  85 global step 5696   Batch #:  0 loss:  0.0973781\n",
      "Epoch #:  85 global step 5706   Batch #:  10 loss:  0.07267171\n",
      "Epoch #:  85 global step 5716   Batch #:  20 loss:  0.12853596\n",
      "Epoch #:  85 global step 5726   Batch #:  30 loss:  0.067931995\n",
      "Epoch #:  85 global step 5736   Batch #:  40 loss:  0.098726586\n",
      "Epoch #:  85 global step 5746   Batch #:  50 loss:  0.11148611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 86/500 [02:55<14:05,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  85 global step 5756   Batch #:  60 loss:  0.090466\n",
      "Epoch #:  86 global step 5763   Batch #:  0 loss:  0.090202905\n",
      "Epoch #:  86 global step 5773   Batch #:  10 loss:  0.085129276\n",
      "Epoch #:  86 global step 5783   Batch #:  20 loss:  0.12426804\n",
      "Epoch #:  86 global step 5793   Batch #:  30 loss:  0.08553073\n",
      "Epoch #:  86 global step 5803   Batch #:  40 loss:  0.10233045\n",
      "Epoch #:  86 global step 5813   Batch #:  50 loss:  0.10529433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 87/500 [02:57<14:03,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  86 global step 5823   Batch #:  60 loss:  0.09988753\n",
      "Epoch #:  87 global step 5830   Batch #:  0 loss:  0.09519719\n",
      "Epoch #:  87 global step 5840   Batch #:  10 loss:  0.09832108\n",
      "Epoch #:  87 global step 5850   Batch #:  20 loss:  0.1304447\n",
      "Epoch #:  87 global step 5860   Batch #:  30 loss:  0.055838507\n",
      "Epoch #:  87 global step 5870   Batch #:  40 loss:  0.10340535\n",
      "Epoch #:  87 global step 5880   Batch #:  50 loss:  0.1766596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 88/500 [02:59<14:01,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  87 global step 5890   Batch #:  60 loss:  0.12185504\n",
      "Epoch #:  88 global step 5897   Batch #:  0 loss:  0.11285668\n",
      "Epoch #:  88 global step 5907   Batch #:  10 loss:  0.11033647\n",
      "Epoch #:  88 global step 5917   Batch #:  20 loss:  0.1333242\n",
      "Epoch #:  88 global step 5927   Batch #:  30 loss:  0.14456181\n",
      "Epoch #:  88 global step 5937   Batch #:  40 loss:  0.21783479\n",
      "Epoch #:  88 global step 5947   Batch #:  50 loss:  0.18385908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 89/500 [03:01<13:59,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  88 global step 5957   Batch #:  60 loss:  0.13403828\n",
      "Epoch #:  89 global step 5964   Batch #:  0 loss:  0.19370158\n",
      "Epoch #:  89 global step 5974   Batch #:  10 loss:  0.14232811\n",
      "Epoch #:  89 global step 5984   Batch #:  20 loss:  0.16809626\n",
      "Epoch #:  89 global step 5994   Batch #:  30 loss:  0.06379393\n",
      "Epoch #:  89 global step 6004   Batch #:  40 loss:  0.13482717\n",
      "Epoch #:  89 global step 6014   Batch #:  50 loss:  0.14930457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 90/500 [03:03<13:57,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  89 global step 6024   Batch #:  60 loss:  0.112756334\n",
      "Epoch #:  90 global step 6031   Batch #:  0 loss:  0.13535745\n",
      "Epoch #:  90 global step 6041   Batch #:  10 loss:  0.12552197\n",
      "Epoch #:  90 global step 6051   Batch #:  20 loss:  0.18564922\n",
      "Epoch #:  90 global step 6061   Batch #:  30 loss:  0.079292424\n",
      "Epoch #:  90 global step 6071   Batch #:  40 loss:  0.18751176\n",
      "Epoch #:  90 global step 6081   Batch #:  50 loss:  0.24015494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 91/500 [03:05<13:55,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  90 global step 6091   Batch #:  60 loss:  0.17308678\n",
      "Epoch #:  91 global step 6098   Batch #:  0 loss:  0.11733935\n",
      "Epoch #:  91 global step 6108   Batch #:  10 loss:  0.152262\n",
      "Epoch #:  91 global step 6118   Batch #:  20 loss:  0.24269326\n",
      "Epoch #:  91 global step 6128   Batch #:  30 loss:  0.060712133\n",
      "Epoch #:  91 global step 6138   Batch #:  40 loss:  0.12526502\n",
      "Epoch #:  91 global step 6148   Batch #:  50 loss:  0.16316792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 92/500 [03:07<13:53,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  91 global step 6158   Batch #:  60 loss:  0.114479564\n",
      "Epoch #:  92 global step 6165   Batch #:  0 loss:  0.0950521\n",
      "Epoch #:  92 global step 6175   Batch #:  10 loss:  0.14817011\n",
      "Epoch #:  92 global step 6185   Batch #:  20 loss:  0.08055132\n",
      "Epoch #:  92 global step 6195   Batch #:  30 loss:  0.07351192\n",
      "Epoch #:  92 global step 6205   Batch #:  40 loss:  0.08386178\n",
      "Epoch #:  92 global step 6215   Batch #:  50 loss:  0.18371838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 19%|█▊        | 93/500 [03:09<13:51,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  92 global step 6225   Batch #:  60 loss:  0.098218165\n",
      "Epoch #:  93 global step 6232   Batch #:  0 loss:  0.11877205\n",
      "Epoch #:  93 global step 6242   Batch #:  10 loss:  0.120876804\n",
      "Epoch #:  93 global step 6252   Batch #:  20 loss:  0.1138537\n",
      "Epoch #:  93 global step 6262   Batch #:  30 loss:  0.044374425\n",
      "Epoch #:  93 global step 6272   Batch #:  40 loss:  0.083389\n",
      "Epoch #:  93 global step 6282   Batch #:  50 loss:  0.14773951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 19%|█▉        | 94/500 [03:11<13:49,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  93 global step 6292   Batch #:  60 loss:  0.097183704\n",
      "Epoch #:  94 global step 6299   Batch #:  0 loss:  0.078896895\n",
      "Epoch #:  94 global step 6309   Batch #:  10 loss:  0.121243045\n",
      "Epoch #:  94 global step 6319   Batch #:  20 loss:  0.18762079\n",
      "Epoch #:  94 global step 6329   Batch #:  30 loss:  0.051006\n",
      "Epoch #:  94 global step 6339   Batch #:  40 loss:  0.11263451\n",
      "Epoch #:  94 global step 6349   Batch #:  50 loss:  0.14629139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 19%|█▉        | 95/500 [03:14<13:47,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  94 global step 6359   Batch #:  60 loss:  0.08902789\n",
      "Epoch #:  95 global step 6366   Batch #:  0 loss:  0.07630858\n",
      "Epoch #:  95 global step 6376   Batch #:  10 loss:  0.07550114\n",
      "Epoch #:  95 global step 6386   Batch #:  20 loss:  0.092560105\n",
      "Epoch #:  95 global step 6396   Batch #:  30 loss:  0.0459568\n",
      "Epoch #:  95 global step 6406   Batch #:  40 loss:  0.10795465\n",
      "Epoch #:  95 global step 6416   Batch #:  50 loss:  0.13433035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 19%|█▉        | 96/500 [03:16<13:44,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  95 global step 6426   Batch #:  60 loss:  0.13175932\n",
      "Epoch #:  96 global step 6433   Batch #:  0 loss:  0.16802928\n",
      "Epoch #:  96 global step 6443   Batch #:  10 loss:  0.16913287\n",
      "Epoch #:  96 global step 6453   Batch #:  20 loss:  0.17718406\n",
      "Epoch #:  96 global step 6463   Batch #:  30 loss:  0.07270007\n",
      "Epoch #:  96 global step 6473   Batch #:  40 loss:  0.49255565\n",
      "Epoch #:  96 global step 6483   Batch #:  50 loss:  0.51451486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 19%|█▉        | 97/500 [03:18<13:42,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  96 global step 6493   Batch #:  60 loss:  0.4978593\n",
      "Epoch #:  97 global step 6500   Batch #:  0 loss:  0.4340964\n",
      "Epoch #:  97 global step 6510   Batch #:  10 loss:  0.5072353\n",
      "Epoch #:  97 global step 6520   Batch #:  20 loss:  0.51091087\n",
      "Epoch #:  97 global step 6530   Batch #:  30 loss:  0.3976856\n",
      "Epoch #:  97 global step 6540   Batch #:  40 loss:  0.35290647\n",
      "Epoch #:  97 global step 6550   Batch #:  50 loss:  0.3042727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 20%|█▉        | 98/500 [03:20<13:40,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  97 global step 6560   Batch #:  60 loss:  0.27275467\n",
      "Epoch #:  98 global step 6567   Batch #:  0 loss:  0.27207783\n",
      "Epoch #:  98 global step 6577   Batch #:  10 loss:  0.2573606\n",
      "Epoch #:  98 global step 6587   Batch #:  20 loss:  0.31076914\n",
      "Epoch #:  98 global step 6597   Batch #:  30 loss:  0.16978133\n",
      "Epoch #:  98 global step 6607   Batch #:  40 loss:  0.18530309\n",
      "Epoch #:  98 global step 6617   Batch #:  50 loss:  0.26964968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 20%|█▉        | 99/500 [03:22<13:38,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  98 global step 6627   Batch #:  60 loss:  0.27544135\n",
      "Epoch #:  99 global step 6634   Batch #:  0 loss:  0.20151256\n",
      "Epoch #:  99 global step 6644   Batch #:  10 loss:  0.19885665\n",
      "Epoch #:  99 global step 6654   Batch #:  20 loss:  0.34078342\n",
      "Epoch #:  99 global step 6664   Batch #:  30 loss:  0.13028793\n",
      "Epoch #:  99 global step 6674   Batch #:  40 loss:  0.20872195\n",
      "Epoch #:  99 global step 6684   Batch #:  50 loss:  0.21897222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 20%|██        | 100/500 [03:24<13:36,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  99 global step 6694   Batch #:  60 loss:  0.20058197\n",
      "Epoch #:  100 global step 6701   Batch #:  0 loss:  0.16120958\n",
      "Epoch #:  100 global step 6711   Batch #:  10 loss:  0.1414046\n",
      "Epoch #:  100 global step 6721   Batch #:  20 loss:  0.20659193\n",
      "Epoch #:  100 global step 6731   Batch #:  30 loss:  0.19366533\n",
      "Epoch #:  100 global step 6741   Batch #:  40 loss:  0.15501016\n",
      "Epoch #:  100 global step 6751   Batch #:  50 loss:  0.20289329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 20%|██        | 101/500 [03:26<13:34,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  100 global step 6761   Batch #:  60 loss:  0.19558986\n",
      "Epoch #:  101 global step 6768   Batch #:  0 loss:  0.19464095\n",
      "Epoch #:  101 global step 6778   Batch #:  10 loss:  0.12944898\n",
      "Epoch #:  101 global step 6788   Batch #:  20 loss:  0.2157412\n",
      "Epoch #:  101 global step 6798   Batch #:  30 loss:  0.12915927\n",
      "Epoch #:  101 global step 6808   Batch #:  40 loss:  0.13334629\n",
      "Epoch #:  101 global step 6818   Batch #:  50 loss:  0.19503212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 20%|██        | 102/500 [03:28<13:32,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  101 global step 6828   Batch #:  60 loss:  0.23790075\n",
      "Epoch #:  102 global step 6835   Batch #:  0 loss:  0.23995006\n",
      "Epoch #:  102 global step 6845   Batch #:  10 loss:  0.17288238\n",
      "Epoch #:  102 global step 6855   Batch #:  20 loss:  0.22413538\n",
      "Epoch #:  102 global step 6865   Batch #:  30 loss:  0.07129237\n",
      "Epoch #:  102 global step 6875   Batch #:  40 loss:  0.10704066\n",
      "Epoch #:  102 global step 6885   Batch #:  50 loss:  0.15899818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 21%|██        | 103/500 [03:30<13:30,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  102 global step 6895   Batch #:  60 loss:  0.1594907\n",
      "Epoch #:  103 global step 6902   Batch #:  0 loss:  0.13023078\n",
      "Epoch #:  103 global step 6912   Batch #:  10 loss:  0.13178304\n",
      "Epoch #:  103 global step 6922   Batch #:  20 loss:  0.14317317\n",
      "Epoch #:  103 global step 6932   Batch #:  30 loss:  0.07561976\n",
      "Epoch #:  103 global step 6942   Batch #:  40 loss:  0.09841401\n",
      "Epoch #:  103 global step 6952   Batch #:  50 loss:  0.13768445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 21%|██        | 104/500 [03:32<13:28,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  103 global step 6962   Batch #:  60 loss:  0.13226403\n",
      "Epoch #:  104 global step 6969   Batch #:  0 loss:  0.12529881\n",
      "Epoch #:  104 global step 6979   Batch #:  10 loss:  0.11751275\n",
      "Epoch #:  104 global step 6989   Batch #:  20 loss:  0.1374965\n",
      "Epoch #:  104 global step 6999   Batch #:  30 loss:  0.058851413\n",
      "Epoch #:  104 global step 7009   Batch #:  40 loss:  0.096447594\n",
      "Epoch #:  104 global step 7019   Batch #:  50 loss:  0.13088627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 21%|██        | 105/500 [03:34<13:26,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  104 global step 7029   Batch #:  60 loss:  0.110448964\n",
      "Epoch #:  105 global step 7036   Batch #:  0 loss:  0.08733454\n",
      "Epoch #:  105 global step 7046   Batch #:  10 loss:  0.12451014\n",
      "Epoch #:  105 global step 7056   Batch #:  20 loss:  0.14951824\n",
      "Epoch #:  105 global step 7066   Batch #:  30 loss:  0.18934877\n",
      "Epoch #:  105 global step 7076   Batch #:  40 loss:  0.22419323\n",
      "Epoch #:  105 global step 7086   Batch #:  50 loss:  0.97271806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 21%|██        | 106/500 [03:36<13:24,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  105 global step 7096   Batch #:  60 loss:  0.6694386\n",
      "Epoch #:  106 global step 7103   Batch #:  0 loss:  0.5768038\n",
      "Epoch #:  106 global step 7113   Batch #:  10 loss:  0.63430864\n",
      "Epoch #:  106 global step 7123   Batch #:  20 loss:  0.5956703\n",
      "Epoch #:  106 global step 7133   Batch #:  30 loss:  0.5588169\n",
      "Epoch #:  106 global step 7143   Batch #:  40 loss:  0.5101919\n",
      "Epoch #:  106 global step 7153   Batch #:  50 loss:  0.46566254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 21%|██▏       | 107/500 [03:38<13:22,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  106 global step 7163   Batch #:  60 loss:  0.49450323\n",
      "Epoch #:  107 global step 7170   Batch #:  0 loss:  0.45712832\n",
      "Epoch #:  107 global step 7180   Batch #:  10 loss:  0.46810108\n",
      "Epoch #:  107 global step 7190   Batch #:  20 loss:  0.5350387\n",
      "Epoch #:  107 global step 7200   Batch #:  30 loss:  0.41537008\n",
      "Epoch #:  107 global step 7210   Batch #:  40 loss:  0.45291945\n",
      "Epoch #:  107 global step 7220   Batch #:  50 loss:  0.41561693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 22%|██▏       | 108/500 [03:40<13:20,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  107 global step 7230   Batch #:  60 loss:  0.38238382\n",
      "Epoch #:  108 global step 7237   Batch #:  0 loss:  0.3780524\n",
      "Epoch #:  108 global step 7247   Batch #:  10 loss:  0.4143519\n",
      "Epoch #:  108 global step 7257   Batch #:  20 loss:  0.4209621\n",
      "Epoch #:  108 global step 7267   Batch #:  30 loss:  0.3093075\n",
      "Epoch #:  108 global step 7277   Batch #:  40 loss:  0.32115376\n",
      "Epoch #:  108 global step 7287   Batch #:  50 loss:  0.32596186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 22%|██▏       | 109/500 [03:42<13:18,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  108 global step 7297   Batch #:  60 loss:  0.28628448\n",
      "Epoch #:  109 global step 7304   Batch #:  0 loss:  0.31663737\n",
      "Epoch #:  109 global step 7314   Batch #:  10 loss:  0.2528537\n",
      "Epoch #:  109 global step 7324   Batch #:  20 loss:  0.34279698\n",
      "Epoch #:  109 global step 7334   Batch #:  30 loss:  0.21916664\n",
      "Epoch #:  109 global step 7344   Batch #:  40 loss:  0.26247117\n",
      "Epoch #:  109 global step 7354   Batch #:  50 loss:  0.31036144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 22%|██▏       | 110/500 [03:44<13:16,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  109 global step 7364   Batch #:  60 loss:  0.23501354\n",
      "Epoch #:  110 global step 7371   Batch #:  0 loss:  0.23973736\n",
      "Epoch #:  110 global step 7381   Batch #:  10 loss:  0.21657833\n",
      "Epoch #:  110 global step 7391   Batch #:  20 loss:  0.28555623\n",
      "Epoch #:  110 global step 7401   Batch #:  30 loss:  0.17661335\n",
      "Epoch #:  110 global step 7411   Batch #:  40 loss:  0.23659696\n",
      "Epoch #:  110 global step 7421   Batch #:  50 loss:  0.28583652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 22%|██▏       | 111/500 [03:46<13:14,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  110 global step 7431   Batch #:  60 loss:  0.22058015\n",
      "Epoch #:  111 global step 7438   Batch #:  0 loss:  0.27247712\n",
      "Epoch #:  111 global step 7448   Batch #:  10 loss:  0.18243524\n",
      "Epoch #:  111 global step 7458   Batch #:  20 loss:  0.3636663\n",
      "Epoch #:  111 global step 7468   Batch #:  30 loss:  0.28734335\n",
      "Epoch #:  111 global step 7478   Batch #:  40 loss:  0.19926266\n",
      "Epoch #:  111 global step 7488   Batch #:  50 loss:  0.26959887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 22%|██▏       | 112/500 [03:48<13:12,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  111 global step 7498   Batch #:  60 loss:  0.23686033\n",
      "Epoch #:  112 global step 7505   Batch #:  0 loss:  0.24082467\n",
      "Epoch #:  112 global step 7515   Batch #:  10 loss:  0.19241452\n",
      "Epoch #:  112 global step 7525   Batch #:  20 loss:  0.24222451\n",
      "Epoch #:  112 global step 7535   Batch #:  30 loss:  0.18315725\n",
      "Epoch #:  112 global step 7545   Batch #:  40 loss:  0.16092752\n",
      "Epoch #:  112 global step 7555   Batch #:  50 loss:  0.21356297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 113/500 [03:50<13:10,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  112 global step 7565   Batch #:  60 loss:  0.17801853\n",
      "Epoch #:  113 global step 7572   Batch #:  0 loss:  0.18898912\n",
      "Epoch #:  113 global step 7582   Batch #:  10 loss:  0.17016795\n",
      "Epoch #:  113 global step 7592   Batch #:  20 loss:  0.21019267\n",
      "Epoch #:  113 global step 7602   Batch #:  30 loss:  0.16260546\n",
      "Epoch #:  113 global step 7612   Batch #:  40 loss:  0.1717918\n",
      "Epoch #:  113 global step 7622   Batch #:  50 loss:  0.19294158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 114/500 [03:52<13:08,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  113 global step 7632   Batch #:  60 loss:  0.215777\n",
      "Epoch #:  114 global step 7639   Batch #:  0 loss:  0.20090684\n",
      "Epoch #:  114 global step 7649   Batch #:  10 loss:  0.147718\n",
      "Epoch #:  114 global step 7659   Batch #:  20 loss:  0.20354408\n",
      "Epoch #:  114 global step 7669   Batch #:  30 loss:  0.13803752\n",
      "Epoch #:  114 global step 7679   Batch #:  40 loss:  0.13605936\n",
      "Epoch #:  114 global step 7689   Batch #:  50 loss:  0.1997325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 115/500 [03:54<13:05,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  114 global step 7699   Batch #:  60 loss:  0.1595446\n",
      "Epoch #:  115 global step 7706   Batch #:  0 loss:  0.17374639\n",
      "Epoch #:  115 global step 7716   Batch #:  10 loss:  0.13379078\n",
      "Epoch #:  115 global step 7726   Batch #:  20 loss:  0.16133143\n",
      "Epoch #:  115 global step 7736   Batch #:  30 loss:  0.11071551\n",
      "Epoch #:  115 global step 7746   Batch #:  40 loss:  0.110080265\n",
      "Epoch #:  115 global step 7756   Batch #:  50 loss:  0.7167918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 116/500 [03:56<13:03,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  115 global step 7766   Batch #:  60 loss:  0.83421564\n",
      "Epoch #:  116 global step 7773   Batch #:  0 loss:  0.47434247\n",
      "Epoch #:  116 global step 7783   Batch #:  10 loss:  0.50296885\n",
      "Epoch #:  116 global step 7793   Batch #:  20 loss:  0.49196622\n",
      "Epoch #:  116 global step 7803   Batch #:  30 loss:  0.28308654\n",
      "Epoch #:  116 global step 7813   Batch #:  40 loss:  0.32853615\n",
      "Epoch #:  116 global step 7823   Batch #:  50 loss:  0.37366793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 117/500 [03:58<13:01,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  116 global step 7833   Batch #:  60 loss:  0.3456831\n",
      "Epoch #:  117 global step 7840   Batch #:  0 loss:  0.27414498\n",
      "Epoch #:  117 global step 7850   Batch #:  10 loss:  0.27685767\n",
      "Epoch #:  117 global step 7860   Batch #:  20 loss:  0.28107426\n",
      "Epoch #:  117 global step 7870   Batch #:  30 loss:  0.1651565\n",
      "Epoch #:  117 global step 7880   Batch #:  40 loss:  0.17551032\n",
      "Epoch #:  117 global step 7890   Batch #:  50 loss:  0.19692992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 24%|██▎       | 118/500 [04:00<12:59,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  117 global step 7900   Batch #:  60 loss:  0.24776453\n",
      "Epoch #:  118 global step 7907   Batch #:  0 loss:  0.25341377\n",
      "Epoch #:  118 global step 7917   Batch #:  10 loss:  0.17173786\n",
      "Epoch #:  118 global step 7927   Batch #:  20 loss:  0.23712188\n",
      "Epoch #:  118 global step 7937   Batch #:  30 loss:  0.096978806\n",
      "Epoch #:  118 global step 7947   Batch #:  40 loss:  0.14159662\n",
      "Epoch #:  118 global step 7957   Batch #:  50 loss:  0.17286465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 24%|██▍       | 119/500 [04:02<12:57,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  118 global step 7967   Batch #:  60 loss:  0.13546579\n",
      "Epoch #:  119 global step 7974   Batch #:  0 loss:  0.2309892\n",
      "Epoch #:  119 global step 7984   Batch #:  10 loss:  0.15081665\n",
      "Epoch #:  119 global step 7994   Batch #:  20 loss:  0.20839287\n",
      "Epoch #:  119 global step 8004   Batch #:  30 loss:  0.09780097\n",
      "Epoch #:  119 global step 8014   Batch #:  40 loss:  0.1139054\n",
      "Epoch #:  119 global step 8024   Batch #:  50 loss:  0.14316055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 24%|██▍       | 120/500 [04:04<12:55,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  119 global step 8034   Batch #:  60 loss:  0.09478531\n",
      "Epoch #:  120 global step 8041   Batch #:  0 loss:  0.21978088\n",
      "Epoch #:  120 global step 8051   Batch #:  10 loss:  0.117372505\n",
      "Epoch #:  120 global step 8061   Batch #:  20 loss:  0.1555768\n",
      "Epoch #:  120 global step 8071   Batch #:  30 loss:  0.058670465\n",
      "Epoch #:  120 global step 8081   Batch #:  40 loss:  0.12470351\n",
      "Epoch #:  120 global step 8091   Batch #:  50 loss:  0.13195121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 24%|██▍       | 121/500 [04:07<12:53,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  120 global step 8101   Batch #:  60 loss:  0.09171111\n",
      "Epoch #:  121 global step 8108   Batch #:  0 loss:  0.19500466\n",
      "Epoch #:  121 global step 8118   Batch #:  10 loss:  0.10360827\n",
      "Epoch #:  121 global step 8128   Batch #:  20 loss:  0.14432734\n",
      "Epoch #:  121 global step 8138   Batch #:  30 loss:  0.0591728\n",
      "Epoch #:  121 global step 8148   Batch #:  40 loss:  0.11231078\n",
      "Epoch #:  121 global step 8158   Batch #:  50 loss:  0.12945187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 24%|██▍       | 122/500 [04:09<12:51,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  121 global step 8168   Batch #:  60 loss:  0.07946516\n",
      "Epoch #:  122 global step 8175   Batch #:  0 loss:  0.1813679\n",
      "Epoch #:  122 global step 8185   Batch #:  10 loss:  0.102401026\n",
      "Epoch #:  122 global step 8195   Batch #:  20 loss:  0.13475439\n",
      "Epoch #:  122 global step 8205   Batch #:  30 loss:  0.05810561\n",
      "Epoch #:  122 global step 8215   Batch #:  40 loss:  0.109893516\n",
      "Epoch #:  122 global step 8225   Batch #:  50 loss:  0.12531239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 25%|██▍       | 123/500 [04:11<12:49,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  122 global step 8235   Batch #:  60 loss:  0.081092246\n",
      "Epoch #:  123 global step 8242   Batch #:  0 loss:  0.15083708\n",
      "Epoch #:  123 global step 8252   Batch #:  10 loss:  0.10221508\n",
      "Epoch #:  123 global step 8262   Batch #:  20 loss:  0.13321874\n",
      "Epoch #:  123 global step 8272   Batch #:  30 loss:  0.054753136\n",
      "Epoch #:  123 global step 8282   Batch #:  40 loss:  0.11009614\n",
      "Epoch #:  123 global step 8292   Batch #:  50 loss:  0.13288073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 25%|██▍       | 124/500 [04:13<12:47,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  123 global step 8302   Batch #:  60 loss:  0.08978882\n",
      "Epoch #:  124 global step 8309   Batch #:  0 loss:  0.1290166\n",
      "Epoch #:  124 global step 8319   Batch #:  10 loss:  0.11010519\n",
      "Epoch #:  124 global step 8329   Batch #:  20 loss:  0.12720804\n",
      "Epoch #:  124 global step 8339   Batch #:  30 loss:  0.058542177\n",
      "Epoch #:  124 global step 8349   Batch #:  40 loss:  0.12285102\n",
      "Epoch #:  124 global step 8359   Batch #:  50 loss:  0.13861488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 125/500 [04:15<12:45,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  124 global step 8369   Batch #:  60 loss:  0.08470805\n",
      "Epoch #:  125 global step 8376   Batch #:  0 loss:  0.11268553\n",
      "Epoch #:  125 global step 8386   Batch #:  10 loss:  0.0978092\n",
      "Epoch #:  125 global step 8396   Batch #:  20 loss:  0.12291338\n",
      "Epoch #:  125 global step 8406   Batch #:  30 loss:  0.063216545\n",
      "Epoch #:  125 global step 8416   Batch #:  40 loss:  0.10361515\n",
      "Epoch #:  125 global step 8426   Batch #:  50 loss:  0.12011551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 126/500 [04:17<12:43,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  125 global step 8436   Batch #:  60 loss:  0.08373811\n",
      "Epoch #:  126 global step 8443   Batch #:  0 loss:  0.12382609\n",
      "Epoch #:  126 global step 8453   Batch #:  10 loss:  0.11432182\n",
      "Epoch #:  126 global step 8463   Batch #:  20 loss:  0.13015963\n",
      "Epoch #:  126 global step 8473   Batch #:  30 loss:  0.06114388\n",
      "Epoch #:  126 global step 8483   Batch #:  40 loss:  0.17445432\n",
      "Epoch #:  126 global step 8493   Batch #:  50 loss:  0.12853645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 127/500 [04:19<12:41,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  126 global step 8503   Batch #:  60 loss:  0.09109048\n",
      "Epoch #:  127 global step 8510   Batch #:  0 loss:  0.10663972\n",
      "Epoch #:  127 global step 8520   Batch #:  10 loss:  0.1089929\n",
      "Epoch #:  127 global step 8530   Batch #:  20 loss:  0.13064843\n",
      "Epoch #:  127 global step 8540   Batch #:  30 loss:  0.058983423\n",
      "Epoch #:  127 global step 8550   Batch #:  40 loss:  0.11086607\n",
      "Epoch #:  127 global step 8560   Batch #:  50 loss:  0.11750714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 26%|██▌       | 128/500 [04:21<12:39,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  127 global step 8570   Batch #:  60 loss:  0.101725176\n",
      "Epoch #:  128 global step 8577   Batch #:  0 loss:  0.10939657\n",
      "Epoch #:  128 global step 8587   Batch #:  10 loss:  0.107255325\n",
      "Epoch #:  128 global step 8597   Batch #:  20 loss:  0.13597456\n",
      "Epoch #:  128 global step 8607   Batch #:  30 loss:  0.055526227\n",
      "Epoch #:  128 global step 8617   Batch #:  40 loss:  0.116709575\n",
      "Epoch #:  128 global step 8627   Batch #:  50 loss:  0.118063904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 26%|██▌       | 129/500 [04:23<12:37,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  128 global step 8637   Batch #:  60 loss:  0.08737898\n",
      "Epoch #:  129 global step 8644   Batch #:  0 loss:  0.1068577\n",
      "Epoch #:  129 global step 8654   Batch #:  10 loss:  0.11013536\n",
      "Epoch #:  129 global step 8664   Batch #:  20 loss:  0.14285038\n",
      "Epoch #:  129 global step 8674   Batch #:  30 loss:  0.05489787\n",
      "Epoch #:  129 global step 8684   Batch #:  40 loss:  0.112188675\n",
      "Epoch #:  129 global step 8694   Batch #:  50 loss:  0.12204234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 26%|██▌       | 130/500 [04:25<12:35,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  129 global step 8704   Batch #:  60 loss:  0.0873994\n",
      "Epoch #:  130 global step 8711   Batch #:  0 loss:  0.100249395\n",
      "Epoch #:  130 global step 8721   Batch #:  10 loss:  0.10115874\n",
      "Epoch #:  130 global step 8731   Batch #:  20 loss:  0.13255833\n",
      "Epoch #:  130 global step 8741   Batch #:  30 loss:  0.05220256\n",
      "Epoch #:  130 global step 8751   Batch #:  40 loss:  0.10655229\n",
      "Epoch #:  130 global step 8761   Batch #:  50 loss:  0.19405746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 26%|██▌       | 131/500 [04:27<12:33,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  130 global step 8771   Batch #:  60 loss:  0.12393204\n",
      "Epoch #:  131 global step 8778   Batch #:  0 loss:  0.10758711\n",
      "Epoch #:  131 global step 8788   Batch #:  10 loss:  0.11842927\n",
      "Epoch #:  131 global step 8798   Batch #:  20 loss:  0.12650824\n",
      "Epoch #:  131 global step 8808   Batch #:  30 loss:  0.0570633\n",
      "Epoch #:  131 global step 8818   Batch #:  40 loss:  0.10822732\n",
      "Epoch #:  131 global step 8828   Batch #:  50 loss:  0.14592808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 26%|██▋       | 132/500 [04:29<12:31,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  131 global step 8838   Batch #:  60 loss:  0.11359068\n",
      "Epoch #:  132 global step 8845   Batch #:  0 loss:  0.1488063\n",
      "Epoch #:  132 global step 8855   Batch #:  10 loss:  0.1292486\n",
      "Epoch #:  132 global step 8865   Batch #:  20 loss:  0.15892477\n",
      "Epoch #:  132 global step 8875   Batch #:  30 loss:  0.12970293\n",
      "Epoch #:  132 global step 8885   Batch #:  40 loss:  0.2471197\n",
      "Epoch #:  132 global step 8895   Batch #:  50 loss:  0.22970328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 133/500 [04:31<12:29,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  132 global step 8905   Batch #:  60 loss:  0.11986694\n",
      "Epoch #:  133 global step 8912   Batch #:  0 loss:  0.16398054\n",
      "Epoch #:  133 global step 8922   Batch #:  10 loss:  0.15266639\n",
      "Epoch #:  133 global step 8932   Batch #:  20 loss:  0.19064975\n",
      "Epoch #:  133 global step 8942   Batch #:  30 loss:  0.07325407\n",
      "Epoch #:  133 global step 8952   Batch #:  40 loss:  0.19000219\n",
      "Epoch #:  133 global step 8962   Batch #:  50 loss:  0.15889658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 134/500 [04:33<12:27,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  133 global step 8972   Batch #:  60 loss:  0.10986849\n",
      "Epoch #:  134 global step 8979   Batch #:  0 loss:  0.11524266\n",
      "Epoch #:  134 global step 8989   Batch #:  10 loss:  0.10758546\n",
      "Epoch #:  134 global step 8999   Batch #:  20 loss:  0.15415718\n",
      "Epoch #:  134 global step 9009   Batch #:  30 loss:  0.054793566\n",
      "Epoch #:  134 global step 9019   Batch #:  40 loss:  0.10679269\n",
      "Epoch #:  134 global step 9029   Batch #:  50 loss:  0.1109171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 135/500 [04:35<12:25,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  134 global step 9039   Batch #:  60 loss:  0.12926961\n",
      "Epoch #:  135 global step 9046   Batch #:  0 loss:  0.120395236\n",
      "Epoch #:  135 global step 9056   Batch #:  10 loss:  0.10237418\n",
      "Epoch #:  135 global step 9066   Batch #:  20 loss:  0.17077565\n",
      "Epoch #:  135 global step 9076   Batch #:  30 loss:  0.060883883\n",
      "Epoch #:  135 global step 9086   Batch #:  40 loss:  0.1339889\n",
      "Epoch #:  135 global step 9096   Batch #:  50 loss:  0.12002263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 136/500 [04:37<12:22,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  135 global step 9106   Batch #:  60 loss:  0.10328854\n",
      "Epoch #:  136 global step 9113   Batch #:  0 loss:  0.10132162\n",
      "Epoch #:  136 global step 9123   Batch #:  10 loss:  0.10185066\n",
      "Epoch #:  136 global step 9133   Batch #:  20 loss:  0.1498285\n",
      "Epoch #:  136 global step 9143   Batch #:  30 loss:  0.05649051\n",
      "Epoch #:  136 global step 9153   Batch #:  40 loss:  0.111689664\n",
      "Epoch #:  136 global step 9163   Batch #:  50 loss:  0.11648585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 137/500 [04:39<12:20,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  136 global step 9173   Batch #:  60 loss:  0.10082285\n",
      "Epoch #:  137 global step 9180   Batch #:  0 loss:  0.09729519\n",
      "Epoch #:  137 global step 9190   Batch #:  10 loss:  0.09929127\n",
      "Epoch #:  137 global step 9200   Batch #:  20 loss:  0.14597157\n",
      "Epoch #:  137 global step 9210   Batch #:  30 loss:  0.05341996\n",
      "Epoch #:  137 global step 9220   Batch #:  40 loss:  0.106512085\n",
      "Epoch #:  137 global step 9230   Batch #:  50 loss:  0.11171638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 138/500 [04:41<12:18,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  137 global step 9240   Batch #:  60 loss:  0.12184276\n",
      "Epoch #:  138 global step 9247   Batch #:  0 loss:  0.13608888\n",
      "Epoch #:  138 global step 9257   Batch #:  10 loss:  0.18475136\n",
      "Epoch #:  138 global step 9267   Batch #:  20 loss:  0.1756517\n",
      "Epoch #:  138 global step 9277   Batch #:  30 loss:  0.119770385\n",
      "Epoch #:  138 global step 9287   Batch #:  40 loss:  0.17336614\n",
      "Epoch #:  138 global step 9297   Batch #:  50 loss:  0.14573543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 139/500 [04:43<12:16,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  138 global step 9307   Batch #:  60 loss:  0.10159347\n",
      "Epoch #:  139 global step 9314   Batch #:  0 loss:  0.27978104\n",
      "Epoch #:  139 global step 9324   Batch #:  10 loss:  0.13735567\n",
      "Epoch #:  139 global step 9334   Batch #:  20 loss:  0.14144138\n",
      "Epoch #:  139 global step 9344   Batch #:  30 loss:  0.09036462\n",
      "Epoch #:  139 global step 9354   Batch #:  40 loss:  0.13434146\n",
      "Epoch #:  139 global step 9364   Batch #:  50 loss:  0.12708794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 140/500 [04:45<12:14,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  139 global step 9374   Batch #:  60 loss:  0.09976413\n",
      "Epoch #:  140 global step 9381   Batch #:  0 loss:  0.09818838\n",
      "Epoch #:  140 global step 9391   Batch #:  10 loss:  0.0835648\n",
      "Epoch #:  140 global step 9401   Batch #:  20 loss:  0.14087477\n",
      "Epoch #:  140 global step 9411   Batch #:  30 loss:  0.07092416\n",
      "Epoch #:  140 global step 9421   Batch #:  40 loss:  0.12702465\n",
      "Epoch #:  140 global step 9431   Batch #:  50 loss:  0.2135533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 141/500 [04:47<12:12,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  140 global step 9441   Batch #:  60 loss:  0.16329452\n",
      "Epoch #:  141 global step 9448   Batch #:  0 loss:  0.193802\n",
      "Epoch #:  141 global step 9458   Batch #:  10 loss:  0.1608993\n",
      "Epoch #:  141 global step 9468   Batch #:  20 loss:  0.27190176\n",
      "Epoch #:  141 global step 9478   Batch #:  30 loss:  0.09610593\n",
      "Epoch #:  141 global step 9488   Batch #:  40 loss:  0.17456023\n",
      "Epoch #:  141 global step 9498   Batch #:  50 loss:  0.170097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 142/500 [04:49<12:10,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  141 global step 9508   Batch #:  60 loss:  0.18782829\n",
      "Epoch #:  142 global step 9515   Batch #:  0 loss:  0.1356015\n",
      "Epoch #:  142 global step 9525   Batch #:  10 loss:  0.15800533\n",
      "Epoch #:  142 global step 9535   Batch #:  20 loss:  0.14761187\n",
      "Epoch #:  142 global step 9545   Batch #:  30 loss:  0.053809974\n",
      "Epoch #:  142 global step 9555   Batch #:  40 loss:  0.12560266\n",
      "Epoch #:  142 global step 9565   Batch #:  50 loss:  0.12394958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 29%|██▊       | 143/500 [04:51<12:08,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  142 global step 9575   Batch #:  60 loss:  0.0878374\n",
      "Epoch #:  143 global step 9582   Batch #:  0 loss:  0.08853144\n",
      "Epoch #:  143 global step 9592   Batch #:  10 loss:  0.107970856\n",
      "Epoch #:  143 global step 9602   Batch #:  20 loss:  0.13495485\n",
      "Epoch #:  143 global step 9612   Batch #:  30 loss:  0.0425905\n",
      "Epoch #:  143 global step 9622   Batch #:  40 loss:  0.11891154\n",
      "Epoch #:  143 global step 9632   Batch #:  50 loss:  0.10890526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 29%|██▉       | 144/500 [04:53<12:06,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  143 global step 9642   Batch #:  60 loss:  0.08076363\n",
      "Epoch #:  144 global step 9649   Batch #:  0 loss:  0.079325765\n",
      "Epoch #:  144 global step 9659   Batch #:  10 loss:  0.119069375\n",
      "Epoch #:  144 global step 9669   Batch #:  20 loss:  0.13178931\n",
      "Epoch #:  144 global step 9679   Batch #:  30 loss:  0.04266869\n",
      "Epoch #:  144 global step 9689   Batch #:  40 loss:  0.117413804\n",
      "Epoch #:  144 global step 9699   Batch #:  50 loss:  0.108418465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 29%|██▉       | 145/500 [04:55<12:04,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  144 global step 9709   Batch #:  60 loss:  0.08378612\n",
      "Epoch #:  145 global step 9716   Batch #:  0 loss:  0.069978826\n",
      "Epoch #:  145 global step 9726   Batch #:  10 loss:  0.09177897\n",
      "Epoch #:  145 global step 9736   Batch #:  20 loss:  0.13284634\n",
      "Epoch #:  145 global step 9746   Batch #:  30 loss:  0.050277863\n",
      "Epoch #:  145 global step 9756   Batch #:  40 loss:  0.11511182\n",
      "Epoch #:  145 global step 9766   Batch #:  50 loss:  0.11615883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 29%|██▉       | 146/500 [04:57<12:02,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  145 global step 9776   Batch #:  60 loss:  0.081580326\n",
      "Epoch #:  146 global step 9783   Batch #:  0 loss:  0.07136846\n",
      "Epoch #:  146 global step 9793   Batch #:  10 loss:  0.08976049\n",
      "Epoch #:  146 global step 9803   Batch #:  20 loss:  0.1289191\n",
      "Epoch #:  146 global step 9813   Batch #:  30 loss:  0.045253783\n",
      "Epoch #:  146 global step 9823   Batch #:  40 loss:  0.113719836\n",
      "Epoch #:  146 global step 9833   Batch #:  50 loss:  0.11105098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 29%|██▉       | 147/500 [04:59<12:00,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  146 global step 9843   Batch #:  60 loss:  0.08301303\n",
      "Epoch #:  147 global step 9850   Batch #:  0 loss:  0.06709802\n",
      "Epoch #:  147 global step 9860   Batch #:  10 loss:  0.08988601\n",
      "Epoch #:  147 global step 9870   Batch #:  20 loss:  0.11880829\n",
      "Epoch #:  147 global step 9880   Batch #:  30 loss:  0.045458585\n",
      "Epoch #:  147 global step 9890   Batch #:  40 loss:  0.10826471\n",
      "Epoch #:  147 global step 9900   Batch #:  50 loss:  0.106068596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 30%|██▉       | 148/500 [05:02<11:58,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  147 global step 9910   Batch #:  60 loss:  0.08442698\n",
      "Epoch #:  148 global step 9917   Batch #:  0 loss:  0.06324385\n",
      "Epoch #:  148 global step 9927   Batch #:  10 loss:  0.0879375\n",
      "Epoch #:  148 global step 9937   Batch #:  20 loss:  0.1195282\n",
      "Epoch #:  148 global step 9947   Batch #:  30 loss:  0.04261663\n",
      "Epoch #:  148 global step 9957   Batch #:  40 loss:  0.10730845\n",
      "Epoch #:  148 global step 9967   Batch #:  50 loss:  0.10590197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 30%|██▉       | 149/500 [05:04<11:56,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  148 global step 9977   Batch #:  60 loss:  0.0803636\n",
      "Epoch #:  149 global step 9984   Batch #:  0 loss:  0.06134702\n",
      "Epoch #:  149 global step 9994   Batch #:  10 loss:  0.0940097\n",
      "Epoch #:  149 global step 10004   Batch #:  20 loss:  0.11690705\n",
      "Epoch #:  149 global step 10014   Batch #:  30 loss:  0.042975526\n",
      "Epoch #:  149 global step 10024   Batch #:  40 loss:  0.10620271\n",
      "Epoch #:  149 global step 10034   Batch #:  50 loss:  0.097280554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 30%|███       | 150/500 [05:06<11:54,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  149 global step 10044   Batch #:  60 loss:  0.083515935\n",
      "Epoch #:  150 global step 10051   Batch #:  0 loss:  0.06463167\n",
      "Epoch #:  150 global step 10061   Batch #:  10 loss:  0.087043144\n",
      "Epoch #:  150 global step 10071   Batch #:  20 loss:  0.1178704\n",
      "Epoch #:  150 global step 10081   Batch #:  30 loss:  0.04280198\n",
      "Epoch #:  150 global step 10091   Batch #:  40 loss:  0.10480266\n",
      "Epoch #:  150 global step 10101   Batch #:  50 loss:  0.09212557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 30%|███       | 151/500 [05:08<11:52,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  150 global step 10111   Batch #:  60 loss:  0.08045052\n",
      "Epoch #:  151 global step 10118   Batch #:  0 loss:  0.062315907\n",
      "Epoch #:  151 global step 10128   Batch #:  10 loss:  0.08964695\n",
      "Epoch #:  151 global step 10138   Batch #:  20 loss:  0.11455235\n",
      "Epoch #:  151 global step 10148   Batch #:  30 loss:  0.047464546\n",
      "Epoch #:  151 global step 10158   Batch #:  40 loss:  0.103024594\n",
      "Epoch #:  151 global step 10168   Batch #:  50 loss:  0.09331985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 30%|███       | 152/500 [05:10<11:50,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  151 global step 10178   Batch #:  60 loss:  0.07944047\n",
      "Epoch #:  152 global step 10185   Batch #:  0 loss:  0.060572762\n",
      "Epoch #:  152 global step 10195   Batch #:  10 loss:  0.08749173\n",
      "Epoch #:  152 global step 10205   Batch #:  20 loss:  0.11481821\n",
      "Epoch #:  152 global step 10215   Batch #:  30 loss:  0.04242943\n",
      "Epoch #:  152 global step 10225   Batch #:  40 loss:  0.10271986\n",
      "Epoch #:  152 global step 10235   Batch #:  50 loss:  0.10001318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 31%|███       | 153/500 [05:12<11:48,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  152 global step 10245   Batch #:  60 loss:  0.08034111\n",
      "Epoch #:  153 global step 10252   Batch #:  0 loss:  0.059791192\n",
      "Epoch #:  153 global step 10262   Batch #:  10 loss:  0.08581974\n",
      "Epoch #:  153 global step 10272   Batch #:  20 loss:  0.113711506\n",
      "Epoch #:  153 global step 10282   Batch #:  30 loss:  0.043436203\n",
      "Epoch #:  153 global step 10292   Batch #:  40 loss:  0.10354514\n",
      "Epoch #:  153 global step 10302   Batch #:  50 loss:  0.10279006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 31%|███       | 154/500 [05:14<11:45,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  153 global step 10312   Batch #:  60 loss:  0.08880931\n",
      "Epoch #:  154 global step 10319   Batch #:  0 loss:  0.063547306\n",
      "Epoch #:  154 global step 10329   Batch #:  10 loss:  0.09077158\n",
      "Epoch #:  154 global step 10339   Batch #:  20 loss:  0.11420636\n",
      "Epoch #:  154 global step 10349   Batch #:  30 loss:  0.042670365\n",
      "Epoch #:  154 global step 10359   Batch #:  40 loss:  0.10010666\n",
      "Epoch #:  154 global step 10369   Batch #:  50 loss:  0.09445733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 31%|███       | 155/500 [05:16<11:43,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  154 global step 10379   Batch #:  60 loss:  0.0875473\n",
      "Epoch #:  155 global step 10386   Batch #:  0 loss:  0.060106087\n",
      "Epoch #:  155 global step 10396   Batch #:  10 loss:  0.083752066\n",
      "Epoch #:  155 global step 10406   Batch #:  20 loss:  0.11289316\n",
      "Epoch #:  155 global step 10416   Batch #:  30 loss:  0.04168613\n",
      "Epoch #:  155 global step 10426   Batch #:  40 loss:  0.09944435\n",
      "Epoch #:  155 global step 10436   Batch #:  50 loss:  0.10724964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 31%|███       | 156/500 [05:18<11:41,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  155 global step 10446   Batch #:  60 loss:  0.08979695\n",
      "Epoch #:  156 global step 10453   Batch #:  0 loss:  0.054388635\n",
      "Epoch #:  156 global step 10463   Batch #:  10 loss:  0.07815139\n",
      "Epoch #:  156 global step 10473   Batch #:  20 loss:  0.11352117\n",
      "Epoch #:  156 global step 10483   Batch #:  30 loss:  0.040780507\n",
      "Epoch #:  156 global step 10493   Batch #:  40 loss:  0.099154145\n",
      "Epoch #:  156 global step 10503   Batch #:  50 loss:  0.09497118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 31%|███▏      | 157/500 [05:20<11:39,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  156 global step 10513   Batch #:  60 loss:  0.08452049\n",
      "Epoch #:  157 global step 10520   Batch #:  0 loss:  0.05263929\n",
      "Epoch #:  157 global step 10530   Batch #:  10 loss:  0.0759775\n",
      "Epoch #:  157 global step 10540   Batch #:  20 loss:  0.11491314\n",
      "Epoch #:  157 global step 10550   Batch #:  30 loss:  0.04147564\n",
      "Epoch #:  157 global step 10560   Batch #:  40 loss:  0.094998695\n",
      "Epoch #:  157 global step 10570   Batch #:  50 loss:  0.100666545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 32%|███▏      | 158/500 [05:22<11:37,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  157 global step 10580   Batch #:  60 loss:  0.1850836\n",
      "Epoch #:  158 global step 10587   Batch #:  0 loss:  0.13110384\n",
      "Epoch #:  158 global step 10597   Batch #:  10 loss:  0.09129843\n",
      "Epoch #:  158 global step 10607   Batch #:  20 loss:  0.1223007\n",
      "Epoch #:  158 global step 10617   Batch #:  30 loss:  0.10894116\n",
      "Epoch #:  158 global step 10627   Batch #:  40 loss:  0.13471925\n",
      "Epoch #:  158 global step 10637   Batch #:  50 loss:  0.17532445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 32%|███▏      | 159/500 [05:24<11:35,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  158 global step 10647   Batch #:  60 loss:  0.10832454\n",
      "Epoch #:  159 global step 10654   Batch #:  0 loss:  0.1094827\n",
      "Epoch #:  159 global step 10664   Batch #:  10 loss:  0.10509161\n",
      "Epoch #:  159 global step 10674   Batch #:  20 loss:  0.14246239\n",
      "Epoch #:  159 global step 10684   Batch #:  30 loss:  0.05339296\n",
      "Epoch #:  159 global step 10694   Batch #:  40 loss:  0.11566566\n",
      "Epoch #:  159 global step 10704   Batch #:  50 loss:  0.09836001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 32%|███▏      | 160/500 [05:26<11:33,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  159 global step 10714   Batch #:  60 loss:  0.08564077\n",
      "Epoch #:  160 global step 10721   Batch #:  0 loss:  0.18855642\n",
      "Epoch #:  160 global step 10731   Batch #:  10 loss:  0.23722234\n",
      "Epoch #:  160 global step 10741   Batch #:  20 loss:  0.20559826\n",
      "Epoch #:  160 global step 10751   Batch #:  30 loss:  0.06940775\n",
      "Epoch #:  160 global step 10761   Batch #:  40 loss:  0.10881165\n",
      "Epoch #:  160 global step 10771   Batch #:  50 loss:  0.107667886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 32%|███▏      | 161/500 [05:28<11:31,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  160 global step 10781   Batch #:  60 loss:  0.09770903\n",
      "Epoch #:  161 global step 10788   Batch #:  0 loss:  0.07972104\n",
      "Epoch #:  161 global step 10798   Batch #:  10 loss:  0.06426401\n",
      "Epoch #:  161 global step 10808   Batch #:  20 loss:  0.13053435\n",
      "Epoch #:  161 global step 10818   Batch #:  30 loss:  0.055682886\n",
      "Epoch #:  161 global step 10828   Batch #:  40 loss:  0.118457325\n",
      "Epoch #:  161 global step 10838   Batch #:  50 loss:  0.116671436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 32%|███▏      | 162/500 [05:30<11:29,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  161 global step 10848   Batch #:  60 loss:  0.09300921\n",
      "Epoch #:  162 global step 10855   Batch #:  0 loss:  0.070010096\n",
      "Epoch #:  162 global step 10865   Batch #:  10 loss:  0.06431752\n",
      "Epoch #:  162 global step 10875   Batch #:  20 loss:  0.12946549\n",
      "Epoch #:  162 global step 10885   Batch #:  30 loss:  0.051073663\n",
      "Epoch #:  162 global step 10895   Batch #:  40 loss:  0.10418426\n",
      "Epoch #:  162 global step 10905   Batch #:  50 loss:  0.115393385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 163/500 [05:32<11:27,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  162 global step 10915   Batch #:  60 loss:  0.08729374\n",
      "Epoch #:  163 global step 10922   Batch #:  0 loss:  0.07462387\n",
      "Epoch #:  163 global step 10932   Batch #:  10 loss:  0.060626037\n",
      "Epoch #:  163 global step 10942   Batch #:  20 loss:  0.12480277\n",
      "Epoch #:  163 global step 10952   Batch #:  30 loss:  0.050892472\n",
      "Epoch #:  163 global step 10962   Batch #:  40 loss:  0.10045463\n",
      "Epoch #:  163 global step 10972   Batch #:  50 loss:  0.10938394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 164/500 [05:34<11:25,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  163 global step 10982   Batch #:  60 loss:  0.09241143\n",
      "Epoch #:  164 global step 10989   Batch #:  0 loss:  0.07204961\n",
      "Epoch #:  164 global step 10999   Batch #:  10 loss:  0.067732684\n",
      "Epoch #:  164 global step 11009   Batch #:  20 loss:  0.118694626\n",
      "Epoch #:  164 global step 11019   Batch #:  30 loss:  0.056730144\n",
      "Epoch #:  164 global step 11029   Batch #:  40 loss:  0.1144167\n",
      "Epoch #:  164 global step 11039   Batch #:  50 loss:  0.10655648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 165/500 [05:36<11:23,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  164 global step 11049   Batch #:  60 loss:  0.094606034\n",
      "Epoch #:  165 global step 11056   Batch #:  0 loss:  0.06445775\n",
      "Epoch #:  165 global step 11066   Batch #:  10 loss:  0.05557568\n",
      "Epoch #:  165 global step 11076   Batch #:  20 loss:  0.12481798\n",
      "Epoch #:  165 global step 11086   Batch #:  30 loss:  0.04775013\n",
      "Epoch #:  165 global step 11096   Batch #:  40 loss:  0.10567415\n",
      "Epoch #:  165 global step 11106   Batch #:  50 loss:  0.10697922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 166/500 [05:38<11:21,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  165 global step 11116   Batch #:  60 loss:  0.08752611\n",
      "Epoch #:  166 global step 11123   Batch #:  0 loss:  0.06010646\n",
      "Epoch #:  166 global step 11133   Batch #:  10 loss:  0.059822917\n",
      "Epoch #:  166 global step 11143   Batch #:  20 loss:  0.11947695\n",
      "Epoch #:  166 global step 11153   Batch #:  30 loss:  0.04758135\n",
      "Epoch #:  166 global step 11163   Batch #:  40 loss:  0.103875175\n",
      "Epoch #:  166 global step 11173   Batch #:  50 loss:  0.10134609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 167/500 [05:40<11:19,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  166 global step 11183   Batch #:  60 loss:  0.08633043\n",
      "Epoch #:  167 global step 11190   Batch #:  0 loss:  0.062197022\n",
      "Epoch #:  167 global step 11200   Batch #:  10 loss:  0.048494156\n",
      "Epoch #:  167 global step 11210   Batch #:  20 loss:  0.116787225\n",
      "Epoch #:  167 global step 11220   Batch #:  30 loss:  0.044366777\n",
      "Epoch #:  167 global step 11230   Batch #:  40 loss:  0.10290382\n",
      "Epoch #:  167 global step 11240   Batch #:  50 loss:  0.10414118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 34%|███▎      | 168/500 [05:42<11:17,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  167 global step 11250   Batch #:  60 loss:  0.08578817\n",
      "Epoch #:  168 global step 11257   Batch #:  0 loss:  0.05862648\n",
      "Epoch #:  168 global step 11267   Batch #:  10 loss:  0.050810687\n",
      "Epoch #:  168 global step 11277   Batch #:  20 loss:  0.11147095\n",
      "Epoch #:  168 global step 11287   Batch #:  30 loss:  0.04412012\n",
      "Epoch #:  168 global step 11297   Batch #:  40 loss:  0.102058336\n",
      "Epoch #:  168 global step 11307   Batch #:  50 loss:  0.10138304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 34%|███▍      | 169/500 [05:44<11:15,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  168 global step 11317   Batch #:  60 loss:  0.085034035\n",
      "Epoch #:  169 global step 11324   Batch #:  0 loss:  0.0616043\n",
      "Epoch #:  169 global step 11334   Batch #:  10 loss:  0.049321223\n",
      "Epoch #:  169 global step 11344   Batch #:  20 loss:  0.10642804\n",
      "Epoch #:  169 global step 11354   Batch #:  30 loss:  0.042304073\n",
      "Epoch #:  169 global step 11364   Batch #:  40 loss:  0.10108712\n",
      "Epoch #:  169 global step 11374   Batch #:  50 loss:  0.10149419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 34%|███▍      | 170/500 [05:46<11:13,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  169 global step 11384   Batch #:  60 loss:  0.09020941\n",
      "Epoch #:  170 global step 11391   Batch #:  0 loss:  0.059980236\n",
      "Epoch #:  170 global step 11401   Batch #:  10 loss:  0.04605149\n",
      "Epoch #:  170 global step 11411   Batch #:  20 loss:  0.10537626\n",
      "Epoch #:  170 global step 11421   Batch #:  30 loss:  0.043156337\n",
      "Epoch #:  170 global step 11431   Batch #:  40 loss:  0.09962038\n",
      "Epoch #:  170 global step 11441   Batch #:  50 loss:  0.10333349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 34%|███▍      | 171/500 [05:48<11:11,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  170 global step 11451   Batch #:  60 loss:  0.09015001\n",
      "Epoch #:  171 global step 11458   Batch #:  0 loss:  0.06261831\n",
      "Epoch #:  171 global step 11468   Batch #:  10 loss:  0.052045494\n",
      "Epoch #:  171 global step 11478   Batch #:  20 loss:  0.10481339\n",
      "Epoch #:  171 global step 11488   Batch #:  30 loss:  0.044238944\n",
      "Epoch #:  171 global step 11498   Batch #:  40 loss:  0.10041384\n",
      "Epoch #:  171 global step 11508   Batch #:  50 loss:  0.100735664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 34%|███▍      | 172/500 [05:50<11:09,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  171 global step 11518   Batch #:  60 loss:  0.08996044\n",
      "Epoch #:  172 global step 11525   Batch #:  0 loss:  0.059245355\n",
      "Epoch #:  172 global step 11535   Batch #:  10 loss:  0.05650645\n",
      "Epoch #:  172 global step 11545   Batch #:  20 loss:  0.10125725\n",
      "Epoch #:  172 global step 11555   Batch #:  30 loss:  0.04129181\n",
      "Epoch #:  172 global step 11565   Batch #:  40 loss:  0.096903406\n",
      "Epoch #:  172 global step 11575   Batch #:  50 loss:  0.09873358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 35%|███▍      | 173/500 [05:52<11:06,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  172 global step 11585   Batch #:  60 loss:  0.08042955\n",
      "Epoch #:  173 global step 11592   Batch #:  0 loss:  0.058234595\n",
      "Epoch #:  173 global step 11602   Batch #:  10 loss:  0.05168737\n",
      "Epoch #:  173 global step 11612   Batch #:  20 loss:  0.10022804\n",
      "Epoch #:  173 global step 11622   Batch #:  30 loss:  0.041570622\n",
      "Epoch #:  173 global step 11632   Batch #:  40 loss:  0.098411314\n",
      "Epoch #:  173 global step 11642   Batch #:  50 loss:  0.102596454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 35%|███▍      | 174/500 [05:54<11:04,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  173 global step 11652   Batch #:  60 loss:  0.083527096\n",
      "Epoch #:  174 global step 11659   Batch #:  0 loss:  0.06414753\n",
      "Epoch #:  174 global step 11669   Batch #:  10 loss:  0.043976586\n",
      "Epoch #:  174 global step 11679   Batch #:  20 loss:  0.0865236\n",
      "Epoch #:  174 global step 11689   Batch #:  30 loss:  0.042491667\n",
      "Epoch #:  174 global step 11699   Batch #:  40 loss:  0.090735726\n",
      "Epoch #:  174 global step 11709   Batch #:  50 loss:  0.10006528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 35%|███▌      | 175/500 [05:56<11:02,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  174 global step 11719   Batch #:  60 loss:  0.08206444\n",
      "Epoch #:  175 global step 11726   Batch #:  0 loss:  0.06393329\n",
      "Epoch #:  175 global step 11736   Batch #:  10 loss:  0.05189079\n",
      "Epoch #:  175 global step 11746   Batch #:  20 loss:  0.08496176\n",
      "Epoch #:  175 global step 11756   Batch #:  30 loss:  0.049025826\n",
      "Epoch #:  175 global step 11766   Batch #:  40 loss:  0.08900813\n",
      "Epoch #:  175 global step 11776   Batch #:  50 loss:  0.100482225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 35%|███▌      | 176/500 [05:58<11:00,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  175 global step 11786   Batch #:  60 loss:  0.08185606\n",
      "Epoch #:  176 global step 11793   Batch #:  0 loss:  0.061812706\n",
      "Epoch #:  176 global step 11803   Batch #:  10 loss:  0.044579707\n",
      "Epoch #:  176 global step 11813   Batch #:  20 loss:  0.086519375\n",
      "Epoch #:  176 global step 11823   Batch #:  30 loss:  0.044105228\n",
      "Epoch #:  176 global step 11833   Batch #:  40 loss:  0.0900987\n",
      "Epoch #:  176 global step 11843   Batch #:  50 loss:  0.09752802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 35%|███▌      | 177/500 [06:01<10:58,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  176 global step 11853   Batch #:  60 loss:  0.0837807\n",
      "Epoch #:  177 global step 11860   Batch #:  0 loss:  0.0719195\n",
      "Epoch #:  177 global step 11870   Batch #:  10 loss:  0.05527165\n",
      "Epoch #:  177 global step 11880   Batch #:  20 loss:  0.080387324\n",
      "Epoch #:  177 global step 11890   Batch #:  30 loss:  0.0404758\n",
      "Epoch #:  177 global step 11900   Batch #:  40 loss:  0.08702945\n",
      "Epoch #:  177 global step 11910   Batch #:  50 loss:  0.100749515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 178/500 [06:03<10:56,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  177 global step 11920   Batch #:  60 loss:  0.07945341\n",
      "Epoch #:  178 global step 11927   Batch #:  0 loss:  0.06460234\n",
      "Epoch #:  178 global step 11937   Batch #:  10 loss:  0.046065744\n",
      "Epoch #:  178 global step 11947   Batch #:  20 loss:  0.0826611\n",
      "Epoch #:  178 global step 11957   Batch #:  30 loss:  0.044539437\n",
      "Epoch #:  178 global step 11967   Batch #:  40 loss:  0.08716011\n",
      "Epoch #:  178 global step 11977   Batch #:  50 loss:  0.09865345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 179/500 [06:05<10:54,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  178 global step 11987   Batch #:  60 loss:  0.0788156\n",
      "Epoch #:  179 global step 11994   Batch #:  0 loss:  0.062392335\n",
      "Epoch #:  179 global step 12004   Batch #:  10 loss:  0.046768077\n",
      "Epoch #:  179 global step 12014   Batch #:  20 loss:  0.07654865\n",
      "Epoch #:  179 global step 12024   Batch #:  30 loss:  0.045233484\n",
      "Epoch #:  179 global step 12034   Batch #:  40 loss:  0.079413205\n",
      "Epoch #:  179 global step 12044   Batch #:  50 loss:  0.0817119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 180/500 [06:07<10:52,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  179 global step 12054   Batch #:  60 loss:  0.07863126\n",
      "Epoch #:  180 global step 12061   Batch #:  0 loss:  0.06623848\n",
      "Epoch #:  180 global step 12071   Batch #:  10 loss:  0.048362352\n",
      "Epoch #:  180 global step 12081   Batch #:  20 loss:  0.0730608\n",
      "Epoch #:  180 global step 12091   Batch #:  30 loss:  0.036111224\n",
      "Epoch #:  180 global step 12101   Batch #:  40 loss:  0.08567096\n",
      "Epoch #:  180 global step 12111   Batch #:  50 loss:  0.08029511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 181/500 [06:09<10:50,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  180 global step 12121   Batch #:  60 loss:  0.085313566\n",
      "Epoch #:  181 global step 12128   Batch #:  0 loss:  0.0595211\n",
      "Epoch #:  181 global step 12138   Batch #:  10 loss:  0.051396213\n",
      "Epoch #:  181 global step 12148   Batch #:  20 loss:  0.07803589\n",
      "Epoch #:  181 global step 12158   Batch #:  30 loss:  0.040124033\n",
      "Epoch #:  181 global step 12168   Batch #:  40 loss:  0.08271783\n",
      "Epoch #:  181 global step 12178   Batch #:  50 loss:  0.07617777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 36%|███▋      | 182/500 [06:11<10:48,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  181 global step 12188   Batch #:  60 loss:  0.084514104\n",
      "Epoch #:  182 global step 12195   Batch #:  0 loss:  0.06602922\n",
      "Epoch #:  182 global step 12205   Batch #:  10 loss:  0.05916819\n",
      "Epoch #:  182 global step 12215   Batch #:  20 loss:  0.07740006\n",
      "Epoch #:  182 global step 12225   Batch #:  30 loss:  0.045809515\n",
      "Epoch #:  182 global step 12235   Batch #:  40 loss:  0.08598363\n",
      "Epoch #:  182 global step 12245   Batch #:  50 loss:  0.07425367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 37%|███▋      | 183/500 [06:13<10:46,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  182 global step 12255   Batch #:  60 loss:  0.07971547\n",
      "Epoch #:  183 global step 12262   Batch #:  0 loss:  0.06266883\n",
      "Epoch #:  183 global step 12272   Batch #:  10 loss:  0.050403498\n",
      "Epoch #:  183 global step 12282   Batch #:  20 loss:  0.0716247\n",
      "Epoch #:  183 global step 12292   Batch #:  30 loss:  0.038890794\n",
      "Epoch #:  183 global step 12302   Batch #:  40 loss:  0.08961439\n",
      "Epoch #:  183 global step 12312   Batch #:  50 loss:  0.080018096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 37%|███▋      | 184/500 [06:15<10:44,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  183 global step 12322   Batch #:  60 loss:  0.078080975\n",
      "Epoch #:  184 global step 12329   Batch #:  0 loss:  0.06426717\n",
      "Epoch #:  184 global step 12339   Batch #:  10 loss:  0.050574135\n",
      "Epoch #:  184 global step 12349   Batch #:  20 loss:  0.07713095\n",
      "Epoch #:  184 global step 12359   Batch #:  30 loss:  0.039717674\n",
      "Epoch #:  184 global step 12369   Batch #:  40 loss:  0.08872867\n",
      "Epoch #:  184 global step 12379   Batch #:  50 loss:  0.07633775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 37%|███▋      | 185/500 [06:17<10:42,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  184 global step 12389   Batch #:  60 loss:  0.078113966\n",
      "Epoch #:  185 global step 12396   Batch #:  0 loss:  0.06849289\n",
      "Epoch #:  185 global step 12406   Batch #:  10 loss:  0.050352577\n",
      "Epoch #:  185 global step 12416   Batch #:  20 loss:  0.07902751\n",
      "Epoch #:  185 global step 12426   Batch #:  30 loss:  0.08085455\n",
      "Epoch #:  185 global step 12436   Batch #:  40 loss:  0.17274852\n",
      "Epoch #:  185 global step 12446   Batch #:  50 loss:  0.16951111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 37%|███▋      | 186/500 [06:19<10:40,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  185 global step 12456   Batch #:  60 loss:  0.2814033\n",
      "Epoch #:  186 global step 12463   Batch #:  0 loss:  0.1681183\n",
      "Epoch #:  186 global step 12473   Batch #:  10 loss:  0.1976591\n",
      "Epoch #:  186 global step 12483   Batch #:  20 loss:  0.2234171\n",
      "Epoch #:  186 global step 12493   Batch #:  30 loss:  0.11522059\n",
      "Epoch #:  186 global step 12503   Batch #:  40 loss:  0.49154755\n",
      "Epoch #:  186 global step 12513   Batch #:  50 loss:  0.23040585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 37%|███▋      | 187/500 [06:21<10:38,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  186 global step 12523   Batch #:  60 loss:  0.16056715\n",
      "Epoch #:  187 global step 12530   Batch #:  0 loss:  0.11895136\n",
      "Epoch #:  187 global step 12540   Batch #:  10 loss:  0.11254276\n",
      "Epoch #:  187 global step 12550   Batch #:  20 loss:  0.19540118\n",
      "Epoch #:  187 global step 12560   Batch #:  30 loss:  0.5298454\n",
      "Epoch #:  187 global step 12570   Batch #:  40 loss:  0.446335\n",
      "Epoch #:  187 global step 12580   Batch #:  50 loss:  0.3743228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 188/500 [06:23<10:36,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  187 global step 12590   Batch #:  60 loss:  0.3464194\n",
      "Epoch #:  188 global step 12597   Batch #:  0 loss:  0.2979058\n",
      "Epoch #:  188 global step 12607   Batch #:  10 loss:  0.2519413\n",
      "Epoch #:  188 global step 12617   Batch #:  20 loss:  0.26933357\n",
      "Epoch #:  188 global step 12627   Batch #:  30 loss:  0.15554625\n",
      "Epoch #:  188 global step 12637   Batch #:  40 loss:  0.1501842\n",
      "Epoch #:  188 global step 12647   Batch #:  50 loss:  0.21974331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 189/500 [06:25<10:34,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  188 global step 12657   Batch #:  60 loss:  0.15818763\n",
      "Epoch #:  189 global step 12664   Batch #:  0 loss:  0.18061322\n",
      "Epoch #:  189 global step 12674   Batch #:  10 loss:  0.13540481\n",
      "Epoch #:  189 global step 12684   Batch #:  20 loss:  0.29810068\n",
      "Epoch #:  189 global step 12694   Batch #:  30 loss:  0.18371932\n",
      "Epoch #:  189 global step 12704   Batch #:  40 loss:  0.1377725\n",
      "Epoch #:  189 global step 12714   Batch #:  50 loss:  0.18663725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 190/500 [06:27<10:32,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  189 global step 12724   Batch #:  60 loss:  0.0972911\n",
      "Epoch #:  190 global step 12731   Batch #:  0 loss:  0.14308247\n",
      "Epoch #:  190 global step 12741   Batch #:  10 loss:  0.1300489\n",
      "Epoch #:  190 global step 12751   Batch #:  20 loss:  0.38720897\n",
      "Epoch #:  190 global step 12761   Batch #:  30 loss:  0.166563\n",
      "Epoch #:  190 global step 12771   Batch #:  40 loss:  0.3100154\n",
      "Epoch #:  190 global step 12781   Batch #:  50 loss:  0.2853944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 191/500 [06:29<10:30,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  190 global step 12791   Batch #:  60 loss:  0.28929675\n",
      "Epoch #:  191 global step 12798   Batch #:  0 loss:  0.22440043\n",
      "Epoch #:  191 global step 12808   Batch #:  10 loss:  0.22914934\n",
      "Epoch #:  191 global step 12818   Batch #:  20 loss:  0.2788065\n",
      "Epoch #:  191 global step 12828   Batch #:  30 loss:  0.14317192\n",
      "Epoch #:  191 global step 12838   Batch #:  40 loss:  0.17972364\n",
      "Epoch #:  191 global step 12848   Batch #:  50 loss:  0.21087927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 192/500 [06:31<10:28,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  191 global step 12858   Batch #:  60 loss:  0.14414768\n",
      "Epoch #:  192 global step 12865   Batch #:  0 loss:  0.12859854\n",
      "Epoch #:  192 global step 12875   Batch #:  10 loss:  0.14096229\n",
      "Epoch #:  192 global step 12885   Batch #:  20 loss:  0.16529463\n",
      "Epoch #:  192 global step 12895   Batch #:  30 loss:  0.089156106\n",
      "Epoch #:  192 global step 12905   Batch #:  40 loss:  0.1165123\n",
      "Epoch #:  192 global step 12915   Batch #:  50 loss:  0.1539597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 39%|███▊      | 193/500 [06:33<10:26,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  192 global step 12925   Batch #:  60 loss:  0.124644116\n",
      "Epoch #:  193 global step 12932   Batch #:  0 loss:  0.13079262\n",
      "Epoch #:  193 global step 12942   Batch #:  10 loss:  0.13245498\n",
      "Epoch #:  193 global step 12952   Batch #:  20 loss:  0.124025345\n",
      "Epoch #:  193 global step 12962   Batch #:  30 loss:  0.09311205\n",
      "Epoch #:  193 global step 12972   Batch #:  40 loss:  0.11379005\n",
      "Epoch #:  193 global step 12982   Batch #:  50 loss:  0.12754922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 39%|███▉      | 194/500 [06:35<10:23,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  193 global step 12992   Batch #:  60 loss:  0.08815782\n",
      "Epoch #:  194 global step 12999   Batch #:  0 loss:  0.108528554\n",
      "Epoch #:  194 global step 13009   Batch #:  10 loss:  0.12331038\n",
      "Epoch #:  194 global step 13019   Batch #:  20 loss:  0.11867805\n",
      "Epoch #:  194 global step 13029   Batch #:  30 loss:  0.07200809\n",
      "Epoch #:  194 global step 13039   Batch #:  40 loss:  0.1126439\n",
      "Epoch #:  194 global step 13049   Batch #:  50 loss:  0.11095038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 39%|███▉      | 195/500 [06:37<10:21,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  194 global step 13059   Batch #:  60 loss:  0.16709897\n",
      "Epoch #:  195 global step 13066   Batch #:  0 loss:  0.1334309\n",
      "Epoch #:  195 global step 13076   Batch #:  10 loss:  0.1118641\n",
      "Epoch #:  195 global step 13086   Batch #:  20 loss:  0.1255193\n",
      "Epoch #:  195 global step 13096   Batch #:  30 loss:  0.064590156\n",
      "Epoch #:  195 global step 13106   Batch #:  40 loss:  0.10775088\n",
      "Epoch #:  195 global step 13116   Batch #:  50 loss:  0.15134433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 39%|███▉      | 196/500 [06:39<10:19,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  195 global step 13126   Batch #:  60 loss:  0.15729254\n",
      "Epoch #:  196 global step 13133   Batch #:  0 loss:  0.11452772\n",
      "Epoch #:  196 global step 13143   Batch #:  10 loss:  0.104369074\n",
      "Epoch #:  196 global step 13153   Batch #:  20 loss:  0.121683985\n",
      "Epoch #:  196 global step 13163   Batch #:  30 loss:  0.08759126\n",
      "Epoch #:  196 global step 13173   Batch #:  40 loss:  0.12654583\n",
      "Epoch #:  196 global step 13183   Batch #:  50 loss:  0.11259868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 39%|███▉      | 197/500 [06:41<10:17,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  196 global step 13193   Batch #:  60 loss:  0.09360211\n",
      "Epoch #:  197 global step 13200   Batch #:  0 loss:  0.10725291\n",
      "Epoch #:  197 global step 13210   Batch #:  10 loss:  0.10021298\n",
      "Epoch #:  197 global step 13220   Batch #:  20 loss:  0.11790397\n",
      "Epoch #:  197 global step 13230   Batch #:  30 loss:  0.06938879\n",
      "Epoch #:  197 global step 13240   Batch #:  40 loss:  0.12902094\n",
      "Epoch #:  197 global step 13250   Batch #:  50 loss:  0.11583281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|███▉      | 198/500 [06:43<10:15,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  197 global step 13260   Batch #:  60 loss:  0.16778\n",
      "Epoch #:  198 global step 13267   Batch #:  0 loss:  0.15063687\n",
      "Epoch #:  198 global step 13277   Batch #:  10 loss:  0.09126786\n",
      "Epoch #:  198 global step 13287   Batch #:  20 loss:  0.16140337\n",
      "Epoch #:  198 global step 13297   Batch #:  30 loss:  0.060910285\n",
      "Epoch #:  198 global step 13307   Batch #:  40 loss:  0.11583478\n",
      "Epoch #:  198 global step 13317   Batch #:  50 loss:  0.11206438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|███▉      | 199/500 [06:45<10:13,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  198 global step 13327   Batch #:  60 loss:  0.0846806\n",
      "Epoch #:  199 global step 13334   Batch #:  0 loss:  0.09694399\n",
      "Epoch #:  199 global step 13344   Batch #:  10 loss:  0.087311\n",
      "Epoch #:  199 global step 13354   Batch #:  20 loss:  0.11662435\n",
      "Epoch #:  199 global step 13364   Batch #:  30 loss:  0.06013246\n",
      "Epoch #:  199 global step 13374   Batch #:  40 loss:  0.1136393\n",
      "Epoch #:  199 global step 13384   Batch #:  50 loss:  0.11089484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 200/500 [06:47<10:11,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  199 global step 13394   Batch #:  60 loss:  0.08190745\n",
      "Epoch #:  200 global step 13401   Batch #:  0 loss:  0.09229058\n",
      "Epoch #:  200 global step 13411   Batch #:  10 loss:  0.08514109\n",
      "Epoch #:  200 global step 13421   Batch #:  20 loss:  0.12002455\n",
      "Epoch #:  200 global step 13431   Batch #:  30 loss:  0.05832656\n",
      "Epoch #:  200 global step 13441   Batch #:  40 loss:  0.1099648\n",
      "Epoch #:  200 global step 13451   Batch #:  50 loss:  0.10907896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 201/500 [06:49<10:09,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  200 global step 13461   Batch #:  60 loss:  0.07810366\n",
      "Epoch #:  201 global step 13468   Batch #:  0 loss:  0.08910956\n",
      "Epoch #:  201 global step 13478   Batch #:  10 loss:  0.07693431\n",
      "Epoch #:  201 global step 13488   Batch #:  20 loss:  0.11615287\n",
      "Epoch #:  201 global step 13498   Batch #:  30 loss:  0.058653556\n",
      "Epoch #:  201 global step 13508   Batch #:  40 loss:  0.10349663\n",
      "Epoch #:  201 global step 13518   Batch #:  50 loss:  0.107361935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 202/500 [06:51<10:07,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  201 global step 13528   Batch #:  60 loss:  0.08126819\n",
      "Epoch #:  202 global step 13535   Batch #:  0 loss:  0.09622078\n",
      "Epoch #:  202 global step 13545   Batch #:  10 loss:  0.072352484\n",
      "Epoch #:  202 global step 13555   Batch #:  20 loss:  0.11778185\n",
      "Epoch #:  202 global step 13565   Batch #:  30 loss:  0.056099266\n",
      "Epoch #:  202 global step 13575   Batch #:  40 loss:  0.10778919\n",
      "Epoch #:  202 global step 13585   Batch #:  50 loss:  0.10813284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 41%|████      | 203/500 [06:53<10:05,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  202 global step 13595   Batch #:  60 loss:  0.07953327\n",
      "Epoch #:  203 global step 13602   Batch #:  0 loss:  0.09792019\n",
      "Epoch #:  203 global step 13612   Batch #:  10 loss:  0.0964429\n",
      "Epoch #:  203 global step 13622   Batch #:  20 loss:  0.20853257\n",
      "Epoch #:  203 global step 13632   Batch #:  30 loss:  0.05913337\n",
      "Epoch #:  203 global step 13642   Batch #:  40 loss:  0.109063596\n",
      "Epoch #:  203 global step 13652   Batch #:  50 loss:  0.106852986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 41%|████      | 204/500 [06:55<10:03,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  203 global step 13662   Batch #:  60 loss:  0.07986333\n",
      "Epoch #:  204 global step 13669   Batch #:  0 loss:  0.088049\n",
      "Epoch #:  204 global step 13679   Batch #:  10 loss:  0.0769269\n",
      "Epoch #:  204 global step 13689   Batch #:  20 loss:  0.122233175\n",
      "Epoch #:  204 global step 13699   Batch #:  30 loss:  0.075005956\n",
      "Epoch #:  204 global step 13709   Batch #:  40 loss:  0.11332939\n",
      "Epoch #:  204 global step 13719   Batch #:  50 loss:  0.11036841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 41%|████      | 205/500 [06:57<10:01,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  204 global step 13729   Batch #:  60 loss:  0.08480999\n",
      "Epoch #:  205 global step 13736   Batch #:  0 loss:  0.08682116\n",
      "Epoch #:  205 global step 13746   Batch #:  10 loss:  0.08773997\n",
      "Epoch #:  205 global step 13756   Batch #:  20 loss:  0.118571244\n",
      "Epoch #:  205 global step 13766   Batch #:  30 loss:  0.05572827\n",
      "Epoch #:  205 global step 13776   Batch #:  40 loss:  0.11329474\n",
      "Epoch #:  205 global step 13786   Batch #:  50 loss:  0.17957488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 41%|████      | 206/500 [07:00<09:59,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  205 global step 13796   Batch #:  60 loss:  0.19079953\n",
      "Epoch #:  206 global step 13803   Batch #:  0 loss:  0.20816639\n",
      "Epoch #:  206 global step 13813   Batch #:  10 loss:  0.18329917\n",
      "Epoch #:  206 global step 13823   Batch #:  20 loss:  0.20858695\n",
      "Epoch #:  206 global step 13833   Batch #:  30 loss:  0.09838514\n",
      "Epoch #:  206 global step 13843   Batch #:  40 loss:  0.12823002\n",
      "Epoch #:  206 global step 13853   Batch #:  50 loss:  0.11885144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 41%|████▏     | 207/500 [07:02<09:57,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  206 global step 13863   Batch #:  60 loss:  0.09567232\n",
      "Epoch #:  207 global step 13870   Batch #:  0 loss:  0.09532323\n",
      "Epoch #:  207 global step 13880   Batch #:  10 loss:  0.17885216\n",
      "Epoch #:  207 global step 13890   Batch #:  20 loss:  0.25574562\n",
      "Epoch #:  207 global step 13900   Batch #:  30 loss:  0.110052414\n",
      "Epoch #:  207 global step 13910   Batch #:  40 loss:  0.2219013\n",
      "Epoch #:  207 global step 13920   Batch #:  50 loss:  0.1614357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 42%|████▏     | 208/500 [07:04<09:55,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  207 global step 13930   Batch #:  60 loss:  0.22576873\n",
      "Epoch #:  208 global step 13937   Batch #:  0 loss:  0.12899417\n",
      "Epoch #:  208 global step 13947   Batch #:  10 loss:  0.27625272\n",
      "Epoch #:  208 global step 13957   Batch #:  20 loss:  0.2687783\n",
      "Epoch #:  208 global step 13967   Batch #:  30 loss:  0.12045951\n",
      "Epoch #:  208 global step 13977   Batch #:  40 loss:  0.14760283\n",
      "Epoch #:  208 global step 13987   Batch #:  50 loss:  0.1617412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 42%|████▏     | 209/500 [07:06<09:53,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  208 global step 13997   Batch #:  60 loss:  0.15396659\n",
      "Epoch #:  209 global step 14004   Batch #:  0 loss:  0.11374234\n",
      "Epoch #:  209 global step 14014   Batch #:  10 loss:  0.12503517\n",
      "Epoch #:  209 global step 14024   Batch #:  20 loss:  0.17292921\n",
      "Epoch #:  209 global step 14034   Batch #:  30 loss:  0.07649883\n",
      "Epoch #:  209 global step 14044   Batch #:  40 loss:  0.15659605\n",
      "Epoch #:  209 global step 14054   Batch #:  50 loss:  0.13084722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 42%|████▏     | 210/500 [07:08<09:51,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  209 global step 14064   Batch #:  60 loss:  0.11400827\n",
      "Epoch #:  210 global step 14071   Batch #:  0 loss:  0.09691201\n",
      "Epoch #:  210 global step 14081   Batch #:  10 loss:  0.13126329\n",
      "Epoch #:  210 global step 14091   Batch #:  20 loss:  0.15410674\n",
      "Epoch #:  210 global step 14101   Batch #:  30 loss:  0.06877721\n",
      "Epoch #:  210 global step 14111   Batch #:  40 loss:  0.1085488\n",
      "Epoch #:  210 global step 14121   Batch #:  50 loss:  0.13180216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 42%|████▏     | 211/500 [07:10<09:49,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  210 global step 14131   Batch #:  60 loss:  0.1009989\n",
      "Epoch #:  211 global step 14138   Batch #:  0 loss:  0.095275536\n",
      "Epoch #:  211 global step 14148   Batch #:  10 loss:  0.098928235\n",
      "Epoch #:  211 global step 14158   Batch #:  20 loss:  0.12862206\n",
      "Epoch #:  211 global step 14168   Batch #:  30 loss:  0.06816019\n",
      "Epoch #:  211 global step 14178   Batch #:  40 loss:  0.1314196\n",
      "Epoch #:  211 global step 14188   Batch #:  50 loss:  0.14158757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 42%|████▏     | 212/500 [07:12<09:47,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  211 global step 14198   Batch #:  60 loss:  0.09945941\n",
      "Epoch #:  212 global step 14205   Batch #:  0 loss:  0.112834536\n",
      "Epoch #:  212 global step 14215   Batch #:  10 loss:  0.11016944\n",
      "Epoch #:  212 global step 14225   Batch #:  20 loss:  0.15276556\n",
      "Epoch #:  212 global step 14235   Batch #:  30 loss:  0.06506287\n",
      "Epoch #:  212 global step 14245   Batch #:  40 loss:  0.11835594\n",
      "Epoch #:  212 global step 14255   Batch #:  50 loss:  0.13004346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 213/500 [07:14<09:45,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  212 global step 14265   Batch #:  60 loss:  0.09077626\n",
      "Epoch #:  213 global step 14272   Batch #:  0 loss:  0.102740854\n",
      "Epoch #:  213 global step 14282   Batch #:  10 loss:  0.10957413\n",
      "Epoch #:  213 global step 14292   Batch #:  20 loss:  0.14582008\n",
      "Epoch #:  213 global step 14302   Batch #:  30 loss:  0.05866141\n",
      "Epoch #:  213 global step 14312   Batch #:  40 loss:  0.115842916\n",
      "Epoch #:  213 global step 14322   Batch #:  50 loss:  0.11682062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 214/500 [07:16<09:43,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  213 global step 14332   Batch #:  60 loss:  0.08311723\n",
      "Epoch #:  214 global step 14339   Batch #:  0 loss:  0.0957521\n",
      "Epoch #:  214 global step 14349   Batch #:  10 loss:  0.108266026\n",
      "Epoch #:  214 global step 14359   Batch #:  20 loss:  0.1343529\n",
      "Epoch #:  214 global step 14369   Batch #:  30 loss:  0.05962982\n",
      "Epoch #:  214 global step 14379   Batch #:  40 loss:  0.10229984\n",
      "Epoch #:  214 global step 14389   Batch #:  50 loss:  0.10942295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 215/500 [07:18<09:41,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  214 global step 14399   Batch #:  60 loss:  0.08498113\n",
      "Epoch #:  215 global step 14406   Batch #:  0 loss:  0.09664538\n",
      "Epoch #:  215 global step 14416   Batch #:  10 loss:  0.111408114\n",
      "Epoch #:  215 global step 14426   Batch #:  20 loss:  0.13155018\n",
      "Epoch #:  215 global step 14436   Batch #:  30 loss:  0.05221211\n",
      "Epoch #:  215 global step 14446   Batch #:  40 loss:  0.10764398\n",
      "Epoch #:  215 global step 14456   Batch #:  50 loss:  0.111317106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 216/500 [07:20<09:39,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  215 global step 14466   Batch #:  60 loss:  0.08913703\n",
      "Epoch #:  216 global step 14473   Batch #:  0 loss:  0.09258965\n",
      "Epoch #:  216 global step 14483   Batch #:  10 loss:  0.09972993\n",
      "Epoch #:  216 global step 14493   Batch #:  20 loss:  0.13808188\n",
      "Epoch #:  216 global step 14503   Batch #:  30 loss:  0.05115532\n",
      "Epoch #:  216 global step 14513   Batch #:  40 loss:  0.109762885\n",
      "Epoch #:  216 global step 14523   Batch #:  50 loss:  0.11035131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 217/500 [07:22<09:36,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  216 global step 14533   Batch #:  60 loss:  0.085359335\n",
      "Epoch #:  217 global step 14540   Batch #:  0 loss:  0.094263405\n",
      "Epoch #:  217 global step 14550   Batch #:  10 loss:  0.10155308\n",
      "Epoch #:  217 global step 14560   Batch #:  20 loss:  0.12782972\n",
      "Epoch #:  217 global step 14570   Batch #:  30 loss:  0.05198368\n",
      "Epoch #:  217 global step 14580   Batch #:  40 loss:  0.11109226\n",
      "Epoch #:  217 global step 14590   Batch #:  50 loss:  0.12692128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 44%|████▎     | 218/500 [07:24<09:34,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  217 global step 14600   Batch #:  60 loss:  0.09172169\n",
      "Epoch #:  218 global step 14607   Batch #:  0 loss:  0.10100634\n",
      "Epoch #:  218 global step 14617   Batch #:  10 loss:  0.10507369\n",
      "Epoch #:  218 global step 14627   Batch #:  20 loss:  0.13412812\n",
      "Epoch #:  218 global step 14637   Batch #:  30 loss:  0.051554617\n",
      "Epoch #:  218 global step 14647   Batch #:  40 loss:  0.1000628\n",
      "Epoch #:  218 global step 14657   Batch #:  50 loss:  0.1105145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 44%|████▍     | 219/500 [07:26<09:32,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  218 global step 14667   Batch #:  60 loss:  0.08726422\n",
      "Epoch #:  219 global step 14674   Batch #:  0 loss:  0.08560822\n",
      "Epoch #:  219 global step 14684   Batch #:  10 loss:  0.104112744\n",
      "Epoch #:  219 global step 14694   Batch #:  20 loss:  0.13466834\n",
      "Epoch #:  219 global step 14704   Batch #:  30 loss:  0.051229313\n",
      "Epoch #:  219 global step 14714   Batch #:  40 loss:  0.10138298\n",
      "Epoch #:  219 global step 14724   Batch #:  50 loss:  0.1090229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 44%|████▍     | 220/500 [07:28<09:30,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  219 global step 14734   Batch #:  60 loss:  0.08357831\n",
      "Epoch #:  220 global step 14741   Batch #:  0 loss:  0.098807685\n",
      "Epoch #:  220 global step 14751   Batch #:  10 loss:  0.08436881\n",
      "Epoch #:  220 global step 14761   Batch #:  20 loss:  0.12287551\n",
      "Epoch #:  220 global step 14771   Batch #:  30 loss:  0.054548413\n",
      "Epoch #:  220 global step 14781   Batch #:  40 loss:  0.09977917\n",
      "Epoch #:  220 global step 14791   Batch #:  50 loss:  0.10490087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 44%|████▍     | 221/500 [07:30<09:28,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  220 global step 14801   Batch #:  60 loss:  0.08732592\n",
      "Epoch #:  221 global step 14808   Batch #:  0 loss:  0.09570742\n",
      "Epoch #:  221 global step 14818   Batch #:  10 loss:  0.080212794\n",
      "Epoch #:  221 global step 14828   Batch #:  20 loss:  0.11890315\n",
      "Epoch #:  221 global step 14838   Batch #:  30 loss:  0.058079887\n",
      "Epoch #:  221 global step 14848   Batch #:  40 loss:  0.10667837\n",
      "Epoch #:  221 global step 14858   Batch #:  50 loss:  0.10945993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 44%|████▍     | 222/500 [07:32<09:26,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  221 global step 14868   Batch #:  60 loss:  0.08203996\n",
      "Epoch #:  222 global step 14875   Batch #:  0 loss:  0.10239048\n",
      "Epoch #:  222 global step 14885   Batch #:  10 loss:  0.081586614\n",
      "Epoch #:  222 global step 14895   Batch #:  20 loss:  0.13841602\n",
      "Epoch #:  222 global step 14905   Batch #:  30 loss:  0.05833878\n",
      "Epoch #:  222 global step 14915   Batch #:  40 loss:  0.10664446\n",
      "Epoch #:  222 global step 14925   Batch #:  50 loss:  0.10483104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 45%|████▍     | 223/500 [07:34<09:24,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  222 global step 14935   Batch #:  60 loss:  0.080362655\n",
      "Epoch #:  223 global step 14942   Batch #:  0 loss:  0.09736481\n",
      "Epoch #:  223 global step 14952   Batch #:  10 loss:  0.06900904\n",
      "Epoch #:  223 global step 14962   Batch #:  20 loss:  0.12581153\n",
      "Epoch #:  223 global step 14972   Batch #:  30 loss:  0.057528812\n",
      "Epoch #:  223 global step 14982   Batch #:  40 loss:  0.10628906\n",
      "Epoch #:  223 global step 14992   Batch #:  50 loss:  0.1129324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 45%|████▍     | 224/500 [07:36<09:22,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  223 global step 15002   Batch #:  60 loss:  0.08284536\n",
      "Epoch #:  224 global step 15009   Batch #:  0 loss:  0.09174147\n",
      "Epoch #:  224 global step 15019   Batch #:  10 loss:  0.09356937\n",
      "Epoch #:  224 global step 15029   Batch #:  20 loss:  0.12144733\n",
      "Epoch #:  224 global step 15039   Batch #:  30 loss:  0.061286982\n",
      "Epoch #:  224 global step 15049   Batch #:  40 loss:  0.10889777\n",
      "Epoch #:  224 global step 15059   Batch #:  50 loss:  0.11662728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 225/500 [07:38<09:20,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  224 global step 15069   Batch #:  60 loss:  0.08456909\n",
      "Epoch #:  225 global step 15076   Batch #:  0 loss:  0.15818489\n",
      "Epoch #:  225 global step 15086   Batch #:  10 loss:  0.08758639\n",
      "Epoch #:  225 global step 15096   Batch #:  20 loss:  0.13909972\n",
      "Epoch #:  225 global step 15106   Batch #:  30 loss:  0.058257025\n",
      "Epoch #:  225 global step 15116   Batch #:  40 loss:  0.10898183\n",
      "Epoch #:  225 global step 15126   Batch #:  50 loss:  0.2145569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 226/500 [07:40<09:18,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  225 global step 15136   Batch #:  60 loss:  0.13828509\n",
      "Epoch #:  226 global step 15143   Batch #:  0 loss:  0.11100169\n",
      "Epoch #:  226 global step 15153   Batch #:  10 loss:  0.112206265\n",
      "Epoch #:  226 global step 15163   Batch #:  20 loss:  0.18263024\n",
      "Epoch #:  226 global step 15173   Batch #:  30 loss:  0.06557892\n",
      "Epoch #:  226 global step 15183   Batch #:  40 loss:  0.11417604\n",
      "Epoch #:  226 global step 15193   Batch #:  50 loss:  0.11301135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 227/500 [07:42<09:16,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  226 global step 15203   Batch #:  60 loss:  0.11103902\n",
      "Epoch #:  227 global step 15210   Batch #:  0 loss:  0.086192064\n",
      "Epoch #:  227 global step 15220   Batch #:  10 loss:  0.089550406\n",
      "Epoch #:  227 global step 15230   Batch #:  20 loss:  0.12081068\n",
      "Epoch #:  227 global step 15240   Batch #:  30 loss:  0.049856994\n",
      "Epoch #:  227 global step 15250   Batch #:  40 loss:  0.10002279\n",
      "Epoch #:  227 global step 15260   Batch #:  50 loss:  0.10717758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 228/500 [07:44<09:14,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  227 global step 15270   Batch #:  60 loss:  0.06817888\n",
      "Epoch #:  228 global step 15277   Batch #:  0 loss:  0.091591686\n",
      "Epoch #:  228 global step 15287   Batch #:  10 loss:  0.07271626\n",
      "Epoch #:  228 global step 15297   Batch #:  20 loss:  0.16148074\n",
      "Epoch #:  228 global step 15307   Batch #:  30 loss:  0.051135793\n",
      "Epoch #:  228 global step 15317   Batch #:  40 loss:  0.100886844\n",
      "Epoch #:  228 global step 15327   Batch #:  50 loss:  0.10137265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 229/500 [07:46<09:12,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  228 global step 15337   Batch #:  60 loss:  0.10729569\n",
      "Epoch #:  229 global step 15344   Batch #:  0 loss:  0.08536057\n",
      "Epoch #:  229 global step 15354   Batch #:  10 loss:  0.059403207\n",
      "Epoch #:  229 global step 15364   Batch #:  20 loss:  0.12352992\n",
      "Epoch #:  229 global step 15374   Batch #:  30 loss:  0.073881395\n",
      "Epoch #:  229 global step 15384   Batch #:  40 loss:  0.16355473\n",
      "Epoch #:  229 global step 15394   Batch #:  50 loss:  0.12079568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 230/500 [07:48<09:10,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  229 global step 15404   Batch #:  60 loss:  0.08485175\n",
      "Epoch #:  230 global step 15411   Batch #:  0 loss:  0.08868079\n",
      "Epoch #:  230 global step 15421   Batch #:  10 loss:  0.0627784\n",
      "Epoch #:  230 global step 15431   Batch #:  20 loss:  0.09777342\n",
      "Epoch #:  230 global step 15441   Batch #:  30 loss:  0.088880435\n",
      "Epoch #:  230 global step 15451   Batch #:  40 loss:  0.10287207\n",
      "Epoch #:  230 global step 15461   Batch #:  50 loss:  0.11140185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 231/500 [07:50<09:08,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  230 global step 15471   Batch #:  60 loss:  0.083159775\n",
      "Epoch #:  231 global step 15478   Batch #:  0 loss:  0.084758066\n",
      "Epoch #:  231 global step 15488   Batch #:  10 loss:  0.05632361\n",
      "Epoch #:  231 global step 15498   Batch #:  20 loss:  0.0914827\n",
      "Epoch #:  231 global step 15508   Batch #:  30 loss:  0.056718327\n",
      "Epoch #:  231 global step 15518   Batch #:  40 loss:  0.10034965\n",
      "Epoch #:  231 global step 15528   Batch #:  50 loss:  0.104321055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 46%|████▋     | 232/500 [07:52<09:06,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  231 global step 15538   Batch #:  60 loss:  0.073520325\n",
      "Epoch #:  232 global step 15545   Batch #:  0 loss:  0.08300095\n",
      "Epoch #:  232 global step 15555   Batch #:  10 loss:  0.05300972\n",
      "Epoch #:  232 global step 15565   Batch #:  20 loss:  0.10038787\n",
      "Epoch #:  232 global step 15575   Batch #:  30 loss:  0.056903224\n",
      "Epoch #:  232 global step 15585   Batch #:  40 loss:  0.098581806\n",
      "Epoch #:  232 global step 15595   Batch #:  50 loss:  0.10609327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 47%|████▋     | 233/500 [07:54<09:04,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  232 global step 15605   Batch #:  60 loss:  0.0730408\n",
      "Epoch #:  233 global step 15612   Batch #:  0 loss:  0.081797756\n",
      "Epoch #:  233 global step 15622   Batch #:  10 loss:  0.070269905\n",
      "Epoch #:  233 global step 15632   Batch #:  20 loss:  0.1024755\n",
      "Epoch #:  233 global step 15642   Batch #:  30 loss:  0.055677626\n",
      "Epoch #:  233 global step 15652   Batch #:  40 loss:  0.09647549\n",
      "Epoch #:  233 global step 15662   Batch #:  50 loss:  0.1053447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 47%|████▋     | 234/500 [07:57<09:02,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  233 global step 15672   Batch #:  60 loss:  0.06668786\n",
      "Epoch #:  234 global step 15679   Batch #:  0 loss:  0.08138961\n",
      "Epoch #:  234 global step 15689   Batch #:  10 loss:  0.054360654\n",
      "Epoch #:  234 global step 15699   Batch #:  20 loss:  0.09553484\n",
      "Epoch #:  234 global step 15709   Batch #:  30 loss:  0.056430325\n",
      "Epoch #:  234 global step 15719   Batch #:  40 loss:  0.09706278\n",
      "Epoch #:  234 global step 15729   Batch #:  50 loss:  0.10584743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 47%|████▋     | 235/500 [07:59<09:00,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  234 global step 15739   Batch #:  60 loss:  0.069474235\n",
      "Epoch #:  235 global step 15746   Batch #:  0 loss:  0.08209512\n",
      "Epoch #:  235 global step 15756   Batch #:  10 loss:  0.05766851\n",
      "Epoch #:  235 global step 15766   Batch #:  20 loss:  0.07734505\n",
      "Epoch #:  235 global step 15776   Batch #:  30 loss:  0.05187784\n",
      "Epoch #:  235 global step 15786   Batch #:  40 loss:  0.09696063\n",
      "Epoch #:  235 global step 15796   Batch #:  50 loss:  0.10461762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 47%|████▋     | 236/500 [08:01<08:58,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  235 global step 15806   Batch #:  60 loss:  0.06956676\n",
      "Epoch #:  236 global step 15813   Batch #:  0 loss:  0.08142807\n",
      "Epoch #:  236 global step 15823   Batch #:  10 loss:  0.05843568\n",
      "Epoch #:  236 global step 15833   Batch #:  20 loss:  0.08960969\n",
      "Epoch #:  236 global step 15843   Batch #:  30 loss:  0.051685207\n",
      "Epoch #:  236 global step 15853   Batch #:  40 loss:  0.09620696\n",
      "Epoch #:  236 global step 15863   Batch #:  50 loss:  0.1044213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 47%|████▋     | 237/500 [08:03<08:56,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  236 global step 15873   Batch #:  60 loss:  0.07257393\n",
      "Epoch #:  237 global step 15880   Batch #:  0 loss:  0.081161484\n",
      "Epoch #:  237 global step 15890   Batch #:  10 loss:  0.050779905\n",
      "Epoch #:  237 global step 15900   Batch #:  20 loss:  0.07572637\n",
      "Epoch #:  237 global step 15910   Batch #:  30 loss:  0.051377825\n",
      "Epoch #:  237 global step 15920   Batch #:  40 loss:  0.09472836\n",
      "Epoch #:  237 global step 15930   Batch #:  50 loss:  0.10078396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 48%|████▊     | 238/500 [08:05<08:54,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  237 global step 15940   Batch #:  60 loss:  0.06979599\n",
      "Epoch #:  238 global step 15947   Batch #:  0 loss:  0.08141579\n",
      "Epoch #:  238 global step 15957   Batch #:  10 loss:  0.059955448\n",
      "Epoch #:  238 global step 15967   Batch #:  20 loss:  0.08235533\n",
      "Epoch #:  238 global step 15977   Batch #:  30 loss:  0.05089812\n",
      "Epoch #:  238 global step 15987   Batch #:  40 loss:  0.09337162\n",
      "Epoch #:  238 global step 15997   Batch #:  50 loss:  0.104670316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 48%|████▊     | 239/500 [08:07<08:52,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  238 global step 16007   Batch #:  60 loss:  0.070814215\n",
      "Epoch #:  239 global step 16014   Batch #:  0 loss:  0.08039771\n",
      "Epoch #:  239 global step 16024   Batch #:  10 loss:  0.05757942\n",
      "Epoch #:  239 global step 16034   Batch #:  20 loss:  0.07812395\n",
      "Epoch #:  239 global step 16044   Batch #:  30 loss:  0.050224353\n",
      "Epoch #:  239 global step 16054   Batch #:  40 loss:  0.09159055\n",
      "Epoch #:  239 global step 16064   Batch #:  50 loss:  0.10343778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 48%|████▊     | 240/500 [08:09<08:49,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  239 global step 16074   Batch #:  60 loss:  0.07016583\n",
      "Epoch #:  240 global step 16081   Batch #:  0 loss:  0.079456925\n",
      "Epoch #:  240 global step 16091   Batch #:  10 loss:  0.041213926\n",
      "Epoch #:  240 global step 16101   Batch #:  20 loss:  0.080968216\n",
      "Epoch #:  240 global step 16111   Batch #:  30 loss:  0.051136427\n",
      "Epoch #:  240 global step 16121   Batch #:  40 loss:  0.09289476\n",
      "Epoch #:  240 global step 16131   Batch #:  50 loss:  0.10184818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 48%|████▊     | 241/500 [08:11<08:47,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  240 global step 16141   Batch #:  60 loss:  0.07097998\n",
      "Epoch #:  241 global step 16148   Batch #:  0 loss:  0.08034076\n",
      "Epoch #:  241 global step 16158   Batch #:  10 loss:  0.062087476\n",
      "Epoch #:  241 global step 16168   Batch #:  20 loss:  0.07153767\n",
      "Epoch #:  241 global step 16178   Batch #:  30 loss:  0.05086244\n",
      "Epoch #:  241 global step 16188   Batch #:  40 loss:  0.09001856\n",
      "Epoch #:  241 global step 16198   Batch #:  50 loss:  0.103566065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 48%|████▊     | 242/500 [08:13<08:45,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  241 global step 16208   Batch #:  60 loss:  0.07049011\n",
      "Epoch #:  242 global step 16215   Batch #:  0 loss:  0.07865855\n",
      "Epoch #:  242 global step 16225   Batch #:  10 loss:  0.05622727\n",
      "Epoch #:  242 global step 16235   Batch #:  20 loss:  0.088810205\n",
      "Epoch #:  242 global step 16245   Batch #:  30 loss:  0.049962595\n",
      "Epoch #:  242 global step 16255   Batch #:  40 loss:  0.08959613\n",
      "Epoch #:  242 global step 16265   Batch #:  50 loss:  0.102179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 49%|████▊     | 243/500 [08:15<08:43,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  242 global step 16275   Batch #:  60 loss:  0.07146682\n",
      "Epoch #:  243 global step 16282   Batch #:  0 loss:  0.07848938\n",
      "Epoch #:  243 global step 16292   Batch #:  10 loss:  0.05608229\n",
      "Epoch #:  243 global step 16302   Batch #:  20 loss:  0.08284839\n",
      "Epoch #:  243 global step 16312   Batch #:  30 loss:  0.049770705\n",
      "Epoch #:  243 global step 16322   Batch #:  40 loss:  0.091925874\n",
      "Epoch #:  243 global step 16332   Batch #:  50 loss:  0.09980735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 49%|████▉     | 244/500 [08:17<08:41,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  243 global step 16342   Batch #:  60 loss:  0.077538125\n",
      "Epoch #:  244 global step 16349   Batch #:  0 loss:  0.07790239\n",
      "Epoch #:  244 global step 16359   Batch #:  10 loss:  0.04799593\n",
      "Epoch #:  244 global step 16369   Batch #:  20 loss:  0.07977473\n",
      "Epoch #:  244 global step 16379   Batch #:  30 loss:  0.050271165\n",
      "Epoch #:  244 global step 16389   Batch #:  40 loss:  0.09218785\n",
      "Epoch #:  244 global step 16399   Batch #:  50 loss:  0.102702454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 49%|████▉     | 245/500 [08:19<08:39,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  244 global step 16409   Batch #:  60 loss:  0.06912855\n",
      "Epoch #:  245 global step 16416   Batch #:  0 loss:  0.07687728\n",
      "Epoch #:  245 global step 16426   Batch #:  10 loss:  0.049563844\n",
      "Epoch #:  245 global step 16436   Batch #:  20 loss:  0.079608224\n",
      "Epoch #:  245 global step 16446   Batch #:  30 loss:  0.04969573\n",
      "Epoch #:  245 global step 16456   Batch #:  40 loss:  0.09175379\n",
      "Epoch #:  245 global step 16466   Batch #:  50 loss:  0.10596616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 49%|████▉     | 246/500 [08:21<08:37,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  245 global step 16476   Batch #:  60 loss:  0.07518902\n",
      "Epoch #:  246 global step 16483   Batch #:  0 loss:  0.0766883\n",
      "Epoch #:  246 global step 16493   Batch #:  10 loss:  0.05755309\n",
      "Epoch #:  246 global step 16503   Batch #:  20 loss:  0.08169272\n",
      "Epoch #:  246 global step 16513   Batch #:  30 loss:  0.0494998\n",
      "Epoch #:  246 global step 16523   Batch #:  40 loss:  0.088977434\n",
      "Epoch #:  246 global step 16533   Batch #:  50 loss:  0.10403921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 49%|████▉     | 247/500 [08:23<08:35,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  246 global step 16543   Batch #:  60 loss:  0.06909255\n",
      "Epoch #:  247 global step 16550   Batch #:  0 loss:  0.07847625\n",
      "Epoch #:  247 global step 16560   Batch #:  10 loss:  0.05905421\n",
      "Epoch #:  247 global step 16570   Batch #:  20 loss:  0.09547301\n",
      "Epoch #:  247 global step 16580   Batch #:  30 loss:  0.049855694\n",
      "Epoch #:  247 global step 16590   Batch #:  40 loss:  0.088456474\n",
      "Epoch #:  247 global step 16600   Batch #:  50 loss:  0.10395743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 50%|████▉     | 248/500 [08:25<08:33,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  247 global step 16610   Batch #:  60 loss:  0.06759215\n",
      "Epoch #:  248 global step 16617   Batch #:  0 loss:  0.0770156\n",
      "Epoch #:  248 global step 16627   Batch #:  10 loss:  0.0463828\n",
      "Epoch #:  248 global step 16637   Batch #:  20 loss:  0.07324918\n",
      "Epoch #:  248 global step 16647   Batch #:  30 loss:  0.049794767\n",
      "Epoch #:  248 global step 16657   Batch #:  40 loss:  0.08779948\n",
      "Epoch #:  248 global step 16667   Batch #:  50 loss:  0.10362628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 50%|████▉     | 249/500 [08:27<08:31,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  248 global step 16677   Batch #:  60 loss:  0.06977843\n",
      "Epoch #:  249 global step 16684   Batch #:  0 loss:  0.07622537\n",
      "Epoch #:  249 global step 16694   Batch #:  10 loss:  0.043412652\n",
      "Epoch #:  249 global step 16704   Batch #:  20 loss:  0.09181035\n",
      "Epoch #:  249 global step 16714   Batch #:  30 loss:  0.048892163\n",
      "Epoch #:  249 global step 16724   Batch #:  40 loss:  0.08781483\n",
      "Epoch #:  249 global step 16734   Batch #:  50 loss:  0.103315555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 250/500 [08:29<08:29,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  249 global step 16744   Batch #:  60 loss:  0.06766515\n",
      "Epoch #:  250 global step 16751   Batch #:  0 loss:  0.078217514\n",
      "Epoch #:  250 global step 16761   Batch #:  10 loss:  0.04974482\n",
      "Epoch #:  250 global step 16771   Batch #:  20 loss:  0.07761036\n",
      "Epoch #:  250 global step 16781   Batch #:  30 loss:  0.068207406\n",
      "Epoch #:  250 global step 16791   Batch #:  40 loss:  0.096975155\n",
      "Epoch #:  250 global step 16801   Batch #:  50 loss:  0.10633677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 251/500 [08:31<08:27,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  250 global step 16811   Batch #:  60 loss:  0.12928864\n",
      "Epoch #:  251 global step 16818   Batch #:  0 loss:  0.06253558\n",
      "Epoch #:  251 global step 16828   Batch #:  10 loss:  0.0709367\n",
      "Epoch #:  251 global step 16838   Batch #:  20 loss:  0.09727811\n",
      "Epoch #:  251 global step 16848   Batch #:  30 loss:  0.09182738\n",
      "Epoch #:  251 global step 16858   Batch #:  40 loss:  0.10077696\n",
      "Epoch #:  251 global step 16868   Batch #:  50 loss:  0.13146351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 252/500 [08:33<08:25,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  251 global step 16878   Batch #:  60 loss:  0.13025536\n",
      "Epoch #:  252 global step 16885   Batch #:  0 loss:  0.13462962\n",
      "Epoch #:  252 global step 16895   Batch #:  10 loss:  0.17125994\n",
      "Epoch #:  252 global step 16905   Batch #:  20 loss:  0.18892108\n",
      "Epoch #:  252 global step 16915   Batch #:  30 loss:  0.24013399\n",
      "Epoch #:  252 global step 16925   Batch #:  40 loss:  0.14159462\n",
      "Epoch #:  252 global step 16935   Batch #:  50 loss:  0.20411156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 51%|█████     | 253/500 [08:35<08:23,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  252 global step 16945   Batch #:  60 loss:  0.10728241\n",
      "Epoch #:  253 global step 16952   Batch #:  0 loss:  0.14667293\n",
      "Epoch #:  253 global step 16962   Batch #:  10 loss:  0.14593492\n",
      "Epoch #:  253 global step 16972   Batch #:  20 loss:  0.2783531\n",
      "Epoch #:  253 global step 16982   Batch #:  30 loss:  0.10716012\n",
      "Epoch #:  253 global step 16992   Batch #:  40 loss:  0.27040052\n",
      "Epoch #:  253 global step 17002   Batch #:  50 loss:  0.24737707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 51%|█████     | 254/500 [08:37<08:21,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  253 global step 17012   Batch #:  60 loss:  0.27984196\n",
      "Epoch #:  254 global step 17019   Batch #:  0 loss:  0.21775609\n",
      "Epoch #:  254 global step 17029   Batch #:  10 loss:  0.37443078\n",
      "Epoch #:  254 global step 17039   Batch #:  20 loss:  0.28941327\n",
      "Epoch #:  254 global step 17049   Batch #:  30 loss:  0.12410586\n",
      "Epoch #:  254 global step 17059   Batch #:  40 loss:  0.11869653\n",
      "Epoch #:  254 global step 17069   Batch #:  50 loss:  0.14167266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 51%|█████     | 255/500 [08:39<08:19,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  254 global step 17079   Batch #:  60 loss:  0.09806607\n",
      "Epoch #:  255 global step 17086   Batch #:  0 loss:  0.115563475\n",
      "Epoch #:  255 global step 17096   Batch #:  10 loss:  0.21482871\n",
      "Epoch #:  255 global step 17106   Batch #:  20 loss:  0.14818186\n",
      "Epoch #:  255 global step 17116   Batch #:  30 loss:  0.07288692\n",
      "Epoch #:  255 global step 17126   Batch #:  40 loss:  0.1166126\n",
      "Epoch #:  255 global step 17136   Batch #:  50 loss:  0.1642374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 51%|█████     | 256/500 [08:41<08:17,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  255 global step 17146   Batch #:  60 loss:  0.12019805\n",
      "Epoch #:  256 global step 17153   Batch #:  0 loss:  0.1320386\n",
      "Epoch #:  256 global step 17163   Batch #:  10 loss:  0.09559274\n",
      "Epoch #:  256 global step 17173   Batch #:  20 loss:  0.13333806\n",
      "Epoch #:  256 global step 17183   Batch #:  30 loss:  0.062817186\n",
      "Epoch #:  256 global step 17193   Batch #:  40 loss:  0.101102054\n",
      "Epoch #:  256 global step 17203   Batch #:  50 loss:  0.108670294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 51%|█████▏    | 257/500 [08:43<08:15,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  256 global step 17213   Batch #:  60 loss:  0.10139385\n",
      "Epoch #:  257 global step 17220   Batch #:  0 loss:  0.56327045\n",
      "Epoch #:  257 global step 17230   Batch #:  10 loss:  0.16624254\n",
      "Epoch #:  257 global step 17240   Batch #:  20 loss:  0.17640646\n",
      "Epoch #:  257 global step 17250   Batch #:  30 loss:  0.073800474\n",
      "Epoch #:  257 global step 17260   Batch #:  40 loss:  0.12570179\n",
      "Epoch #:  257 global step 17270   Batch #:  50 loss:  0.15495679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 52%|█████▏    | 258/500 [08:45<08:13,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  257 global step 17280   Batch #:  60 loss:  0.10187738\n",
      "Epoch #:  258 global step 17287   Batch #:  0 loss:  0.115598634\n",
      "Epoch #:  258 global step 17297   Batch #:  10 loss:  0.100953564\n",
      "Epoch #:  258 global step 17307   Batch #:  20 loss:  0.14900376\n",
      "Epoch #:  258 global step 17317   Batch #:  30 loss:  0.073938504\n",
      "Epoch #:  258 global step 17327   Batch #:  40 loss:  0.10413712\n",
      "Epoch #:  258 global step 17337   Batch #:  50 loss:  0.1342739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 52%|█████▏    | 259/500 [08:47<08:11,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  258 global step 17347   Batch #:  60 loss:  0.0785757\n",
      "Epoch #:  259 global step 17354   Batch #:  0 loss:  0.20672724\n",
      "Epoch #:  259 global step 17364   Batch #:  10 loss:  0.075833894\n",
      "Epoch #:  259 global step 17374   Batch #:  20 loss:  0.16281739\n",
      "Epoch #:  259 global step 17384   Batch #:  30 loss:  0.07548831\n",
      "Epoch #:  259 global step 17394   Batch #:  40 loss:  0.108293116\n",
      "Epoch #:  259 global step 17404   Batch #:  50 loss:  0.105328076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 52%|█████▏    | 260/500 [08:49<08:09,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  259 global step 17414   Batch #:  60 loss:  0.07968852\n",
      "Epoch #:  260 global step 17421   Batch #:  0 loss:  0.2075194\n",
      "Epoch #:  260 global step 17431   Batch #:  10 loss:  0.07803776\n",
      "Epoch #:  260 global step 17441   Batch #:  20 loss:  0.13174075\n",
      "Epoch #:  260 global step 17451   Batch #:  30 loss:  0.0722199\n",
      "Epoch #:  260 global step 17461   Batch #:  40 loss:  0.104386985\n",
      "Epoch #:  260 global step 17471   Batch #:  50 loss:  0.098042294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 52%|█████▏    | 261/500 [08:51<08:07,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  260 global step 17481   Batch #:  60 loss:  0.07662691\n",
      "Epoch #:  261 global step 17488   Batch #:  0 loss:  0.2112645\n",
      "Epoch #:  261 global step 17498   Batch #:  10 loss:  0.06269069\n",
      "Epoch #:  261 global step 17508   Batch #:  20 loss:  0.12014199\n",
      "Epoch #:  261 global step 17518   Batch #:  30 loss:  0.06888505\n",
      "Epoch #:  261 global step 17528   Batch #:  40 loss:  0.107127875\n",
      "Epoch #:  261 global step 17538   Batch #:  50 loss:  0.09782908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 52%|█████▏    | 262/500 [08:53<08:05,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  261 global step 17548   Batch #:  60 loss:  0.07899556\n",
      "Epoch #:  262 global step 17555   Batch #:  0 loss:  0.082610376\n",
      "Epoch #:  262 global step 17565   Batch #:  10 loss:  0.060231213\n",
      "Epoch #:  262 global step 17575   Batch #:  20 loss:  0.11005177\n",
      "Epoch #:  262 global step 17585   Batch #:  30 loss:  0.06984083\n",
      "Epoch #:  262 global step 17595   Batch #:  40 loss:  0.11252015\n",
      "Epoch #:  262 global step 17605   Batch #:  50 loss:  0.098466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 53%|█████▎    | 263/500 [08:56<08:03,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  262 global step 17615   Batch #:  60 loss:  0.079094775\n",
      "Epoch #:  263 global step 17622   Batch #:  0 loss:  0.08083476\n",
      "Epoch #:  263 global step 17632   Batch #:  10 loss:  0.055857964\n",
      "Epoch #:  263 global step 17642   Batch #:  20 loss:  0.10459824\n",
      "Epoch #:  263 global step 17652   Batch #:  30 loss:  0.06528744\n",
      "Epoch #:  263 global step 17662   Batch #:  40 loss:  0.108171456\n",
      "Epoch #:  263 global step 17672   Batch #:  50 loss:  0.09679219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 53%|█████▎    | 264/500 [08:58<08:00,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  263 global step 17682   Batch #:  60 loss:  0.07496114\n",
      "Epoch #:  264 global step 17689   Batch #:  0 loss:  0.080994815\n",
      "Epoch #:  264 global step 17699   Batch #:  10 loss:  0.05362096\n",
      "Epoch #:  264 global step 17709   Batch #:  20 loss:  0.102208845\n",
      "Epoch #:  264 global step 17719   Batch #:  30 loss:  0.06550944\n",
      "Epoch #:  264 global step 17729   Batch #:  40 loss:  0.10608504\n",
      "Epoch #:  264 global step 17739   Batch #:  50 loss:  0.09825647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 53%|█████▎    | 265/500 [09:00<07:58,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  264 global step 17749   Batch #:  60 loss:  0.078649774\n",
      "Epoch #:  265 global step 17756   Batch #:  0 loss:  0.07819386\n",
      "Epoch #:  265 global step 17766   Batch #:  10 loss:  0.05222676\n",
      "Epoch #:  265 global step 17776   Batch #:  20 loss:  0.09871324\n",
      "Epoch #:  265 global step 17786   Batch #:  30 loss:  0.06801737\n",
      "Epoch #:  265 global step 17796   Batch #:  40 loss:  0.104418315\n",
      "Epoch #:  265 global step 17806   Batch #:  50 loss:  0.09726508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 53%|█████▎    | 266/500 [09:02<07:56,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  265 global step 17816   Batch #:  60 loss:  0.077556826\n",
      "Epoch #:  266 global step 17823   Batch #:  0 loss:  0.07836071\n",
      "Epoch #:  266 global step 17833   Batch #:  10 loss:  0.06630218\n",
      "Epoch #:  266 global step 17843   Batch #:  20 loss:  0.10026861\n",
      "Epoch #:  266 global step 17853   Batch #:  30 loss:  0.067315966\n",
      "Epoch #:  266 global step 17863   Batch #:  40 loss:  0.10757127\n",
      "Epoch #:  266 global step 17873   Batch #:  50 loss:  0.09752401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 53%|█████▎    | 267/500 [09:04<07:54,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  266 global step 17883   Batch #:  60 loss:  0.07781039\n",
      "Epoch #:  267 global step 17890   Batch #:  0 loss:  0.080506824\n",
      "Epoch #:  267 global step 17900   Batch #:  10 loss:  0.05910152\n",
      "Epoch #:  267 global step 17910   Batch #:  20 loss:  0.09485172\n",
      "Epoch #:  267 global step 17920   Batch #:  30 loss:  0.06673906\n",
      "Epoch #:  267 global step 17930   Batch #:  40 loss:  0.103345886\n",
      "Epoch #:  267 global step 17940   Batch #:  50 loss:  0.09751535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 54%|█████▎    | 268/500 [09:06<07:52,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  267 global step 17950   Batch #:  60 loss:  0.07756562\n",
      "Epoch #:  268 global step 17957   Batch #:  0 loss:  0.079133354\n",
      "Epoch #:  268 global step 17967   Batch #:  10 loss:  0.05966478\n",
      "Epoch #:  268 global step 17977   Batch #:  20 loss:  0.1024579\n",
      "Epoch #:  268 global step 17987   Batch #:  30 loss:  0.06599932\n",
      "Epoch #:  268 global step 17997   Batch #:  40 loss:  0.104924165\n",
      "Epoch #:  268 global step 18007   Batch #:  50 loss:  0.09699873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 54%|█████▍    | 269/500 [09:08<07:50,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  268 global step 18017   Batch #:  60 loss:  0.077741496\n",
      "Epoch #:  269 global step 18024   Batch #:  0 loss:  0.07800632\n",
      "Epoch #:  269 global step 18034   Batch #:  10 loss:  0.07029192\n",
      "Epoch #:  269 global step 18044   Batch #:  20 loss:  0.10681605\n",
      "Epoch #:  269 global step 18054   Batch #:  30 loss:  0.06489946\n",
      "Epoch #:  269 global step 18064   Batch #:  40 loss:  0.10733059\n",
      "Epoch #:  269 global step 18074   Batch #:  50 loss:  0.09802254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 54%|█████▍    | 270/500 [09:10<07:48,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  269 global step 18084   Batch #:  60 loss:  0.071914986\n",
      "Epoch #:  270 global step 18091   Batch #:  0 loss:  0.07627515\n",
      "Epoch #:  270 global step 18101   Batch #:  10 loss:  0.0766953\n",
      "Epoch #:  270 global step 18111   Batch #:  20 loss:  0.09760273\n",
      "Epoch #:  270 global step 18121   Batch #:  30 loss:  0.068268806\n",
      "Epoch #:  270 global step 18131   Batch #:  40 loss:  0.10644023\n",
      "Epoch #:  270 global step 18141   Batch #:  50 loss:  0.09822931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 54%|█████▍    | 271/500 [09:12<07:46,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  270 global step 18151   Batch #:  60 loss:  0.06808863\n",
      "Epoch #:  271 global step 18158   Batch #:  0 loss:  0.07654604\n",
      "Epoch #:  271 global step 18168   Batch #:  10 loss:  0.062100574\n",
      "Epoch #:  271 global step 18178   Batch #:  20 loss:  0.10385182\n",
      "Epoch #:  271 global step 18188   Batch #:  30 loss:  0.06761841\n",
      "Epoch #:  271 global step 18198   Batch #:  40 loss:  0.106615506\n",
      "Epoch #:  271 global step 18208   Batch #:  50 loss:  0.09862749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 54%|█████▍    | 272/500 [09:14<07:44,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  271 global step 18218   Batch #:  60 loss:  0.06777558\n",
      "Epoch #:  272 global step 18225   Batch #:  0 loss:  0.07649722\n",
      "Epoch #:  272 global step 18235   Batch #:  10 loss:  0.06631811\n",
      "Epoch #:  272 global step 18245   Batch #:  20 loss:  0.10865515\n",
      "Epoch #:  272 global step 18255   Batch #:  30 loss:  0.06606136\n",
      "Epoch #:  272 global step 18265   Batch #:  40 loss:  0.10699481\n",
      "Epoch #:  272 global step 18275   Batch #:  50 loss:  0.09565508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 55%|█████▍    | 273/500 [09:16<07:42,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  272 global step 18285   Batch #:  60 loss:  0.06749373\n",
      "Epoch #:  273 global step 18292   Batch #:  0 loss:  0.07499173\n",
      "Epoch #:  273 global step 18302   Batch #:  10 loss:  0.069568425\n",
      "Epoch #:  273 global step 18312   Batch #:  20 loss:  0.10188388\n",
      "Epoch #:  273 global step 18322   Batch #:  30 loss:  0.0668269\n",
      "Epoch #:  273 global step 18332   Batch #:  40 loss:  0.10417584\n",
      "Epoch #:  273 global step 18342   Batch #:  50 loss:  0.09663206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 55%|█████▍    | 274/500 [09:18<07:40,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  273 global step 18352   Batch #:  60 loss:  0.067958996\n",
      "Epoch #:  274 global step 18359   Batch #:  0 loss:  0.07443247\n",
      "Epoch #:  274 global step 18369   Batch #:  10 loss:  0.06718322\n",
      "Epoch #:  274 global step 18379   Batch #:  20 loss:  0.103065625\n",
      "Epoch #:  274 global step 18389   Batch #:  30 loss:  0.06792921\n",
      "Epoch #:  274 global step 18399   Batch #:  40 loss:  0.104812525\n",
      "Epoch #:  274 global step 18409   Batch #:  50 loss:  0.09835445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 275/500 [09:20<07:38,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  274 global step 18419   Batch #:  60 loss:  0.06877278\n",
      "Epoch #:  275 global step 18426   Batch #:  0 loss:  0.07453876\n",
      "Epoch #:  275 global step 18436   Batch #:  10 loss:  0.06701548\n",
      "Epoch #:  275 global step 18446   Batch #:  20 loss:  0.10436689\n",
      "Epoch #:  275 global step 18456   Batch #:  30 loss:  0.0681724\n",
      "Epoch #:  275 global step 18466   Batch #:  40 loss:  0.10500691\n",
      "Epoch #:  275 global step 18476   Batch #:  50 loss:  0.096133105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 276/500 [09:22<07:36,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  275 global step 18486   Batch #:  60 loss:  0.06898204\n",
      "Epoch #:  276 global step 18493   Batch #:  0 loss:  0.07448362\n",
      "Epoch #:  276 global step 18503   Batch #:  10 loss:  0.07181829\n",
      "Epoch #:  276 global step 18513   Batch #:  20 loss:  0.11969752\n",
      "Epoch #:  276 global step 18523   Batch #:  30 loss:  0.06660141\n",
      "Epoch #:  276 global step 18533   Batch #:  40 loss:  0.10547473\n",
      "Epoch #:  276 global step 18543   Batch #:  50 loss:  0.092891075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 277/500 [09:24<07:34,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  276 global step 18553   Batch #:  60 loss:  0.07147219\n",
      "Epoch #:  277 global step 18560   Batch #:  0 loss:  0.07741583\n",
      "Epoch #:  277 global step 18570   Batch #:  10 loss:  0.057428345\n",
      "Epoch #:  277 global step 18580   Batch #:  20 loss:  0.10261048\n",
      "Epoch #:  277 global step 18590   Batch #:  30 loss:  0.065380566\n",
      "Epoch #:  277 global step 18600   Batch #:  40 loss:  0.10656276\n",
      "Epoch #:  277 global step 18610   Batch #:  50 loss:  0.09685414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 56%|█████▌    | 278/500 [09:26<07:32,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  277 global step 18620   Batch #:  60 loss:  0.069113255\n",
      "Epoch #:  278 global step 18627   Batch #:  0 loss:  0.08010971\n",
      "Epoch #:  278 global step 18637   Batch #:  10 loss:  0.06689001\n",
      "Epoch #:  278 global step 18647   Batch #:  20 loss:  0.1091675\n",
      "Epoch #:  278 global step 18657   Batch #:  30 loss:  0.06572751\n",
      "Epoch #:  278 global step 18667   Batch #:  40 loss:  0.10440269\n",
      "Epoch #:  278 global step 18677   Batch #:  50 loss:  0.09576323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 56%|█████▌    | 279/500 [09:28<07:30,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  278 global step 18687   Batch #:  60 loss:  0.07267915\n",
      "Epoch #:  279 global step 18694   Batch #:  0 loss:  0.07727473\n",
      "Epoch #:  279 global step 18704   Batch #:  10 loss:  0.060867507\n",
      "Epoch #:  279 global step 18714   Batch #:  20 loss:  0.10319752\n",
      "Epoch #:  279 global step 18724   Batch #:  30 loss:  0.06730021\n",
      "Epoch #:  279 global step 18734   Batch #:  40 loss:  0.10945454\n",
      "Epoch #:  279 global step 18744   Batch #:  50 loss:  0.09542271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 56%|█████▌    | 280/500 [09:30<07:28,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  279 global step 18754   Batch #:  60 loss:  0.07036875\n",
      "Epoch #:  280 global step 18761   Batch #:  0 loss:  0.077473775\n",
      "Epoch #:  280 global step 18771   Batch #:  10 loss:  0.06750147\n",
      "Epoch #:  280 global step 18781   Batch #:  20 loss:  0.11136636\n",
      "Epoch #:  280 global step 18791   Batch #:  30 loss:  0.068010636\n",
      "Epoch #:  280 global step 18801   Batch #:  40 loss:  0.106814966\n",
      "Epoch #:  280 global step 18811   Batch #:  50 loss:  0.09386628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 56%|█████▌    | 281/500 [09:32<07:26,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  280 global step 18821   Batch #:  60 loss:  0.069492914\n",
      "Epoch #:  281 global step 18828   Batch #:  0 loss:  0.077026606\n",
      "Epoch #:  281 global step 18838   Batch #:  10 loss:  0.06631852\n",
      "Epoch #:  281 global step 18848   Batch #:  20 loss:  0.10383165\n",
      "Epoch #:  281 global step 18858   Batch #:  30 loss:  0.066152886\n",
      "Epoch #:  281 global step 18868   Batch #:  40 loss:  0.102551565\n",
      "Epoch #:  281 global step 18878   Batch #:  50 loss:  0.0937041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 56%|█████▋    | 282/500 [09:34<07:24,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  281 global step 18888   Batch #:  60 loss:  0.06774003\n",
      "Epoch #:  282 global step 18895   Batch #:  0 loss:  0.07794506\n",
      "Epoch #:  282 global step 18905   Batch #:  10 loss:  0.068756774\n",
      "Epoch #:  282 global step 18915   Batch #:  20 loss:  0.11355866\n",
      "Epoch #:  282 global step 18925   Batch #:  30 loss:  0.063918546\n",
      "Epoch #:  282 global step 18935   Batch #:  40 loss:  0.10105794\n",
      "Epoch #:  282 global step 18945   Batch #:  50 loss:  0.09117621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 57%|█████▋    | 283/500 [09:36<07:22,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  282 global step 18955   Batch #:  60 loss:  0.066244155\n",
      "Epoch #:  283 global step 18962   Batch #:  0 loss:  0.076267354\n",
      "Epoch #:  283 global step 18972   Batch #:  10 loss:  0.06660019\n",
      "Epoch #:  283 global step 18982   Batch #:  20 loss:  0.11171758\n",
      "Epoch #:  283 global step 18992   Batch #:  30 loss:  0.06373351\n",
      "Epoch #:  283 global step 19002   Batch #:  40 loss:  0.10462877\n",
      "Epoch #:  283 global step 19012   Batch #:  50 loss:  0.094325505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 57%|█████▋    | 284/500 [09:38<07:20,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  283 global step 19022   Batch #:  60 loss:  0.06504295\n",
      "Epoch #:  284 global step 19029   Batch #:  0 loss:  0.076589294\n",
      "Epoch #:  284 global step 19039   Batch #:  10 loss:  0.06265126\n",
      "Epoch #:  284 global step 19049   Batch #:  20 loss:  0.10300808\n",
      "Epoch #:  284 global step 19059   Batch #:  30 loss:  0.06433159\n",
      "Epoch #:  284 global step 19069   Batch #:  40 loss:  0.10020345\n",
      "Epoch #:  284 global step 19079   Batch #:  50 loss:  0.09156917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 57%|█████▋    | 285/500 [09:40<07:18,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  284 global step 19089   Batch #:  60 loss:  0.06378543\n",
      "Epoch #:  285 global step 19096   Batch #:  0 loss:  0.07372065\n",
      "Epoch #:  285 global step 19106   Batch #:  10 loss:  0.062123235\n",
      "Epoch #:  285 global step 19116   Batch #:  20 loss:  0.10266319\n",
      "Epoch #:  285 global step 19126   Batch #:  30 loss:  0.0637922\n",
      "Epoch #:  285 global step 19136   Batch #:  40 loss:  0.10365152\n",
      "Epoch #:  285 global step 19146   Batch #:  50 loss:  0.0971292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 57%|█████▋    | 286/500 [09:42<07:16,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  285 global step 19156   Batch #:  60 loss:  0.063624814\n",
      "Epoch #:  286 global step 19163   Batch #:  0 loss:  0.077171035\n",
      "Epoch #:  286 global step 19173   Batch #:  10 loss:  0.073361725\n",
      "Epoch #:  286 global step 19183   Batch #:  20 loss:  0.09660606\n",
      "Epoch #:  286 global step 19193   Batch #:  30 loss:  0.066854335\n",
      "Epoch #:  286 global step 19203   Batch #:  40 loss:  0.103057735\n",
      "Epoch #:  286 global step 19213   Batch #:  50 loss:  0.09373082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 57%|█████▋    | 287/500 [09:44<07:14,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  286 global step 19223   Batch #:  60 loss:  0.06251693\n",
      "Epoch #:  287 global step 19230   Batch #:  0 loss:  0.076850966\n",
      "Epoch #:  287 global step 19240   Batch #:  10 loss:  0.0637687\n",
      "Epoch #:  287 global step 19250   Batch #:  20 loss:  0.093420036\n",
      "Epoch #:  287 global step 19260   Batch #:  30 loss:  0.06255814\n",
      "Epoch #:  287 global step 19270   Batch #:  40 loss:  0.10777395\n",
      "Epoch #:  287 global step 19280   Batch #:  50 loss:  0.09367515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 58%|█████▊    | 288/500 [09:46<07:12,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  287 global step 19290   Batch #:  60 loss:  0.06144807\n",
      "Epoch #:  288 global step 19297   Batch #:  0 loss:  0.07496132\n",
      "Epoch #:  288 global step 19307   Batch #:  10 loss:  0.07653383\n",
      "Epoch #:  288 global step 19317   Batch #:  20 loss:  0.09310324\n",
      "Epoch #:  288 global step 19327   Batch #:  30 loss:  0.06502024\n",
      "Epoch #:  288 global step 19337   Batch #:  40 loss:  0.10461253\n",
      "Epoch #:  288 global step 19347   Batch #:  50 loss:  0.09247421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 58%|█████▊    | 289/500 [09:48<07:09,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  288 global step 19357   Batch #:  60 loss:  0.060938194\n",
      "Epoch #:  289 global step 19364   Batch #:  0 loss:  0.07635359\n",
      "Epoch #:  289 global step 19374   Batch #:  10 loss:  0.0618305\n",
      "Epoch #:  289 global step 19384   Batch #:  20 loss:  0.10338148\n",
      "Epoch #:  289 global step 19394   Batch #:  30 loss:  0.06253925\n",
      "Epoch #:  289 global step 19404   Batch #:  40 loss:  0.10222268\n",
      "Epoch #:  289 global step 19414   Batch #:  50 loss:  0.09536012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 58%|█████▊    | 290/500 [09:50<07:07,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  289 global step 19424   Batch #:  60 loss:  0.060752414\n",
      "Epoch #:  290 global step 19431   Batch #:  0 loss:  0.079814635\n",
      "Epoch #:  290 global step 19441   Batch #:  10 loss:  0.072129235\n",
      "Epoch #:  290 global step 19451   Batch #:  20 loss:  0.17948501\n",
      "Epoch #:  290 global step 19461   Batch #:  30 loss:  0.098710746\n",
      "Epoch #:  290 global step 19471   Batch #:  40 loss:  0.11846437\n",
      "Epoch #:  290 global step 19481   Batch #:  50 loss:  0.12681091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 58%|█████▊    | 291/500 [09:53<07:05,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  290 global step 19491   Batch #:  60 loss:  0.085767865\n",
      "Epoch #:  291 global step 19498   Batch #:  0 loss:  0.11888\n",
      "Epoch #:  291 global step 19508   Batch #:  10 loss:  0.07779802\n",
      "Epoch #:  291 global step 19518   Batch #:  20 loss:  0.094556294\n",
      "Epoch #:  291 global step 19528   Batch #:  30 loss:  0.068779945\n",
      "Epoch #:  291 global step 19538   Batch #:  40 loss:  0.11277924\n",
      "Epoch #:  291 global step 19548   Batch #:  50 loss:  0.11089207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 58%|█████▊    | 292/500 [09:55<07:03,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  291 global step 19558   Batch #:  60 loss:  0.06847366\n",
      "Epoch #:  292 global step 19565   Batch #:  0 loss:  0.08282903\n",
      "Epoch #:  292 global step 19575   Batch #:  10 loss:  0.0825376\n",
      "Epoch #:  292 global step 19585   Batch #:  20 loss:  0.11544111\n",
      "Epoch #:  292 global step 19595   Batch #:  30 loss:  0.07964591\n",
      "Epoch #:  292 global step 19605   Batch #:  40 loss:  0.19222218\n",
      "Epoch #:  292 global step 19615   Batch #:  50 loss:  0.113358505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 59%|█████▊    | 293/500 [09:57<07:01,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  292 global step 19625   Batch #:  60 loss:  0.081237115\n",
      "Epoch #:  293 global step 19632   Batch #:  0 loss:  0.13333654\n",
      "Epoch #:  293 global step 19642   Batch #:  10 loss:  0.16093242\n",
      "Epoch #:  293 global step 19652   Batch #:  20 loss:  0.161583\n",
      "Epoch #:  293 global step 19662   Batch #:  30 loss:  0.0688479\n",
      "Epoch #:  293 global step 19672   Batch #:  40 loss:  0.10489973\n",
      "Epoch #:  293 global step 19682   Batch #:  50 loss:  0.10314408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 59%|█████▉    | 294/500 [09:59<06:59,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  293 global step 19692   Batch #:  60 loss:  0.15690792\n",
      "Epoch #:  294 global step 19699   Batch #:  0 loss:  0.0943535\n",
      "Epoch #:  294 global step 19709   Batch #:  10 loss:  0.101001315\n",
      "Epoch #:  294 global step 19719   Batch #:  20 loss:  0.13556209\n",
      "Epoch #:  294 global step 19729   Batch #:  30 loss:  0.053690314\n",
      "Epoch #:  294 global step 19739   Batch #:  40 loss:  0.10192772\n",
      "Epoch #:  294 global step 19749   Batch #:  50 loss:  0.102916196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 59%|█████▉    | 295/500 [10:01<06:57,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  294 global step 19759   Batch #:  60 loss:  0.07402774\n",
      "Epoch #:  295 global step 19766   Batch #:  0 loss:  0.08997918\n",
      "Epoch #:  295 global step 19776   Batch #:  10 loss:  0.074718244\n",
      "Epoch #:  295 global step 19786   Batch #:  20 loss:  0.1318695\n",
      "Epoch #:  295 global step 19796   Batch #:  30 loss:  0.1603616\n",
      "Epoch #:  295 global step 19806   Batch #:  40 loss:  0.23119394\n",
      "Epoch #:  295 global step 19816   Batch #:  50 loss:  0.1260698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 59%|█████▉    | 296/500 [10:03<06:55,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  295 global step 19826   Batch #:  60 loss:  0.10239774\n",
      "Epoch #:  296 global step 19833   Batch #:  0 loss:  0.17075631\n",
      "Epoch #:  296 global step 19843   Batch #:  10 loss:  0.11016214\n",
      "Epoch #:  296 global step 19853   Batch #:  20 loss:  0.17982058\n",
      "Epoch #:  296 global step 19863   Batch #:  30 loss:  0.086595364\n",
      "Epoch #:  296 global step 19873   Batch #:  40 loss:  0.10788593\n",
      "Epoch #:  296 global step 19883   Batch #:  50 loss:  0.13917752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 59%|█████▉    | 297/500 [10:05<06:53,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  296 global step 19893   Batch #:  60 loss:  0.10436015\n",
      "Epoch #:  297 global step 19900   Batch #:  0 loss:  0.110721365\n",
      "Epoch #:  297 global step 19910   Batch #:  10 loss:  0.12355553\n",
      "Epoch #:  297 global step 19920   Batch #:  20 loss:  0.12222274\n",
      "Epoch #:  297 global step 19930   Batch #:  30 loss:  0.046170957\n",
      "Epoch #:  297 global step 19940   Batch #:  40 loss:  0.10520001\n",
      "Epoch #:  297 global step 19950   Batch #:  50 loss:  0.107900746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 60%|█████▉    | 298/500 [10:07<06:51,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  297 global step 19960   Batch #:  60 loss:  0.079302385\n",
      "Epoch #:  298 global step 19967   Batch #:  0 loss:  0.087914705\n",
      "Epoch #:  298 global step 19977   Batch #:  10 loss:  0.096427776\n",
      "Epoch #:  298 global step 19987   Batch #:  20 loss:  0.10814563\n",
      "Epoch #:  298 global step 19997   Batch #:  30 loss:  0.05087961\n",
      "Epoch #:  298 global step 20007   Batch #:  40 loss:  0.103469625\n",
      "Epoch #:  298 global step 20017   Batch #:  50 loss:  0.0984073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 60%|█████▉    | 299/500 [10:09<06:49,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  298 global step 20027   Batch #:  60 loss:  0.07406915\n",
      "Epoch #:  299 global step 20034   Batch #:  0 loss:  0.12260894\n",
      "Epoch #:  299 global step 20044   Batch #:  10 loss:  0.07717507\n",
      "Epoch #:  299 global step 20054   Batch #:  20 loss:  0.09216128\n",
      "Epoch #:  299 global step 20064   Batch #:  30 loss:  0.053792916\n",
      "Epoch #:  299 global step 20074   Batch #:  40 loss:  0.103064656\n",
      "Epoch #:  299 global step 20084   Batch #:  50 loss:  0.108811915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 300/500 [10:11<06:47,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  299 global step 20094   Batch #:  60 loss:  0.07665649\n",
      "Epoch #:  300 global step 20101   Batch #:  0 loss:  0.08323646\n",
      "Epoch #:  300 global step 20111   Batch #:  10 loss:  0.0801892\n",
      "Epoch #:  300 global step 20121   Batch #:  20 loss:  0.10581396\n",
      "Epoch #:  300 global step 20131   Batch #:  30 loss:  0.049182728\n",
      "Epoch #:  300 global step 20141   Batch #:  40 loss:  0.10539671\n",
      "Epoch #:  300 global step 20151   Batch #:  50 loss:  0.09772462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 301/500 [10:13<06:45,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  300 global step 20161   Batch #:  60 loss:  0.075067215\n",
      "Epoch #:  301 global step 20168   Batch #:  0 loss:  0.07818456\n",
      "Epoch #:  301 global step 20178   Batch #:  10 loss:  0.08906776\n",
      "Epoch #:  301 global step 20188   Batch #:  20 loss:  0.106181435\n",
      "Epoch #:  301 global step 20198   Batch #:  30 loss:  0.048813913\n",
      "Epoch #:  301 global step 20208   Batch #:  40 loss:  0.1049821\n",
      "Epoch #:  301 global step 20218   Batch #:  50 loss:  0.09298944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 302/500 [10:15<06:43,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  301 global step 20228   Batch #:  60 loss:  0.07413915\n",
      "Epoch #:  302 global step 20235   Batch #:  0 loss:  0.06713011\n",
      "Epoch #:  302 global step 20245   Batch #:  10 loss:  0.08665111\n",
      "Epoch #:  302 global step 20255   Batch #:  20 loss:  0.10939108\n",
      "Epoch #:  302 global step 20265   Batch #:  30 loss:  0.051891394\n",
      "Epoch #:  302 global step 20275   Batch #:  40 loss:  0.10230111\n",
      "Epoch #:  302 global step 20285   Batch #:  50 loss:  0.09713496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 61%|██████    | 303/500 [10:17<06:41,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  302 global step 20295   Batch #:  60 loss:  0.07583399\n",
      "Epoch #:  303 global step 20302   Batch #:  0 loss:  0.08451334\n",
      "Epoch #:  303 global step 20312   Batch #:  10 loss:  0.08850444\n",
      "Epoch #:  303 global step 20322   Batch #:  20 loss:  0.10426717\n",
      "Epoch #:  303 global step 20332   Batch #:  30 loss:  0.054202158\n",
      "Epoch #:  303 global step 20342   Batch #:  40 loss:  0.10235436\n",
      "Epoch #:  303 global step 20352   Batch #:  50 loss:  0.10063443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 61%|██████    | 304/500 [10:19<06:39,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  303 global step 20362   Batch #:  60 loss:  0.0748844\n",
      "Epoch #:  304 global step 20369   Batch #:  0 loss:  0.065826066\n",
      "Epoch #:  304 global step 20379   Batch #:  10 loss:  0.09154226\n",
      "Epoch #:  304 global step 20389   Batch #:  20 loss:  0.103878975\n",
      "Epoch #:  304 global step 20399   Batch #:  30 loss:  0.05280444\n",
      "Epoch #:  304 global step 20409   Batch #:  40 loss:  0.10070369\n",
      "Epoch #:  304 global step 20419   Batch #:  50 loss:  0.09874706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 61%|██████    | 305/500 [10:21<06:37,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  304 global step 20429   Batch #:  60 loss:  0.07426531\n",
      "Epoch #:  305 global step 20436   Batch #:  0 loss:  0.06556733\n",
      "Epoch #:  305 global step 20446   Batch #:  10 loss:  0.08868834\n",
      "Epoch #:  305 global step 20456   Batch #:  20 loss:  0.102254085\n",
      "Epoch #:  305 global step 20466   Batch #:  30 loss:  0.05267173\n",
      "Epoch #:  305 global step 20476   Batch #:  40 loss:  0.10269553\n",
      "Epoch #:  305 global step 20486   Batch #:  50 loss:  0.09726877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 61%|██████    | 306/500 [10:23<06:35,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  305 global step 20496   Batch #:  60 loss:  0.07266473\n",
      "Epoch #:  306 global step 20503   Batch #:  0 loss:  0.0797504\n",
      "Epoch #:  306 global step 20513   Batch #:  10 loss:  0.08865298\n",
      "Epoch #:  306 global step 20523   Batch #:  20 loss:  0.15809785\n",
      "Epoch #:  306 global step 20533   Batch #:  30 loss:  0.04791931\n",
      "Epoch #:  306 global step 20543   Batch #:  40 loss:  0.0986487\n",
      "Epoch #:  306 global step 20553   Batch #:  50 loss:  0.091922455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 61%|██████▏   | 307/500 [10:25<06:33,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  306 global step 20563   Batch #:  60 loss:  0.07328967\n",
      "Epoch #:  307 global step 20570   Batch #:  0 loss:  0.07055187\n",
      "Epoch #:  307 global step 20580   Batch #:  10 loss:  0.07761879\n",
      "Epoch #:  307 global step 20590   Batch #:  20 loss:  0.10149156\n",
      "Epoch #:  307 global step 20600   Batch #:  30 loss:  0.05128609\n",
      "Epoch #:  307 global step 20610   Batch #:  40 loss:  0.089658834\n",
      "Epoch #:  307 global step 20620   Batch #:  50 loss:  0.08216234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 62%|██████▏   | 308/500 [10:27<06:31,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  307 global step 20630   Batch #:  60 loss:  0.06828956\n",
      "Epoch #:  308 global step 20637   Batch #:  0 loss:  0.0622074\n",
      "Epoch #:  308 global step 20647   Batch #:  10 loss:  0.07555321\n",
      "Epoch #:  308 global step 20657   Batch #:  20 loss:  0.09859294\n",
      "Epoch #:  308 global step 20667   Batch #:  30 loss:  0.035057936\n",
      "Epoch #:  308 global step 20677   Batch #:  40 loss:  0.09745174\n",
      "Epoch #:  308 global step 20687   Batch #:  50 loss:  0.08120097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 62%|██████▏   | 309/500 [10:29<06:29,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  308 global step 20697   Batch #:  60 loss:  0.06301534\n",
      "Epoch #:  309 global step 20704   Batch #:  0 loss:  0.061096363\n",
      "Epoch #:  309 global step 20714   Batch #:  10 loss:  0.06736112\n",
      "Epoch #:  309 global step 20724   Batch #:  20 loss:  0.092883475\n",
      "Epoch #:  309 global step 20734   Batch #:  30 loss:  0.03685532\n",
      "Epoch #:  309 global step 20744   Batch #:  40 loss:  0.09451028\n",
      "Epoch #:  309 global step 20754   Batch #:  50 loss:  0.080176294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 62%|██████▏   | 310/500 [10:31<06:27,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  309 global step 20764   Batch #:  60 loss:  0.06501178\n",
      "Epoch #:  310 global step 20771   Batch #:  0 loss:  0.059376825\n",
      "Epoch #:  310 global step 20781   Batch #:  10 loss:  0.062384687\n",
      "Epoch #:  310 global step 20791   Batch #:  20 loss:  0.10045864\n",
      "Epoch #:  310 global step 20801   Batch #:  30 loss:  0.03736292\n",
      "Epoch #:  310 global step 20811   Batch #:  40 loss:  0.09193324\n",
      "Epoch #:  310 global step 20821   Batch #:  50 loss:  0.08098701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 62%|██████▏   | 311/500 [10:33<06:25,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  310 global step 20831   Batch #:  60 loss:  0.0614003\n",
      "Epoch #:  311 global step 20838   Batch #:  0 loss:  0.06018669\n",
      "Epoch #:  311 global step 20848   Batch #:  10 loss:  0.06387139\n",
      "Epoch #:  311 global step 20858   Batch #:  20 loss:  0.10251695\n",
      "Epoch #:  311 global step 20868   Batch #:  30 loss:  0.037955493\n",
      "Epoch #:  311 global step 20878   Batch #:  40 loss:  0.09225944\n",
      "Epoch #:  311 global step 20888   Batch #:  50 loss:  0.08154047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 62%|██████▏   | 312/500 [10:35<06:23,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  311 global step 20898   Batch #:  60 loss:  0.0683619\n",
      "Epoch #:  312 global step 20905   Batch #:  0 loss:  0.066761985\n",
      "Epoch #:  312 global step 20915   Batch #:  10 loss:  0.07511579\n",
      "Epoch #:  312 global step 20925   Batch #:  20 loss:  0.10275715\n",
      "Epoch #:  312 global step 20935   Batch #:  30 loss:  0.048938137\n",
      "Epoch #:  312 global step 20945   Batch #:  40 loss:  0.09157617\n",
      "Epoch #:  312 global step 20955   Batch #:  50 loss:  0.080340505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 63%|██████▎   | 313/500 [10:37<06:21,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  312 global step 20965   Batch #:  60 loss:  0.06375718\n",
      "Epoch #:  313 global step 20972   Batch #:  0 loss:  0.06656852\n",
      "Epoch #:  313 global step 20982   Batch #:  10 loss:  0.06707787\n",
      "Epoch #:  313 global step 20992   Batch #:  20 loss:  0.09775484\n",
      "Epoch #:  313 global step 21002   Batch #:  30 loss:  0.04481987\n",
      "Epoch #:  313 global step 21012   Batch #:  40 loss:  0.09454507\n",
      "Epoch #:  313 global step 21022   Batch #:  50 loss:  0.07761537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 63%|██████▎   | 314/500 [10:39<06:19,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  313 global step 21032   Batch #:  60 loss:  0.06886911\n",
      "Epoch #:  314 global step 21039   Batch #:  0 loss:  0.066856764\n",
      "Epoch #:  314 global step 21049   Batch #:  10 loss:  0.065422654\n",
      "Epoch #:  314 global step 21059   Batch #:  20 loss:  0.097165264\n",
      "Epoch #:  314 global step 21069   Batch #:  30 loss:  0.04487368\n",
      "Epoch #:  314 global step 21079   Batch #:  40 loss:  0.09531142\n",
      "Epoch #:  314 global step 21089   Batch #:  50 loss:  0.07840879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 63%|██████▎   | 315/500 [10:41<06:16,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  314 global step 21099   Batch #:  60 loss:  0.0678019\n",
      "Epoch #:  315 global step 21106   Batch #:  0 loss:  0.065769956\n",
      "Epoch #:  315 global step 21116   Batch #:  10 loss:  0.067848444\n",
      "Epoch #:  315 global step 21126   Batch #:  20 loss:  0.10537623\n",
      "Epoch #:  315 global step 21136   Batch #:  30 loss:  0.04223565\n",
      "Epoch #:  315 global step 21146   Batch #:  40 loss:  0.09129384\n",
      "Epoch #:  315 global step 21156   Batch #:  50 loss:  0.07686564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 63%|██████▎   | 316/500 [10:43<06:14,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  315 global step 21166   Batch #:  60 loss:  0.067989595\n",
      "Epoch #:  316 global step 21173   Batch #:  0 loss:  0.06382356\n",
      "Epoch #:  316 global step 21183   Batch #:  10 loss:  0.06061199\n",
      "Epoch #:  316 global step 21193   Batch #:  20 loss:  0.102904044\n",
      "Epoch #:  316 global step 21203   Batch #:  30 loss:  0.040712945\n",
      "Epoch #:  316 global step 21213   Batch #:  40 loss:  0.09154562\n",
      "Epoch #:  316 global step 21223   Batch #:  50 loss:  0.07670075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 63%|██████▎   | 317/500 [10:45<06:12,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  316 global step 21233   Batch #:  60 loss:  0.059668366\n",
      "Epoch #:  317 global step 21240   Batch #:  0 loss:  0.066134915\n",
      "Epoch #:  317 global step 21250   Batch #:  10 loss:  0.06602489\n",
      "Epoch #:  317 global step 21260   Batch #:  20 loss:  0.099878\n",
      "Epoch #:  317 global step 21270   Batch #:  30 loss:  0.04178345\n",
      "Epoch #:  317 global step 21280   Batch #:  40 loss:  0.09466781\n",
      "Epoch #:  317 global step 21290   Batch #:  50 loss:  0.08665837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 64%|██████▎   | 318/500 [10:47<06:10,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  317 global step 21300   Batch #:  60 loss:  0.06508757\n",
      "Epoch #:  318 global step 21307   Batch #:  0 loss:  0.06423681\n",
      "Epoch #:  318 global step 21317   Batch #:  10 loss:  0.0667462\n",
      "Epoch #:  318 global step 21327   Batch #:  20 loss:  0.09297978\n",
      "Epoch #:  318 global step 21337   Batch #:  30 loss:  0.03824114\n",
      "Epoch #:  318 global step 21347   Batch #:  40 loss:  0.09272358\n",
      "Epoch #:  318 global step 21357   Batch #:  50 loss:  0.08282931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 64%|██████▍   | 319/500 [10:49<06:08,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  318 global step 21367   Batch #:  60 loss:  0.059972335\n",
      "Epoch #:  319 global step 21374   Batch #:  0 loss:  0.0661592\n",
      "Epoch #:  319 global step 21384   Batch #:  10 loss:  0.067160726\n",
      "Epoch #:  319 global step 21394   Batch #:  20 loss:  0.09886494\n",
      "Epoch #:  319 global step 21404   Batch #:  30 loss:  0.043099277\n",
      "Epoch #:  319 global step 21414   Batch #:  40 loss:  0.0916583\n",
      "Epoch #:  319 global step 21424   Batch #:  50 loss:  0.08242128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 64%|██████▍   | 320/500 [10:52<06:06,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  319 global step 21434   Batch #:  60 loss:  0.06705545\n",
      "Epoch #:  320 global step 21441   Batch #:  0 loss:  0.07445703\n",
      "Epoch #:  320 global step 21451   Batch #:  10 loss:  0.06573792\n",
      "Epoch #:  320 global step 21461   Batch #:  20 loss:  0.09853701\n",
      "Epoch #:  320 global step 21471   Batch #:  30 loss:  0.042968713\n",
      "Epoch #:  320 global step 21481   Batch #:  40 loss:  0.09542384\n",
      "Epoch #:  320 global step 21491   Batch #:  50 loss:  0.076401465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 64%|██████▍   | 321/500 [10:54<06:04,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  320 global step 21501   Batch #:  60 loss:  0.07482733\n",
      "Epoch #:  321 global step 21508   Batch #:  0 loss:  0.08429389\n",
      "Epoch #:  321 global step 21518   Batch #:  10 loss:  0.063828915\n",
      "Epoch #:  321 global step 21528   Batch #:  20 loss:  0.094615005\n",
      "Epoch #:  321 global step 21538   Batch #:  30 loss:  0.04282472\n",
      "Epoch #:  321 global step 21548   Batch #:  40 loss:  0.09358805\n",
      "Epoch #:  321 global step 21558   Batch #:  50 loss:  0.09099465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 64%|██████▍   | 322/500 [10:56<06:02,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  321 global step 21568   Batch #:  60 loss:  0.06726527\n",
      "Epoch #:  322 global step 21575   Batch #:  0 loss:  0.065724306\n",
      "Epoch #:  322 global step 21585   Batch #:  10 loss:  0.06369936\n",
      "Epoch #:  322 global step 21595   Batch #:  20 loss:  0.088809974\n",
      "Epoch #:  322 global step 21605   Batch #:  30 loss:  0.04127736\n",
      "Epoch #:  322 global step 21615   Batch #:  40 loss:  0.09240465\n",
      "Epoch #:  322 global step 21625   Batch #:  50 loss:  0.08550663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 323/500 [10:58<06:00,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  322 global step 21635   Batch #:  60 loss:  0.07543694\n",
      "Epoch #:  323 global step 21642   Batch #:  0 loss:  0.066155516\n",
      "Epoch #:  323 global step 21652   Batch #:  10 loss:  0.061001666\n",
      "Epoch #:  323 global step 21662   Batch #:  20 loss:  0.09496414\n",
      "Epoch #:  323 global step 21672   Batch #:  30 loss:  0.04299545\n",
      "Epoch #:  323 global step 21682   Batch #:  40 loss:  0.093129404\n",
      "Epoch #:  323 global step 21692   Batch #:  50 loss:  0.08451279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 324/500 [11:00<05:58,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  323 global step 21702   Batch #:  60 loss:  0.06886049\n",
      "Epoch #:  324 global step 21709   Batch #:  0 loss:  0.06407951\n",
      "Epoch #:  324 global step 21719   Batch #:  10 loss:  0.06099002\n",
      "Epoch #:  324 global step 21729   Batch #:  20 loss:  0.09843321\n",
      "Epoch #:  324 global step 21739   Batch #:  30 loss:  0.042876787\n",
      "Epoch #:  324 global step 21749   Batch #:  40 loss:  0.091040626\n",
      "Epoch #:  324 global step 21759   Batch #:  50 loss:  0.08581498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 65%|██████▌   | 325/500 [11:02<05:56,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  324 global step 21769   Batch #:  60 loss:  0.06907017\n",
      "Epoch #:  325 global step 21776   Batch #:  0 loss:  0.0638826\n",
      "Epoch #:  325 global step 21786   Batch #:  10 loss:  0.061728034\n",
      "Epoch #:  325 global step 21796   Batch #:  20 loss:  0.10010987\n",
      "Epoch #:  325 global step 21806   Batch #:  30 loss:  0.035947226\n",
      "Epoch #:  325 global step 21816   Batch #:  40 loss:  0.09364552\n",
      "Epoch #:  325 global step 21826   Batch #:  50 loss:  0.08947778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 65%|██████▌   | 326/500 [11:04<05:54,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  325 global step 21836   Batch #:  60 loss:  0.07790147\n",
      "Epoch #:  326 global step 21843   Batch #:  0 loss:  0.06552743\n",
      "Epoch #:  326 global step 21853   Batch #:  10 loss:  0.06052711\n",
      "Epoch #:  326 global step 21863   Batch #:  20 loss:  0.092741266\n",
      "Epoch #:  326 global step 21873   Batch #:  30 loss:  0.037050907\n",
      "Epoch #:  326 global step 21883   Batch #:  40 loss:  0.12536283\n",
      "Epoch #:  326 global step 21893   Batch #:  50 loss:  0.12819593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 65%|██████▌   | 327/500 [11:06<05:52,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  326 global step 21903   Batch #:  60 loss:  0.09069729\n",
      "Epoch #:  327 global step 21910   Batch #:  0 loss:  0.08694439\n",
      "Epoch #:  327 global step 21920   Batch #:  10 loss:  0.07186799\n",
      "Epoch #:  327 global step 21930   Batch #:  20 loss:  0.14647642\n",
      "Epoch #:  327 global step 21940   Batch #:  30 loss:  0.06743506\n",
      "Epoch #:  327 global step 21950   Batch #:  40 loss:  0.10970493\n",
      "Epoch #:  327 global step 21960   Batch #:  50 loss:  0.12898226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 66%|██████▌   | 328/500 [11:08<05:50,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  327 global step 21970   Batch #:  60 loss:  0.08509804\n",
      "Epoch #:  328 global step 21977   Batch #:  0 loss:  0.06955051\n",
      "Epoch #:  328 global step 21987   Batch #:  10 loss:  0.061092924\n",
      "Epoch #:  328 global step 21997   Batch #:  20 loss:  0.09566554\n",
      "Epoch #:  328 global step 22007   Batch #:  30 loss:  0.063777454\n",
      "Epoch #:  328 global step 22017   Batch #:  40 loss:  0.102100216\n",
      "Epoch #:  328 global step 22027   Batch #:  50 loss:  0.092269875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 66%|██████▌   | 329/500 [11:10<05:48,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  328 global step 22037   Batch #:  60 loss:  0.067770176\n",
      "Epoch #:  329 global step 22044   Batch #:  0 loss:  0.06425453\n",
      "Epoch #:  329 global step 22054   Batch #:  10 loss:  0.05747149\n",
      "Epoch #:  329 global step 22064   Batch #:  20 loss:  0.081938826\n",
      "Epoch #:  329 global step 22074   Batch #:  30 loss:  0.06344422\n",
      "Epoch #:  329 global step 22084   Batch #:  40 loss:  0.099751316\n",
      "Epoch #:  329 global step 22094   Batch #:  50 loss:  0.083700255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 66%|██████▌   | 330/500 [11:12<05:46,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  329 global step 22104   Batch #:  60 loss:  0.068249196\n",
      "Epoch #:  330 global step 22111   Batch #:  0 loss:  0.06842812\n",
      "Epoch #:  330 global step 22121   Batch #:  10 loss:  0.059544623\n",
      "Epoch #:  330 global step 22131   Batch #:  20 loss:  0.0859056\n",
      "Epoch #:  330 global step 22141   Batch #:  30 loss:  0.0617389\n",
      "Epoch #:  330 global step 22151   Batch #:  40 loss:  0.10146814\n",
      "Epoch #:  330 global step 22161   Batch #:  50 loss:  0.08693585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 66%|██████▌   | 331/500 [11:14<05:44,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  330 global step 22171   Batch #:  60 loss:  0.07019296\n",
      "Epoch #:  331 global step 22178   Batch #:  0 loss:  0.06564787\n",
      "Epoch #:  331 global step 22188   Batch #:  10 loss:  0.05868406\n",
      "Epoch #:  331 global step 22198   Batch #:  20 loss:  0.14464529\n",
      "Epoch #:  331 global step 22208   Batch #:  30 loss:  0.043201283\n",
      "Epoch #:  331 global step 22218   Batch #:  40 loss:  0.08810239\n",
      "Epoch #:  331 global step 22228   Batch #:  50 loss:  0.073003836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 66%|██████▋   | 332/500 [11:16<05:42,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  331 global step 22238   Batch #:  60 loss:  0.06658596\n",
      "Epoch #:  332 global step 22245   Batch #:  0 loss:  0.07375768\n",
      "Epoch #:  332 global step 22255   Batch #:  10 loss:  0.050970115\n",
      "Epoch #:  332 global step 22265   Batch #:  20 loss:  0.13690479\n",
      "Epoch #:  332 global step 22275   Batch #:  30 loss:  0.062695265\n",
      "Epoch #:  332 global step 22285   Batch #:  40 loss:  0.097103395\n",
      "Epoch #:  332 global step 22295   Batch #:  50 loss:  0.08557791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 333/500 [11:18<05:40,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  332 global step 22305   Batch #:  60 loss:  0.06477489\n",
      "Epoch #:  333 global step 22312   Batch #:  0 loss:  0.06853506\n",
      "Epoch #:  333 global step 22322   Batch #:  10 loss:  0.054381784\n",
      "Epoch #:  333 global step 22332   Batch #:  20 loss:  0.13674729\n",
      "Epoch #:  333 global step 22342   Batch #:  30 loss:  0.06242516\n",
      "Epoch #:  333 global step 22352   Batch #:  40 loss:  0.098892726\n",
      "Epoch #:  333 global step 22362   Batch #:  50 loss:  0.08576121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 334/500 [11:20<05:38,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  333 global step 22372   Batch #:  60 loss:  0.06350319\n",
      "Epoch #:  334 global step 22379   Batch #:  0 loss:  0.06585898\n",
      "Epoch #:  334 global step 22389   Batch #:  10 loss:  0.05175575\n",
      "Epoch #:  334 global step 22399   Batch #:  20 loss:  0.13923365\n",
      "Epoch #:  334 global step 22409   Batch #:  30 loss:  0.038882885\n",
      "Epoch #:  334 global step 22419   Batch #:  40 loss:  0.08752784\n",
      "Epoch #:  334 global step 22429   Batch #:  50 loss:  0.08379799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 335/500 [11:22<05:36,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  334 global step 22439   Batch #:  60 loss:  0.0725829\n",
      "Epoch #:  335 global step 22446   Batch #:  0 loss:  0.067421265\n",
      "Epoch #:  335 global step 22456   Batch #:  10 loss:  0.049652483\n",
      "Epoch #:  335 global step 22466   Batch #:  20 loss:  0.14727822\n",
      "Epoch #:  335 global step 22476   Batch #:  30 loss:  0.03996266\n",
      "Epoch #:  335 global step 22486   Batch #:  40 loss:  0.0855763\n",
      "Epoch #:  335 global step 22496   Batch #:  50 loss:  0.08316609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 336/500 [11:24<05:34,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  335 global step 22506   Batch #:  60 loss:  0.06957906\n",
      "Epoch #:  336 global step 22513   Batch #:  0 loss:  0.063931\n",
      "Epoch #:  336 global step 22523   Batch #:  10 loss:  0.049982537\n",
      "Epoch #:  336 global step 22533   Batch #:  20 loss:  0.14819835\n",
      "Epoch #:  336 global step 22543   Batch #:  30 loss:  0.03973849\n",
      "Epoch #:  336 global step 22553   Batch #:  40 loss:  0.088101625\n",
      "Epoch #:  336 global step 22563   Batch #:  50 loss:  0.081350066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 337/500 [11:26<05:32,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  336 global step 22573   Batch #:  60 loss:  0.06877517\n",
      "Epoch #:  337 global step 22580   Batch #:  0 loss:  0.06603873\n",
      "Epoch #:  337 global step 22590   Batch #:  10 loss:  0.045904543\n",
      "Epoch #:  337 global step 22600   Batch #:  20 loss:  0.14793722\n",
      "Epoch #:  337 global step 22610   Batch #:  30 loss:  0.039087776\n",
      "Epoch #:  337 global step 22620   Batch #:  40 loss:  0.083257474\n",
      "Epoch #:  337 global step 22630   Batch #:  50 loss:  0.082090795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 68%|██████▊   | 338/500 [11:28<05:30,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  337 global step 22640   Batch #:  60 loss:  0.07046223\n",
      "Epoch #:  338 global step 22647   Batch #:  0 loss:  0.06524125\n",
      "Epoch #:  338 global step 22657   Batch #:  10 loss:  0.048927978\n",
      "Epoch #:  338 global step 22667   Batch #:  20 loss:  0.14766516\n",
      "Epoch #:  338 global step 22677   Batch #:  30 loss:  0.031700835\n",
      "Epoch #:  338 global step 22687   Batch #:  40 loss:  0.08604654\n",
      "Epoch #:  338 global step 22697   Batch #:  50 loss:  0.081559435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 68%|██████▊   | 339/500 [11:30<05:27,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  338 global step 22707   Batch #:  60 loss:  0.06815945\n",
      "Epoch #:  339 global step 22714   Batch #:  0 loss:  0.06517805\n",
      "Epoch #:  339 global step 22724   Batch #:  10 loss:  0.052607536\n",
      "Epoch #:  339 global step 22734   Batch #:  20 loss:  0.1505371\n",
      "Epoch #:  339 global step 22744   Batch #:  30 loss:  0.038923264\n",
      "Epoch #:  339 global step 22754   Batch #:  40 loss:  0.08508497\n",
      "Epoch #:  339 global step 22764   Batch #:  50 loss:  0.081381574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 68%|██████▊   | 340/500 [11:32<05:25,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  339 global step 22774   Batch #:  60 loss:  0.067331254\n",
      "Epoch #:  340 global step 22781   Batch #:  0 loss:  0.068338916\n",
      "Epoch #:  340 global step 22791   Batch #:  10 loss:  0.047379766\n",
      "Epoch #:  340 global step 22801   Batch #:  20 loss:  0.14830971\n",
      "Epoch #:  340 global step 22811   Batch #:  30 loss:  0.038307514\n",
      "Epoch #:  340 global step 22821   Batch #:  40 loss:  0.0853973\n",
      "Epoch #:  340 global step 22831   Batch #:  50 loss:  0.08024199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 68%|██████▊   | 341/500 [11:34<05:23,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  340 global step 22841   Batch #:  60 loss:  0.064534836\n",
      "Epoch #:  341 global step 22848   Batch #:  0 loss:  0.06550081\n",
      "Epoch #:  341 global step 22858   Batch #:  10 loss:  0.050566263\n",
      "Epoch #:  341 global step 22868   Batch #:  20 loss:  0.1488811\n",
      "Epoch #:  341 global step 22878   Batch #:  30 loss:  0.031774383\n",
      "Epoch #:  341 global step 22888   Batch #:  40 loss:  0.0839048\n",
      "Epoch #:  341 global step 22898   Batch #:  50 loss:  0.080189764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 68%|██████▊   | 342/500 [11:36<05:21,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  341 global step 22908   Batch #:  60 loss:  0.14012918\n",
      "Epoch #:  342 global step 22915   Batch #:  0 loss:  0.07143413\n",
      "Epoch #:  342 global step 22925   Batch #:  10 loss:  0.045716103\n",
      "Epoch #:  342 global step 22935   Batch #:  20 loss:  0.06421166\n",
      "Epoch #:  342 global step 22945   Batch #:  30 loss:  0.036866803\n",
      "Epoch #:  342 global step 22955   Batch #:  40 loss:  0.08570079\n",
      "Epoch #:  342 global step 22965   Batch #:  50 loss:  0.08849818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 69%|██████▊   | 343/500 [11:38<05:19,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  342 global step 22975   Batch #:  60 loss:  0.061670665\n",
      "Epoch #:  343 global step 22982   Batch #:  0 loss:  0.06388807\n",
      "Epoch #:  343 global step 22992   Batch #:  10 loss:  0.05563172\n",
      "Epoch #:  343 global step 23002   Batch #:  20 loss:  0.070637435\n",
      "Epoch #:  343 global step 23012   Batch #:  30 loss:  0.06051628\n",
      "Epoch #:  343 global step 23022   Batch #:  40 loss:  0.08909959\n",
      "Epoch #:  343 global step 23032   Batch #:  50 loss:  0.10043932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 69%|██████▉   | 344/500 [11:40<05:17,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  343 global step 23042   Batch #:  60 loss:  0.068879694\n",
      "Epoch #:  344 global step 23049   Batch #:  0 loss:  0.059292667\n",
      "Epoch #:  344 global step 23059   Batch #:  10 loss:  0.047289897\n",
      "Epoch #:  344 global step 23069   Batch #:  20 loss:  0.07676699\n",
      "Epoch #:  344 global step 23079   Batch #:  30 loss:  0.058753256\n",
      "Epoch #:  344 global step 23089   Batch #:  40 loss:  0.096867844\n",
      "Epoch #:  344 global step 23099   Batch #:  50 loss:  0.0983735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 69%|██████▉   | 345/500 [11:42<05:15,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  344 global step 23109   Batch #:  60 loss:  0.066263594\n",
      "Epoch #:  345 global step 23116   Batch #:  0 loss:  0.07087617\n",
      "Epoch #:  345 global step 23126   Batch #:  10 loss:  0.055157527\n",
      "Epoch #:  345 global step 23136   Batch #:  20 loss:  0.07216121\n",
      "Epoch #:  345 global step 23146   Batch #:  30 loss:  0.058060125\n",
      "Epoch #:  345 global step 23156   Batch #:  40 loss:  0.094375476\n",
      "Epoch #:  345 global step 23166   Batch #:  50 loss:  0.09422369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 69%|██████▉   | 346/500 [11:44<05:13,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  345 global step 23176   Batch #:  60 loss:  0.07374724\n",
      "Epoch #:  346 global step 23183   Batch #:  0 loss:  0.06917093\n",
      "Epoch #:  346 global step 23193   Batch #:  10 loss:  0.06420901\n",
      "Epoch #:  346 global step 23203   Batch #:  20 loss:  0.12124831\n",
      "Epoch #:  346 global step 23213   Batch #:  30 loss:  0.05341897\n",
      "Epoch #:  346 global step 23223   Batch #:  40 loss:  0.1147399\n",
      "Epoch #:  346 global step 23233   Batch #:  50 loss:  0.11897986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 69%|██████▉   | 347/500 [11:46<05:11,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  346 global step 23243   Batch #:  60 loss:  0.068900034\n",
      "Epoch #:  347 global step 23250   Batch #:  0 loss:  0.064552896\n",
      "Epoch #:  347 global step 23260   Batch #:  10 loss:  0.059696585\n",
      "Epoch #:  347 global step 23270   Batch #:  20 loss:  0.09055739\n",
      "Epoch #:  347 global step 23280   Batch #:  30 loss:  0.084166944\n",
      "Epoch #:  347 global step 23290   Batch #:  40 loss:  0.08598128\n",
      "Epoch #:  347 global step 23300   Batch #:  50 loss:  0.08176041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 70%|██████▉   | 348/500 [11:48<05:09,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  347 global step 23310   Batch #:  60 loss:  0.053007834\n",
      "Epoch #:  348 global step 23317   Batch #:  0 loss:  0.040826805\n",
      "Epoch #:  348 global step 23327   Batch #:  10 loss:  0.07421879\n",
      "Epoch #:  348 global step 23337   Batch #:  20 loss:  0.08497569\n",
      "Epoch #:  348 global step 23347   Batch #:  30 loss:  0.09950793\n",
      "Epoch #:  348 global step 23357   Batch #:  40 loss:  0.084212355\n",
      "Epoch #:  348 global step 23367   Batch #:  50 loss:  0.16341326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 70%|██████▉   | 349/500 [11:50<05:07,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  348 global step 23377   Batch #:  60 loss:  0.05586532\n",
      "Epoch #:  349 global step 23384   Batch #:  0 loss:  0.057806395\n",
      "Epoch #:  349 global step 23394   Batch #:  10 loss:  0.09599578\n",
      "Epoch #:  349 global step 23404   Batch #:  20 loss:  0.07404108\n",
      "Epoch #:  349 global step 23414   Batch #:  30 loss:  0.12880555\n",
      "Epoch #:  349 global step 23424   Batch #:  40 loss:  0.08675424\n",
      "Epoch #:  349 global step 23434   Batch #:  50 loss:  0.23886316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 350/500 [11:52<05:05,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  349 global step 23444   Batch #:  60 loss:  0.09735063\n",
      "Epoch #:  350 global step 23451   Batch #:  0 loss:  0.04156249\n",
      "Epoch #:  350 global step 23461   Batch #:  10 loss:  0.059528228\n",
      "Epoch #:  350 global step 23471   Batch #:  20 loss:  0.090561815\n",
      "Epoch #:  350 global step 23481   Batch #:  30 loss:  0.036770117\n",
      "Epoch #:  350 global step 23491   Batch #:  40 loss:  0.08433606\n",
      "Epoch #:  350 global step 23501   Batch #:  50 loss:  0.06712113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 351/500 [11:55<05:03,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  350 global step 23511   Batch #:  60 loss:  0.05287498\n",
      "Epoch #:  351 global step 23518   Batch #:  0 loss:  0.051653594\n",
      "Epoch #:  351 global step 23528   Batch #:  10 loss:  0.06017684\n",
      "Epoch #:  351 global step 23538   Batch #:  20 loss:  0.07168043\n",
      "Epoch #:  351 global step 23548   Batch #:  30 loss:  0.047476072\n",
      "Epoch #:  351 global step 23558   Batch #:  40 loss:  0.10227325\n",
      "Epoch #:  351 global step 23568   Batch #:  50 loss:  0.07915164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 352/500 [11:57<05:01,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  351 global step 23578   Batch #:  60 loss:  0.05094489\n",
      "Epoch #:  352 global step 23585   Batch #:  0 loss:  0.05610343\n",
      "Epoch #:  352 global step 23595   Batch #:  10 loss:  0.048453767\n",
      "Epoch #:  352 global step 23605   Batch #:  20 loss:  0.058772266\n",
      "Epoch #:  352 global step 23615   Batch #:  30 loss:  0.038600884\n",
      "Epoch #:  352 global step 23625   Batch #:  40 loss:  0.08959924\n",
      "Epoch #:  352 global step 23635   Batch #:  50 loss:  0.07807139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 71%|███████   | 353/500 [11:59<04:59,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  352 global step 23645   Batch #:  60 loss:  0.050128914\n",
      "Epoch #:  353 global step 23652   Batch #:  0 loss:  0.061568905\n",
      "Epoch #:  353 global step 23662   Batch #:  10 loss:  0.045235008\n",
      "Epoch #:  353 global step 23672   Batch #:  20 loss:  0.058160625\n",
      "Epoch #:  353 global step 23682   Batch #:  30 loss:  0.03817325\n",
      "Epoch #:  353 global step 23692   Batch #:  40 loss:  0.0852963\n",
      "Epoch #:  353 global step 23702   Batch #:  50 loss:  0.07224402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 71%|███████   | 354/500 [12:01<04:57,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  353 global step 23712   Batch #:  60 loss:  0.049815778\n",
      "Epoch #:  354 global step 23719   Batch #:  0 loss:  0.054887105\n",
      "Epoch #:  354 global step 23729   Batch #:  10 loss:  0.046110656\n",
      "Epoch #:  354 global step 23739   Batch #:  20 loss:  0.053640615\n",
      "Epoch #:  354 global step 23749   Batch #:  30 loss:  0.036435574\n",
      "Epoch #:  354 global step 23759   Batch #:  40 loss:  0.101013\n",
      "Epoch #:  354 global step 23769   Batch #:  50 loss:  0.07105417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 71%|███████   | 355/500 [12:03<04:55,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  354 global step 23779   Batch #:  60 loss:  0.04321015\n",
      "Epoch #:  355 global step 23786   Batch #:  0 loss:  0.055846665\n",
      "Epoch #:  355 global step 23796   Batch #:  10 loss:  0.044221856\n",
      "Epoch #:  355 global step 23806   Batch #:  20 loss:  0.054897\n",
      "Epoch #:  355 global step 23816   Batch #:  30 loss:  0.039016306\n",
      "Epoch #:  355 global step 23826   Batch #:  40 loss:  0.082334325\n",
      "Epoch #:  355 global step 23836   Batch #:  50 loss:  0.07486508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 71%|███████   | 356/500 [12:05<04:53,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  355 global step 23846   Batch #:  60 loss:  0.048462022\n",
      "Epoch #:  356 global step 23853   Batch #:  0 loss:  0.055572283\n",
      "Epoch #:  356 global step 23863   Batch #:  10 loss:  0.04283732\n",
      "Epoch #:  356 global step 23873   Batch #:  20 loss:  0.05374247\n",
      "Epoch #:  356 global step 23883   Batch #:  30 loss:  0.036808707\n",
      "Epoch #:  356 global step 23893   Batch #:  40 loss:  0.08418901\n",
      "Epoch #:  356 global step 23903   Batch #:  50 loss:  0.072016045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 71%|███████▏  | 357/500 [12:07<04:51,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  356 global step 23913   Batch #:  60 loss:  0.037958313\n",
      "Epoch #:  357 global step 23920   Batch #:  0 loss:  0.05120328\n",
      "Epoch #:  357 global step 23930   Batch #:  10 loss:  0.041002896\n",
      "Epoch #:  357 global step 23940   Batch #:  20 loss:  0.051137824\n",
      "Epoch #:  357 global step 23950   Batch #:  30 loss:  0.038629368\n",
      "Epoch #:  357 global step 23960   Batch #:  40 loss:  0.083257966\n",
      "Epoch #:  357 global step 23970   Batch #:  50 loss:  0.072445266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 72%|███████▏  | 358/500 [12:09<04:49,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  357 global step 23980   Batch #:  60 loss:  0.04446577\n",
      "Epoch #:  358 global step 23987   Batch #:  0 loss:  0.052516434\n",
      "Epoch #:  358 global step 23997   Batch #:  10 loss:  0.039451625\n",
      "Epoch #:  358 global step 24007   Batch #:  20 loss:  0.049294747\n",
      "Epoch #:  358 global step 24017   Batch #:  30 loss:  0.039546695\n",
      "Epoch #:  358 global step 24027   Batch #:  40 loss:  0.08274999\n",
      "Epoch #:  358 global step 24037   Batch #:  50 loss:  0.06842689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 72%|███████▏  | 359/500 [12:11<04:47,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  358 global step 24047   Batch #:  60 loss:  0.04735862\n",
      "Epoch #:  359 global step 24054   Batch #:  0 loss:  0.050902825\n",
      "Epoch #:  359 global step 24064   Batch #:  10 loss:  0.039549664\n",
      "Epoch #:  359 global step 24074   Batch #:  20 loss:  0.048572596\n",
      "Epoch #:  359 global step 24084   Batch #:  30 loss:  0.037201934\n",
      "Epoch #:  359 global step 24094   Batch #:  40 loss:  0.08485578\n",
      "Epoch #:  359 global step 24104   Batch #:  50 loss:  0.070897676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 72%|███████▏  | 360/500 [12:13<04:45,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  359 global step 24114   Batch #:  60 loss:  0.048172954\n",
      "Epoch #:  360 global step 24121   Batch #:  0 loss:  0.049681775\n",
      "Epoch #:  360 global step 24131   Batch #:  10 loss:  0.040654592\n",
      "Epoch #:  360 global step 24141   Batch #:  20 loss:  0.048942648\n",
      "Epoch #:  360 global step 24151   Batch #:  30 loss:  0.036453072\n",
      "Epoch #:  360 global step 24161   Batch #:  40 loss:  0.084870905\n",
      "Epoch #:  360 global step 24171   Batch #:  50 loss:  0.07040292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 72%|███████▏  | 361/500 [12:15<04:43,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  360 global step 24181   Batch #:  60 loss:  0.044800818\n",
      "Epoch #:  361 global step 24188   Batch #:  0 loss:  0.050897036\n",
      "Epoch #:  361 global step 24198   Batch #:  10 loss:  0.040276743\n",
      "Epoch #:  361 global step 24208   Batch #:  20 loss:  0.048749078\n",
      "Epoch #:  361 global step 24218   Batch #:  30 loss:  0.035583463\n",
      "Epoch #:  361 global step 24228   Batch #:  40 loss:  0.086492814\n",
      "Epoch #:  361 global step 24238   Batch #:  50 loss:  0.07128445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 72%|███████▏  | 362/500 [12:17<04:41,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  361 global step 24248   Batch #:  60 loss:  0.047824867\n",
      "Epoch #:  362 global step 24255   Batch #:  0 loss:  0.05271658\n",
      "Epoch #:  362 global step 24265   Batch #:  10 loss:  0.039314482\n",
      "Epoch #:  362 global step 24275   Batch #:  20 loss:  0.04931038\n",
      "Epoch #:  362 global step 24285   Batch #:  30 loss:  0.036777325\n",
      "Epoch #:  362 global step 24295   Batch #:  40 loss:  0.085780874\n",
      "Epoch #:  362 global step 24305   Batch #:  50 loss:  0.06637228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 73%|███████▎  | 363/500 [12:19<04:39,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  362 global step 24315   Batch #:  60 loss:  0.043719515\n",
      "Epoch #:  363 global step 24322   Batch #:  0 loss:  0.050986275\n",
      "Epoch #:  363 global step 24332   Batch #:  10 loss:  0.038246527\n",
      "Epoch #:  363 global step 24342   Batch #:  20 loss:  0.047988255\n",
      "Epoch #:  363 global step 24352   Batch #:  30 loss:  0.038530026\n",
      "Epoch #:  363 global step 24362   Batch #:  40 loss:  0.084542334\n",
      "Epoch #:  363 global step 24372   Batch #:  50 loss:  0.07243826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 73%|███████▎  | 364/500 [12:21<04:37,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  363 global step 24382   Batch #:  60 loss:  0.044313636\n",
      "Epoch #:  364 global step 24389   Batch #:  0 loss:  0.057650633\n",
      "Epoch #:  364 global step 24399   Batch #:  10 loss:  0.03926656\n",
      "Epoch #:  364 global step 24409   Batch #:  20 loss:  0.04896845\n",
      "Epoch #:  364 global step 24419   Batch #:  30 loss:  0.03546873\n",
      "Epoch #:  364 global step 24429   Batch #:  40 loss:  0.08559539\n",
      "Epoch #:  364 global step 24439   Batch #:  50 loss:  0.06748704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 73%|███████▎  | 365/500 [12:23<04:34,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  364 global step 24449   Batch #:  60 loss:  0.047136646\n",
      "Epoch #:  365 global step 24456   Batch #:  0 loss:  0.04962996\n",
      "Epoch #:  365 global step 24466   Batch #:  10 loss:  0.04148036\n",
      "Epoch #:  365 global step 24476   Batch #:  20 loss:  0.050240383\n",
      "Epoch #:  365 global step 24486   Batch #:  30 loss:  0.039490912\n",
      "Epoch #:  365 global step 24496   Batch #:  40 loss:  0.08563153\n",
      "Epoch #:  365 global step 24506   Batch #:  50 loss:  0.07371651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 73%|███████▎  | 366/500 [12:25<04:32,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  365 global step 24516   Batch #:  60 loss:  0.047367275\n",
      "Epoch #:  366 global step 24523   Batch #:  0 loss:  0.049479693\n",
      "Epoch #:  366 global step 24533   Batch #:  10 loss:  0.0376837\n",
      "Epoch #:  366 global step 24543   Batch #:  20 loss:  0.048247155\n",
      "Epoch #:  366 global step 24553   Batch #:  30 loss:  0.038470507\n",
      "Epoch #:  366 global step 24563   Batch #:  40 loss:  0.083861165\n",
      "Epoch #:  366 global step 24573   Batch #:  50 loss:  0.06541161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 73%|███████▎  | 367/500 [12:27<04:30,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  366 global step 24583   Batch #:  60 loss:  0.047654215\n",
      "Epoch #:  367 global step 24590   Batch #:  0 loss:  0.048216257\n",
      "Epoch #:  367 global step 24600   Batch #:  10 loss:  0.03678491\n",
      "Epoch #:  367 global step 24610   Batch #:  20 loss:  0.04925042\n",
      "Epoch #:  367 global step 24620   Batch #:  30 loss:  0.03402439\n",
      "Epoch #:  367 global step 24630   Batch #:  40 loss:  0.08385198\n",
      "Epoch #:  367 global step 24640   Batch #:  50 loss:  0.07071445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 74%|███████▎  | 368/500 [12:29<04:28,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  367 global step 24650   Batch #:  60 loss:  0.047233798\n",
      "Epoch #:  368 global step 24657   Batch #:  0 loss:  0.047703985\n",
      "Epoch #:  368 global step 24667   Batch #:  10 loss:  0.03808098\n",
      "Epoch #:  368 global step 24677   Batch #:  20 loss:  0.047962826\n",
      "Epoch #:  368 global step 24687   Batch #:  30 loss:  0.041608557\n",
      "Epoch #:  368 global step 24697   Batch #:  40 loss:  0.082958974\n",
      "Epoch #:  368 global step 24707   Batch #:  50 loss:  0.06597901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 369/500 [12:31<04:26,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  368 global step 24717   Batch #:  60 loss:  0.04381593\n",
      "Epoch #:  369 global step 24724   Batch #:  0 loss:  0.049702365\n",
      "Epoch #:  369 global step 24734   Batch #:  10 loss:  0.038197603\n",
      "Epoch #:  369 global step 24744   Batch #:  20 loss:  0.050068304\n",
      "Epoch #:  369 global step 24754   Batch #:  30 loss:  0.03943748\n",
      "Epoch #:  369 global step 24764   Batch #:  40 loss:  0.08263252\n",
      "Epoch #:  369 global step 24774   Batch #:  50 loss:  0.06985704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 370/500 [12:33<04:24,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  369 global step 24784   Batch #:  60 loss:  0.045701716\n",
      "Epoch #:  370 global step 24791   Batch #:  0 loss:  0.04643461\n",
      "Epoch #:  370 global step 24801   Batch #:  10 loss:  0.037387215\n",
      "Epoch #:  370 global step 24811   Batch #:  20 loss:  0.04779723\n",
      "Epoch #:  370 global step 24821   Batch #:  30 loss:  0.032885898\n",
      "Epoch #:  370 global step 24831   Batch #:  40 loss:  0.0847191\n",
      "Epoch #:  370 global step 24841   Batch #:  50 loss:  0.07128616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 371/500 [12:35<04:22,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  370 global step 24851   Batch #:  60 loss:  0.043807153\n",
      "Epoch #:  371 global step 24858   Batch #:  0 loss:  0.048922017\n",
      "Epoch #:  371 global step 24868   Batch #:  10 loss:  0.038238056\n",
      "Epoch #:  371 global step 24878   Batch #:  20 loss:  0.05014747\n",
      "Epoch #:  371 global step 24888   Batch #:  30 loss:  0.03565622\n",
      "Epoch #:  371 global step 24898   Batch #:  40 loss:  0.08333004\n",
      "Epoch #:  371 global step 24908   Batch #:  50 loss:  0.07048485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 372/500 [12:37<04:20,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  371 global step 24918   Batch #:  60 loss:  0.045128603\n",
      "Epoch #:  372 global step 24925   Batch #:  0 loss:  0.046983805\n",
      "Epoch #:  372 global step 24935   Batch #:  10 loss:  0.037740495\n",
      "Epoch #:  372 global step 24945   Batch #:  20 loss:  0.048676\n",
      "Epoch #:  372 global step 24955   Batch #:  30 loss:  0.032880154\n",
      "Epoch #:  372 global step 24965   Batch #:  40 loss:  0.08395711\n",
      "Epoch #:  372 global step 24975   Batch #:  50 loss:  0.071573555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 75%|███████▍  | 373/500 [12:39<04:18,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  372 global step 24985   Batch #:  60 loss:  0.04710438\n",
      "Epoch #:  373 global step 24992   Batch #:  0 loss:  0.045720886\n",
      "Epoch #:  373 global step 25002   Batch #:  10 loss:  0.035468742\n",
      "Epoch #:  373 global step 25012   Batch #:  20 loss:  0.047560275\n",
      "Epoch #:  373 global step 25022   Batch #:  30 loss:  0.038019016\n",
      "Epoch #:  373 global step 25032   Batch #:  40 loss:  0.08401223\n",
      "Epoch #:  373 global step 25042   Batch #:  50 loss:  0.06877922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 75%|███████▍  | 374/500 [12:41<04:16,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  373 global step 25052   Batch #:  60 loss:  0.043621387\n",
      "Epoch #:  374 global step 25059   Batch #:  0 loss:  0.045289986\n",
      "Epoch #:  374 global step 25069   Batch #:  10 loss:  0.035284635\n",
      "Epoch #:  374 global step 25079   Batch #:  20 loss:  0.047999118\n",
      "Epoch #:  374 global step 25089   Batch #:  30 loss:  0.037834387\n",
      "Epoch #:  374 global step 25099   Batch #:  40 loss:  0.084636204\n",
      "Epoch #:  374 global step 25109   Batch #:  50 loss:  0.07027711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 375/500 [12:43<04:14,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  374 global step 25119   Batch #:  60 loss:  0.04645581\n",
      "Epoch #:  375 global step 25126   Batch #:  0 loss:  0.045597274\n",
      "Epoch #:  375 global step 25136   Batch #:  10 loss:  0.035000414\n",
      "Epoch #:  375 global step 25146   Batch #:  20 loss:  0.046723396\n",
      "Epoch #:  375 global step 25156   Batch #:  30 loss:  0.03714949\n",
      "Epoch #:  375 global step 25166   Batch #:  40 loss:  0.097091034\n",
      "Epoch #:  375 global step 25176   Batch #:  50 loss:  0.068555385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 376/500 [12:45<04:12,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  375 global step 25186   Batch #:  60 loss:  0.04495874\n",
      "Epoch #:  376 global step 25193   Batch #:  0 loss:  0.04742267\n",
      "Epoch #:  376 global step 25203   Batch #:  10 loss:  0.035955124\n",
      "Epoch #:  376 global step 25213   Batch #:  20 loss:  0.047088344\n",
      "Epoch #:  376 global step 25223   Batch #:  30 loss:  0.037868798\n",
      "Epoch #:  376 global step 25233   Batch #:  40 loss:  0.08021871\n",
      "Epoch #:  376 global step 25243   Batch #:  50 loss:  0.069399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 377/500 [12:47<04:10,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  376 global step 25253   Batch #:  60 loss:  0.043717932\n",
      "Epoch #:  377 global step 25260   Batch #:  0 loss:  0.045758232\n",
      "Epoch #:  377 global step 25270   Batch #:  10 loss:  0.037289284\n",
      "Epoch #:  377 global step 25280   Batch #:  20 loss:  0.04733452\n",
      "Epoch #:  377 global step 25290   Batch #:  30 loss:  0.033380095\n",
      "Epoch #:  377 global step 25300   Batch #:  40 loss:  0.09704839\n",
      "Epoch #:  377 global step 25310   Batch #:  50 loss:  0.07098142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 76%|███████▌  | 378/500 [12:49<04:08,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  377 global step 25320   Batch #:  60 loss:  0.046731837\n",
      "Epoch #:  378 global step 25327   Batch #:  0 loss:  0.045499414\n",
      "Epoch #:  378 global step 25337   Batch #:  10 loss:  0.03477111\n",
      "Epoch #:  378 global step 25347   Batch #:  20 loss:  0.046335954\n",
      "Epoch #:  378 global step 25357   Batch #:  30 loss:  0.036881935\n",
      "Epoch #:  378 global step 25367   Batch #:  40 loss:  0.079867125\n",
      "Epoch #:  378 global step 25377   Batch #:  50 loss:  0.06953997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 76%|███████▌  | 379/500 [12:51<04:06,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  378 global step 25387   Batch #:  60 loss:  0.04161913\n",
      "Epoch #:  379 global step 25394   Batch #:  0 loss:  0.04482661\n",
      "Epoch #:  379 global step 25404   Batch #:  10 loss:  0.03747435\n",
      "Epoch #:  379 global step 25414   Batch #:  20 loss:  0.045931403\n",
      "Epoch #:  379 global step 25424   Batch #:  30 loss:  0.036788717\n",
      "Epoch #:  379 global step 25434   Batch #:  40 loss:  0.08021248\n",
      "Epoch #:  379 global step 25444   Batch #:  50 loss:  0.06850449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 76%|███████▌  | 380/500 [12:53<04:04,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  379 global step 25454   Batch #:  60 loss:  0.041966584\n",
      "Epoch #:  380 global step 25461   Batch #:  0 loss:  0.046469186\n",
      "Epoch #:  380 global step 25471   Batch #:  10 loss:  0.0366903\n",
      "Epoch #:  380 global step 25481   Batch #:  20 loss:  0.045237616\n",
      "Epoch #:  380 global step 25491   Batch #:  30 loss:  0.0320621\n",
      "Epoch #:  380 global step 25501   Batch #:  40 loss:  0.07986478\n",
      "Epoch #:  380 global step 25511   Batch #:  50 loss:  0.06556252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 76%|███████▌  | 381/500 [12:56<04:02,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  380 global step 25521   Batch #:  60 loss:  0.043262865\n",
      "Epoch #:  381 global step 25528   Batch #:  0 loss:  0.05118298\n",
      "Epoch #:  381 global step 25538   Batch #:  10 loss:  0.035571307\n",
      "Epoch #:  381 global step 25548   Batch #:  20 loss:  0.045478433\n",
      "Epoch #:  381 global step 25558   Batch #:  30 loss:  0.03530691\n",
      "Epoch #:  381 global step 25568   Batch #:  40 loss:  0.08015413\n",
      "Epoch #:  381 global step 25578   Batch #:  50 loss:  0.069194585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 76%|███████▋  | 382/500 [12:58<04:00,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  381 global step 25588   Batch #:  60 loss:  0.04247024\n",
      "Epoch #:  382 global step 25595   Batch #:  0 loss:  0.04906762\n",
      "Epoch #:  382 global step 25605   Batch #:  10 loss:  0.035548702\n",
      "Epoch #:  382 global step 25615   Batch #:  20 loss:  0.04520094\n",
      "Epoch #:  382 global step 25625   Batch #:  30 loss:  0.03661239\n",
      "Epoch #:  382 global step 25635   Batch #:  40 loss:  0.080871604\n",
      "Epoch #:  382 global step 25645   Batch #:  50 loss:  0.06918885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 77%|███████▋  | 383/500 [13:00<03:58,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  382 global step 25655   Batch #:  60 loss:  0.04121545\n",
      "Epoch #:  383 global step 25662   Batch #:  0 loss:  0.048700344\n",
      "Epoch #:  383 global step 25672   Batch #:  10 loss:  0.034809377\n",
      "Epoch #:  383 global step 25682   Batch #:  20 loss:  0.04558562\n",
      "Epoch #:  383 global step 25692   Batch #:  30 loss:  0.031348757\n",
      "Epoch #:  383 global step 25702   Batch #:  40 loss:  0.080717236\n",
      "Epoch #:  383 global step 25712   Batch #:  50 loss:  0.06824498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 77%|███████▋  | 384/500 [13:02<03:56,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  383 global step 25722   Batch #:  60 loss:  0.042625237\n",
      "Epoch #:  384 global step 25729   Batch #:  0 loss:  0.048487347\n",
      "Epoch #:  384 global step 25739   Batch #:  10 loss:  0.04083017\n",
      "Epoch #:  384 global step 25749   Batch #:  20 loss:  0.04769427\n",
      "Epoch #:  384 global step 25759   Batch #:  30 loss:  0.03667921\n",
      "Epoch #:  384 global step 25769   Batch #:  40 loss:  0.079828\n",
      "Epoch #:  384 global step 25779   Batch #:  50 loss:  0.068143204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 77%|███████▋  | 385/500 [13:04<03:54,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  384 global step 25789   Batch #:  60 loss:  0.04449417\n",
      "Epoch #:  385 global step 25796   Batch #:  0 loss:  0.04825532\n",
      "Epoch #:  385 global step 25806   Batch #:  10 loss:  0.0374058\n",
      "Epoch #:  385 global step 25816   Batch #:  20 loss:  0.049410883\n",
      "Epoch #:  385 global step 25826   Batch #:  30 loss:  0.036600925\n",
      "Epoch #:  385 global step 25836   Batch #:  40 loss:  0.080924064\n",
      "Epoch #:  385 global step 25846   Batch #:  50 loss:  0.06852676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 77%|███████▋  | 386/500 [13:06<03:52,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  385 global step 25856   Batch #:  60 loss:  0.040585876\n",
      "Epoch #:  386 global step 25863   Batch #:  0 loss:  0.047600284\n",
      "Epoch #:  386 global step 25873   Batch #:  10 loss:  0.03542672\n",
      "Epoch #:  386 global step 25883   Batch #:  20 loss:  0.049386635\n",
      "Epoch #:  386 global step 25893   Batch #:  30 loss:  0.035432234\n",
      "Epoch #:  386 global step 25903   Batch #:  40 loss:  0.079716496\n",
      "Epoch #:  386 global step 25913   Batch #:  50 loss:  0.071425885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 77%|███████▋  | 387/500 [13:08<03:50,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  386 global step 25923   Batch #:  60 loss:  0.042284403\n",
      "Epoch #:  387 global step 25930   Batch #:  0 loss:  0.04753967\n",
      "Epoch #:  387 global step 25940   Batch #:  10 loss:  0.04059876\n",
      "Epoch #:  387 global step 25950   Batch #:  20 loss:  0.05033928\n",
      "Epoch #:  387 global step 25960   Batch #:  30 loss:  0.038409464\n",
      "Epoch #:  387 global step 25970   Batch #:  40 loss:  0.07965423\n",
      "Epoch #:  387 global step 25980   Batch #:  50 loss:  0.06864571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 78%|███████▊  | 388/500 [13:10<03:48,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  387 global step 25990   Batch #:  60 loss:  0.042214412\n",
      "Epoch #:  388 global step 25997   Batch #:  0 loss:  0.04936727\n",
      "Epoch #:  388 global step 26007   Batch #:  10 loss:  0.036499687\n",
      "Epoch #:  388 global step 26017   Batch #:  20 loss:  0.049087916\n",
      "Epoch #:  388 global step 26027   Batch #:  30 loss:  0.039543893\n",
      "Epoch #:  388 global step 26037   Batch #:  40 loss:  0.07972855\n",
      "Epoch #:  388 global step 26047   Batch #:  50 loss:  0.06899103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 78%|███████▊  | 389/500 [13:12<03:46,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  388 global step 26057   Batch #:  60 loss:  0.046176177\n",
      "Epoch #:  389 global step 26064   Batch #:  0 loss:  0.049745765\n",
      "Epoch #:  389 global step 26074   Batch #:  10 loss:  0.03774005\n",
      "Epoch #:  389 global step 26084   Batch #:  20 loss:  0.04908721\n",
      "Epoch #:  389 global step 26094   Batch #:  30 loss:  0.037434895\n",
      "Epoch #:  389 global step 26104   Batch #:  40 loss:  0.08138184\n",
      "Epoch #:  389 global step 26114   Batch #:  50 loss:  0.07026715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 78%|███████▊  | 390/500 [13:14<03:44,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  389 global step 26124   Batch #:  60 loss:  0.04068223\n",
      "Epoch #:  390 global step 26131   Batch #:  0 loss:  0.04790102\n",
      "Epoch #:  390 global step 26141   Batch #:  10 loss:  0.034083407\n",
      "Epoch #:  390 global step 26151   Batch #:  20 loss:  0.049608827\n",
      "Epoch #:  390 global step 26161   Batch #:  30 loss:  0.03516417\n",
      "Epoch #:  390 global step 26171   Batch #:  40 loss:  0.08242169\n",
      "Epoch #:  390 global step 26181   Batch #:  50 loss:  0.06825014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 78%|███████▊  | 391/500 [13:16<03:42,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  390 global step 26191   Batch #:  60 loss:  0.041400507\n",
      "Epoch #:  391 global step 26198   Batch #:  0 loss:  0.049951717\n",
      "Epoch #:  391 global step 26208   Batch #:  10 loss:  0.037452724\n",
      "Epoch #:  391 global step 26218   Batch #:  20 loss:  0.04669888\n",
      "Epoch #:  391 global step 26228   Batch #:  30 loss:  0.04691223\n",
      "Epoch #:  391 global step 26238   Batch #:  40 loss:  0.086509295\n",
      "Epoch #:  391 global step 26248   Batch #:  50 loss:  0.07034353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 78%|███████▊  | 392/500 [13:18<03:39,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  391 global step 26258   Batch #:  60 loss:  0.036830522\n",
      "Epoch #:  392 global step 26265   Batch #:  0 loss:  0.07180634\n",
      "Epoch #:  392 global step 26275   Batch #:  10 loss:  0.039369248\n",
      "Epoch #:  392 global step 26285   Batch #:  20 loss:  0.049720235\n",
      "Epoch #:  392 global step 26295   Batch #:  30 loss:  0.0507863\n",
      "Epoch #:  392 global step 26305   Batch #:  40 loss:  0.09491527\n",
      "Epoch #:  392 global step 26315   Batch #:  50 loss:  0.07481906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 79%|███████▊  | 393/500 [13:20<03:37,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  392 global step 26325   Batch #:  60 loss:  0.043057155\n",
      "Epoch #:  393 global step 26332   Batch #:  0 loss:  0.116998196\n",
      "Epoch #:  393 global step 26342   Batch #:  10 loss:  0.13767262\n",
      "Epoch #:  393 global step 26352   Batch #:  20 loss:  0.066786095\n",
      "Epoch #:  393 global step 26362   Batch #:  30 loss:  0.056697696\n",
      "Epoch #:  393 global step 26372   Batch #:  40 loss:  0.08177023\n",
      "Epoch #:  393 global step 26382   Batch #:  50 loss:  0.07151305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 79%|███████▉  | 394/500 [13:22<03:35,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  393 global step 26392   Batch #:  60 loss:  0.036311693\n",
      "Epoch #:  394 global step 26399   Batch #:  0 loss:  0.054525733\n",
      "Epoch #:  394 global step 26409   Batch #:  10 loss:  0.08128824\n",
      "Epoch #:  394 global step 26419   Batch #:  20 loss:  0.06063146\n",
      "Epoch #:  394 global step 26429   Batch #:  30 loss:  0.060989358\n",
      "Epoch #:  394 global step 26439   Batch #:  40 loss:  0.09052158\n",
      "Epoch #:  394 global step 26449   Batch #:  50 loss:  0.63582367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 79%|███████▉  | 395/500 [13:24<03:33,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  394 global step 26459   Batch #:  60 loss:  0.09209526\n",
      "Epoch #:  395 global step 26466   Batch #:  0 loss:  0.113580085\n",
      "Epoch #:  395 global step 26476   Batch #:  10 loss:  0.21998471\n",
      "Epoch #:  395 global step 26486   Batch #:  20 loss:  0.21793087\n",
      "Epoch #:  395 global step 26496   Batch #:  30 loss:  0.1835025\n",
      "Epoch #:  395 global step 26506   Batch #:  40 loss:  0.2699543\n",
      "Epoch #:  395 global step 26516   Batch #:  50 loss:  0.11596638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 79%|███████▉  | 396/500 [13:26<03:31,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  395 global step 26526   Batch #:  60 loss:  0.13467215\n",
      "Epoch #:  396 global step 26533   Batch #:  0 loss:  0.045804895\n",
      "Epoch #:  396 global step 26543   Batch #:  10 loss:  0.41986153\n",
      "Epoch #:  396 global step 26553   Batch #:  20 loss:  0.25418028\n",
      "Epoch #:  396 global step 26563   Batch #:  30 loss:  0.11044775\n",
      "Epoch #:  396 global step 26573   Batch #:  40 loss:  0.16176061\n",
      "Epoch #:  396 global step 26583   Batch #:  50 loss:  0.19862328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 79%|███████▉  | 397/500 [13:28<03:29,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  396 global step 26593   Batch #:  60 loss:  0.14398739\n",
      "Epoch #:  397 global step 26600   Batch #:  0 loss:  0.1259916\n",
      "Epoch #:  397 global step 26610   Batch #:  10 loss:  0.13250975\n",
      "Epoch #:  397 global step 26620   Batch #:  20 loss:  0.10900726\n",
      "Epoch #:  397 global step 26630   Batch #:  30 loss:  0.1454354\n",
      "Epoch #:  397 global step 26640   Batch #:  40 loss:  0.13591532\n",
      "Epoch #:  397 global step 26650   Batch #:  50 loss:  0.13834517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 80%|███████▉  | 398/500 [13:30<03:27,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  397 global step 26660   Batch #:  60 loss:  0.15209746\n",
      "Epoch #:  398 global step 26667   Batch #:  0 loss:  0.083858944\n",
      "Epoch #:  398 global step 26677   Batch #:  10 loss:  0.12012849\n",
      "Epoch #:  398 global step 26687   Batch #:  20 loss:  0.13522038\n",
      "Epoch #:  398 global step 26697   Batch #:  30 loss:  0.16670275\n",
      "Epoch #:  398 global step 26707   Batch #:  40 loss:  0.11747835\n",
      "Epoch #:  398 global step 26717   Batch #:  50 loss:  0.11090252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 80%|███████▉  | 399/500 [13:32<03:25,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  398 global step 26727   Batch #:  60 loss:  0.14488605\n",
      "Epoch #:  399 global step 26734   Batch #:  0 loss:  0.08364283\n",
      "Epoch #:  399 global step 26744   Batch #:  10 loss:  0.14289273\n",
      "Epoch #:  399 global step 26754   Batch #:  20 loss:  0.13127592\n",
      "Epoch #:  399 global step 26764   Batch #:  30 loss:  0.15615964\n",
      "Epoch #:  399 global step 26774   Batch #:  40 loss:  0.108031765\n",
      "Epoch #:  399 global step 26784   Batch #:  50 loss:  0.10182623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 400/500 [13:34<03:23,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  399 global step 26794   Batch #:  60 loss:  0.062380157\n",
      "Epoch #:  400 global step 26801   Batch #:  0 loss:  0.11467039\n",
      "Epoch #:  400 global step 26811   Batch #:  10 loss:  0.09787118\n",
      "Epoch #:  400 global step 26821   Batch #:  20 loss:  0.117862694\n",
      "Epoch #:  400 global step 26831   Batch #:  30 loss:  0.1488541\n",
      "Epoch #:  400 global step 26841   Batch #:  40 loss:  0.11724291\n",
      "Epoch #:  400 global step 26851   Batch #:  50 loss:  0.10006366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 401/500 [13:36<03:21,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  400 global step 26861   Batch #:  60 loss:  0.05502455\n",
      "Epoch #:  401 global step 26868   Batch #:  0 loss:  0.06637467\n",
      "Epoch #:  401 global step 26878   Batch #:  10 loss:  0.10997152\n",
      "Epoch #:  401 global step 26888   Batch #:  20 loss:  0.117326446\n",
      "Epoch #:  401 global step 26898   Batch #:  30 loss:  0.13639848\n",
      "Epoch #:  401 global step 26908   Batch #:  40 loss:  0.12616004\n",
      "Epoch #:  401 global step 26918   Batch #:  50 loss:  0.12273466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 402/500 [13:38<03:19,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  401 global step 26928   Batch #:  60 loss:  0.0646132\n",
      "Epoch #:  402 global step 26935   Batch #:  0 loss:  0.07648119\n",
      "Epoch #:  402 global step 26945   Batch #:  10 loss:  0.09924436\n",
      "Epoch #:  402 global step 26955   Batch #:  20 loss:  0.09868497\n",
      "Epoch #:  402 global step 26965   Batch #:  30 loss:  0.14236207\n",
      "Epoch #:  402 global step 26975   Batch #:  40 loss:  0.13958615\n",
      "Epoch #:  402 global step 26985   Batch #:  50 loss:  0.18035495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 81%|████████  | 403/500 [13:40<03:17,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  402 global step 26995   Batch #:  60 loss:  0.12504245\n",
      "Epoch #:  403 global step 27002   Batch #:  0 loss:  0.0939314\n",
      "Epoch #:  403 global step 27012   Batch #:  10 loss:  0.072651856\n",
      "Epoch #:  403 global step 27022   Batch #:  20 loss:  0.0619997\n",
      "Epoch #:  403 global step 27032   Batch #:  30 loss:  0.13232824\n",
      "Epoch #:  403 global step 27042   Batch #:  40 loss:  0.10028597\n",
      "Epoch #:  403 global step 27052   Batch #:  50 loss:  0.07079214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 81%|████████  | 404/500 [13:42<03:15,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  403 global step 27062   Batch #:  60 loss:  0.03816104\n",
      "Epoch #:  404 global step 27069   Batch #:  0 loss:  0.07252727\n",
      "Epoch #:  404 global step 27079   Batch #:  10 loss:  0.039418623\n",
      "Epoch #:  404 global step 27089   Batch #:  20 loss:  0.046110325\n",
      "Epoch #:  404 global step 27099   Batch #:  30 loss:  0.12692474\n",
      "Epoch #:  404 global step 27109   Batch #:  40 loss:  0.0877144\n",
      "Epoch #:  404 global step 27119   Batch #:  50 loss:  0.07233869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 81%|████████  | 405/500 [13:44<03:13,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  404 global step 27129   Batch #:  60 loss:  0.034091882\n",
      "Epoch #:  405 global step 27136   Batch #:  0 loss:  0.051117532\n",
      "Epoch #:  405 global step 27146   Batch #:  10 loss:  0.038741358\n",
      "Epoch #:  405 global step 27156   Batch #:  20 loss:  0.042847257\n",
      "Epoch #:  405 global step 27166   Batch #:  30 loss:  0.1276975\n",
      "Epoch #:  405 global step 27176   Batch #:  40 loss:  0.08229215\n",
      "Epoch #:  405 global step 27186   Batch #:  50 loss:  0.06849673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 81%|████████  | 406/500 [13:46<03:11,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  405 global step 27196   Batch #:  60 loss:  0.03420083\n",
      "Epoch #:  406 global step 27203   Batch #:  0 loss:  0.04089841\n",
      "Epoch #:  406 global step 27213   Batch #:  10 loss:  0.038590867\n",
      "Epoch #:  406 global step 27223   Batch #:  20 loss:  0.043422647\n",
      "Epoch #:  406 global step 27233   Batch #:  30 loss:  0.13090694\n",
      "Epoch #:  406 global step 27243   Batch #:  40 loss:  0.08208059\n",
      "Epoch #:  406 global step 27253   Batch #:  50 loss:  0.06978494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 81%|████████▏ | 407/500 [13:48<03:09,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  406 global step 27263   Batch #:  60 loss:  0.034337495\n",
      "Epoch #:  407 global step 27270   Batch #:  0 loss:  0.03962565\n",
      "Epoch #:  407 global step 27280   Batch #:  10 loss:  0.037149698\n",
      "Epoch #:  407 global step 27290   Batch #:  20 loss:  0.049154766\n",
      "Epoch #:  407 global step 27300   Batch #:  30 loss:  0.1298662\n",
      "Epoch #:  407 global step 27310   Batch #:  40 loss:  0.08876346\n",
      "Epoch #:  407 global step 27320   Batch #:  50 loss:  0.06847956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 82%|████████▏ | 408/500 [13:50<03:07,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  407 global step 27330   Batch #:  60 loss:  0.031617012\n",
      "Epoch #:  408 global step 27337   Batch #:  0 loss:  0.039017536\n",
      "Epoch #:  408 global step 27347   Batch #:  10 loss:  0.034116752\n",
      "Epoch #:  408 global step 27357   Batch #:  20 loss:  0.053715214\n",
      "Epoch #:  408 global step 27367   Batch #:  30 loss:  0.124265336\n",
      "Epoch #:  408 global step 27377   Batch #:  40 loss:  0.08560868\n",
      "Epoch #:  408 global step 27387   Batch #:  50 loss:  0.065216124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 82%|████████▏ | 409/500 [13:52<03:05,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  408 global step 27397   Batch #:  60 loss:  0.031164898\n",
      "Epoch #:  409 global step 27404   Batch #:  0 loss:  0.038576335\n",
      "Epoch #:  409 global step 27414   Batch #:  10 loss:  0.03287355\n",
      "Epoch #:  409 global step 27424   Batch #:  20 loss:  0.05250215\n",
      "Epoch #:  409 global step 27434   Batch #:  30 loss:  0.12381135\n",
      "Epoch #:  409 global step 27444   Batch #:  40 loss:  0.08408551\n",
      "Epoch #:  409 global step 27454   Batch #:  50 loss:  0.06748804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 82%|████████▏ | 410/500 [13:55<03:03,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  409 global step 27464   Batch #:  60 loss:  0.030890083\n",
      "Epoch #:  410 global step 27471   Batch #:  0 loss:  0.03956908\n",
      "Epoch #:  410 global step 27481   Batch #:  10 loss:  0.031527534\n",
      "Epoch #:  410 global step 27491   Batch #:  20 loss:  0.05068246\n",
      "Epoch #:  410 global step 27501   Batch #:  30 loss:  0.1257692\n",
      "Epoch #:  410 global step 27511   Batch #:  40 loss:  0.08064454\n",
      "Epoch #:  410 global step 27521   Batch #:  50 loss:  0.06777274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 82%|████████▏ | 411/500 [13:57<03:01,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  410 global step 27531   Batch #:  60 loss:  0.02555395\n",
      "Epoch #:  411 global step 27538   Batch #:  0 loss:  0.03799584\n",
      "Epoch #:  411 global step 27548   Batch #:  10 loss:  0.03200495\n",
      "Epoch #:  411 global step 27558   Batch #:  20 loss:  0.04906451\n",
      "Epoch #:  411 global step 27568   Batch #:  30 loss:  0.122739226\n",
      "Epoch #:  411 global step 27578   Batch #:  40 loss:  0.071690835\n",
      "Epoch #:  411 global step 27588   Batch #:  50 loss:  0.06731374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 82%|████████▏ | 412/500 [13:59<02:59,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  411 global step 27598   Batch #:  60 loss:  0.030556325\n",
      "Epoch #:  412 global step 27605   Batch #:  0 loss:  0.039813556\n",
      "Epoch #:  412 global step 27615   Batch #:  10 loss:  0.030652372\n",
      "Epoch #:  412 global step 27625   Batch #:  20 loss:  0.049491\n",
      "Epoch #:  412 global step 27635   Batch #:  30 loss:  0.123396955\n",
      "Epoch #:  412 global step 27645   Batch #:  40 loss:  0.07366694\n",
      "Epoch #:  412 global step 27655   Batch #:  50 loss:  0.06753022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 413/500 [14:01<02:57,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  412 global step 27665   Batch #:  60 loss:  0.030354267\n",
      "Epoch #:  413 global step 27672   Batch #:  0 loss:  0.03940516\n",
      "Epoch #:  413 global step 27682   Batch #:  10 loss:  0.030425373\n",
      "Epoch #:  413 global step 27692   Batch #:  20 loss:  0.04905886\n",
      "Epoch #:  413 global step 27702   Batch #:  30 loss:  0.12069973\n",
      "Epoch #:  413 global step 27712   Batch #:  40 loss:  0.072272785\n",
      "Epoch #:  413 global step 27722   Batch #:  50 loss:  0.06749915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 414/500 [14:03<02:55,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  413 global step 27732   Batch #:  60 loss:  0.030503336\n",
      "Epoch #:  414 global step 27739   Batch #:  0 loss:  0.039842166\n",
      "Epoch #:  414 global step 27749   Batch #:  10 loss:  0.030529821\n",
      "Epoch #:  414 global step 27759   Batch #:  20 loss:  0.04842896\n",
      "Epoch #:  414 global step 27769   Batch #:  30 loss:  0.12650499\n",
      "Epoch #:  414 global step 27779   Batch #:  40 loss:  0.06825162\n",
      "Epoch #:  414 global step 27789   Batch #:  50 loss:  0.0664832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 415/500 [14:05<02:53,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  414 global step 27799   Batch #:  60 loss:  0.030035047\n",
      "Epoch #:  415 global step 27806   Batch #:  0 loss:  0.039391547\n",
      "Epoch #:  415 global step 27816   Batch #:  10 loss:  0.03250568\n",
      "Epoch #:  415 global step 27826   Batch #:  20 loss:  0.050183106\n",
      "Epoch #:  415 global step 27836   Batch #:  30 loss:  0.12247693\n",
      "Epoch #:  415 global step 27846   Batch #:  40 loss:  0.06900332\n",
      "Epoch #:  415 global step 27856   Batch #:  50 loss:  0.067356974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 416/500 [14:07<02:51,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  415 global step 27866   Batch #:  60 loss:  0.029817782\n",
      "Epoch #:  416 global step 27873   Batch #:  0 loss:  0.04069735\n",
      "Epoch #:  416 global step 27883   Batch #:  10 loss:  0.030687235\n",
      "Epoch #:  416 global step 27893   Batch #:  20 loss:  0.053747818\n",
      "Epoch #:  416 global step 27903   Batch #:  30 loss:  0.12663536\n",
      "Epoch #:  416 global step 27913   Batch #:  40 loss:  0.06965434\n",
      "Epoch #:  416 global step 27923   Batch #:  50 loss:  0.06604426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 417/500 [14:09<02:49,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  416 global step 27933   Batch #:  60 loss:  0.029617917\n",
      "Epoch #:  417 global step 27940   Batch #:  0 loss:  0.040735938\n",
      "Epoch #:  417 global step 27950   Batch #:  10 loss:  0.032913577\n",
      "Epoch #:  417 global step 27960   Batch #:  20 loss:  0.05275714\n",
      "Epoch #:  417 global step 27970   Batch #:  30 loss:  0.12237054\n",
      "Epoch #:  417 global step 27980   Batch #:  40 loss:  0.067452446\n",
      "Epoch #:  417 global step 27990   Batch #:  50 loss:  0.06695619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 84%|████████▎ | 418/500 [14:11<02:46,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  417 global step 28000   Batch #:  60 loss:  0.029560992\n",
      "Epoch #:  418 global step 28007   Batch #:  0 loss:  0.03935373\n",
      "Epoch #:  418 global step 28017   Batch #:  10 loss:  0.032545574\n",
      "Epoch #:  418 global step 28027   Batch #:  20 loss:  0.05293098\n",
      "Epoch #:  418 global step 28037   Batch #:  30 loss:  0.120899774\n",
      "Epoch #:  418 global step 28047   Batch #:  40 loss:  0.07700372\n",
      "Epoch #:  418 global step 28057   Batch #:  50 loss:  0.06595476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 419/500 [14:13<02:44,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  418 global step 28067   Batch #:  60 loss:  0.029309807\n",
      "Epoch #:  419 global step 28074   Batch #:  0 loss:  0.039523393\n",
      "Epoch #:  419 global step 28084   Batch #:  10 loss:  0.032226466\n",
      "Epoch #:  419 global step 28094   Batch #:  20 loss:  0.05238696\n",
      "Epoch #:  419 global step 28104   Batch #:  30 loss:  0.12657025\n",
      "Epoch #:  419 global step 28114   Batch #:  40 loss:  0.077105545\n",
      "Epoch #:  419 global step 28124   Batch #:  50 loss:  0.067170225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 420/500 [14:15<02:42,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  419 global step 28134   Batch #:  60 loss:  0.029212233\n",
      "Epoch #:  420 global step 28141   Batch #:  0 loss:  0.038892865\n",
      "Epoch #:  420 global step 28151   Batch #:  10 loss:  0.031800482\n",
      "Epoch #:  420 global step 28161   Batch #:  20 loss:  0.05288848\n",
      "Epoch #:  420 global step 28171   Batch #:  30 loss:  0.12479316\n",
      "Epoch #:  420 global step 28181   Batch #:  40 loss:  0.0761105\n",
      "Epoch #:  420 global step 28191   Batch #:  50 loss:  0.06638368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 421/500 [14:17<02:40,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  420 global step 28201   Batch #:  60 loss:  0.029185126\n",
      "Epoch #:  421 global step 28208   Batch #:  0 loss:  0.03687862\n",
      "Epoch #:  421 global step 28218   Batch #:  10 loss:  0.0331824\n",
      "Epoch #:  421 global step 28228   Batch #:  20 loss:  0.051958248\n",
      "Epoch #:  421 global step 28238   Batch #:  30 loss:  0.13186158\n",
      "Epoch #:  421 global step 28248   Batch #:  40 loss:  0.076738015\n",
      "Epoch #:  421 global step 28258   Batch #:  50 loss:  0.06542055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 422/500 [14:19<02:38,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  421 global step 28268   Batch #:  60 loss:  0.028944423\n",
      "Epoch #:  422 global step 28275   Batch #:  0 loss:  0.0379774\n",
      "Epoch #:  422 global step 28285   Batch #:  10 loss:  0.03167956\n",
      "Epoch #:  422 global step 28295   Batch #:  20 loss:  0.052319523\n",
      "Epoch #:  422 global step 28305   Batch #:  30 loss:  0.13296556\n",
      "Epoch #:  422 global step 28315   Batch #:  40 loss:  0.0760098\n",
      "Epoch #:  422 global step 28325   Batch #:  50 loss:  0.06561058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 85%|████████▍ | 423/500 [14:21<02:36,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  422 global step 28335   Batch #:  60 loss:  0.029007448\n",
      "Epoch #:  423 global step 28342   Batch #:  0 loss:  0.038941402\n",
      "Epoch #:  423 global step 28352   Batch #:  10 loss:  0.033235326\n",
      "Epoch #:  423 global step 28362   Batch #:  20 loss:  0.05210243\n",
      "Epoch #:  423 global step 28372   Batch #:  30 loss:  0.12467019\n",
      "Epoch #:  423 global step 28382   Batch #:  40 loss:  0.07597958\n",
      "Epoch #:  423 global step 28392   Batch #:  50 loss:  0.06612646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 85%|████████▍ | 424/500 [14:23<02:34,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  423 global step 28402   Batch #:  60 loss:  0.02895331\n",
      "Epoch #:  424 global step 28409   Batch #:  0 loss:  0.037782114\n",
      "Epoch #:  424 global step 28419   Batch #:  10 loss:  0.03152657\n",
      "Epoch #:  424 global step 28429   Batch #:  20 loss:  0.05199769\n",
      "Epoch #:  424 global step 28439   Batch #:  30 loss:  0.12646598\n",
      "Epoch #:  424 global step 28449   Batch #:  40 loss:  0.07512649\n",
      "Epoch #:  424 global step 28459   Batch #:  50 loss:  0.0668159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 85%|████████▌ | 425/500 [14:25<02:32,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  424 global step 28469   Batch #:  60 loss:  0.028713934\n",
      "Epoch #:  425 global step 28476   Batch #:  0 loss:  0.038016476\n",
      "Epoch #:  425 global step 28486   Batch #:  10 loss:  0.031218385\n",
      "Epoch #:  425 global step 28496   Batch #:  20 loss:  0.053519946\n",
      "Epoch #:  425 global step 28506   Batch #:  30 loss:  0.12512939\n",
      "Epoch #:  425 global step 28516   Batch #:  40 loss:  0.07540687\n",
      "Epoch #:  425 global step 28526   Batch #:  50 loss:  0.066554375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 85%|████████▌ | 426/500 [14:27<02:30,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  425 global step 28536   Batch #:  60 loss:  0.03485896\n",
      "Epoch #:  426 global step 28543   Batch #:  0 loss:  0.039881367\n",
      "Epoch #:  426 global step 28553   Batch #:  10 loss:  0.031720076\n",
      "Epoch #:  426 global step 28563   Batch #:  20 loss:  0.051652376\n",
      "Epoch #:  426 global step 28573   Batch #:  30 loss:  0.1294752\n",
      "Epoch #:  426 global step 28583   Batch #:  40 loss:  0.07481711\n",
      "Epoch #:  426 global step 28593   Batch #:  50 loss:  0.06675739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 85%|████████▌ | 427/500 [14:29<02:28,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  426 global step 28603   Batch #:  60 loss:  0.035070747\n",
      "Epoch #:  427 global step 28610   Batch #:  0 loss:  0.038085256\n",
      "Epoch #:  427 global step 28620   Batch #:  10 loss:  0.04082645\n",
      "Epoch #:  427 global step 28630   Batch #:  20 loss:  0.05363943\n",
      "Epoch #:  427 global step 28640   Batch #:  30 loss:  0.12880929\n",
      "Epoch #:  427 global step 28650   Batch #:  40 loss:  0.06629717\n",
      "Epoch #:  427 global step 28660   Batch #:  50 loss:  0.071138866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 86%|████████▌ | 428/500 [14:31<02:26,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  427 global step 28670   Batch #:  60 loss:  0.022529997\n",
      "Epoch #:  428 global step 28677   Batch #:  0 loss:  0.0399738\n",
      "Epoch #:  428 global step 28687   Batch #:  10 loss:  0.042515308\n",
      "Epoch #:  428 global step 28697   Batch #:  20 loss:  0.05031067\n",
      "Epoch #:  428 global step 28707   Batch #:  30 loss:  0.13181792\n",
      "Epoch #:  428 global step 28717   Batch #:  40 loss:  0.06903159\n",
      "Epoch #:  428 global step 28727   Batch #:  50 loss:  0.07034669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 86%|████████▌ | 429/500 [14:33<02:24,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  428 global step 28737   Batch #:  60 loss:  0.022276985\n",
      "Epoch #:  429 global step 28744   Batch #:  0 loss:  0.03855013\n",
      "Epoch #:  429 global step 28754   Batch #:  10 loss:  0.04015579\n",
      "Epoch #:  429 global step 28764   Batch #:  20 loss:  0.048627757\n",
      "Epoch #:  429 global step 28774   Batch #:  30 loss:  0.12841657\n",
      "Epoch #:  429 global step 28784   Batch #:  40 loss:  0.06626042\n",
      "Epoch #:  429 global step 28794   Batch #:  50 loss:  0.069998406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 86%|████████▌ | 430/500 [14:35<02:22,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  429 global step 28804   Batch #:  60 loss:  0.022120427\n",
      "Epoch #:  430 global step 28811   Batch #:  0 loss:  0.037467968\n",
      "Epoch #:  430 global step 28821   Batch #:  10 loss:  0.03705848\n",
      "Epoch #:  430 global step 28831   Batch #:  20 loss:  0.06671888\n",
      "Epoch #:  430 global step 28841   Batch #:  30 loss:  0.1327239\n",
      "Epoch #:  430 global step 28851   Batch #:  40 loss:  0.070295505\n",
      "Epoch #:  430 global step 28861   Batch #:  50 loss:  0.069944754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 86%|████████▌ | 431/500 [14:37<02:20,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  430 global step 28871   Batch #:  60 loss:  0.029419484\n",
      "Epoch #:  431 global step 28878   Batch #:  0 loss:  0.03467123\n",
      "Epoch #:  431 global step 28888   Batch #:  10 loss:  0.038357064\n",
      "Epoch #:  431 global step 28898   Batch #:  20 loss:  0.070206225\n",
      "Epoch #:  431 global step 28908   Batch #:  30 loss:  0.12888545\n",
      "Epoch #:  431 global step 28918   Batch #:  40 loss:  0.06993686\n",
      "Epoch #:  431 global step 28928   Batch #:  50 loss:  0.08477714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 86%|████████▋ | 432/500 [14:39<02:18,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  431 global step 28938   Batch #:  60 loss:  0.053498086\n",
      "Epoch #:  432 global step 28945   Batch #:  0 loss:  0.037138384\n",
      "Epoch #:  432 global step 28955   Batch #:  10 loss:  0.037118223\n",
      "Epoch #:  432 global step 28965   Batch #:  20 loss:  0.07125371\n",
      "Epoch #:  432 global step 28975   Batch #:  30 loss:  0.13064998\n",
      "Epoch #:  432 global step 28985   Batch #:  40 loss:  0.09036871\n",
      "Epoch #:  432 global step 28995   Batch #:  50 loss:  0.08222401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 87%|████████▋ | 433/500 [14:41<02:16,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  432 global step 29005   Batch #:  60 loss:  0.052859653\n",
      "Epoch #:  433 global step 29012   Batch #:  0 loss:  0.03622447\n",
      "Epoch #:  433 global step 29022   Batch #:  10 loss:  0.038616672\n",
      "Epoch #:  433 global step 29032   Batch #:  20 loss:  0.07009562\n",
      "Epoch #:  433 global step 29042   Batch #:  30 loss:  0.13616225\n",
      "Epoch #:  433 global step 29052   Batch #:  40 loss:  0.09238845\n",
      "Epoch #:  433 global step 29062   Batch #:  50 loss:  0.07607492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 87%|████████▋ | 434/500 [14:43<02:14,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  433 global step 29072   Batch #:  60 loss:  0.06119851\n",
      "Epoch #:  434 global step 29079   Batch #:  0 loss:  0.04281138\n",
      "Epoch #:  434 global step 29089   Batch #:  10 loss:  0.03883782\n",
      "Epoch #:  434 global step 29099   Batch #:  20 loss:  0.072246194\n",
      "Epoch #:  434 global step 29109   Batch #:  30 loss:  0.12732165\n",
      "Epoch #:  434 global step 29119   Batch #:  40 loss:  0.07392347\n",
      "Epoch #:  434 global step 29129   Batch #:  50 loss:  0.06963481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 87%|████████▋ | 435/500 [14:45<02:12,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  434 global step 29139   Batch #:  60 loss:  0.021681499\n",
      "Epoch #:  435 global step 29146   Batch #:  0 loss:  0.03305892\n",
      "Epoch #:  435 global step 29156   Batch #:  10 loss:  0.037112065\n",
      "Epoch #:  435 global step 29166   Batch #:  20 loss:  0.056093857\n",
      "Epoch #:  435 global step 29176   Batch #:  30 loss:  0.1326018\n",
      "Epoch #:  435 global step 29186   Batch #:  40 loss:  0.068312354\n",
      "Epoch #:  435 global step 29196   Batch #:  50 loss:  0.06913414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 87%|████████▋ | 436/500 [14:47<02:10,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  435 global step 29206   Batch #:  60 loss:  0.026851283\n",
      "Epoch #:  436 global step 29213   Batch #:  0 loss:  0.03369121\n",
      "Epoch #:  436 global step 29223   Batch #:  10 loss:  0.03678147\n",
      "Epoch #:  436 global step 29233   Batch #:  20 loss:  0.055585697\n",
      "Epoch #:  436 global step 29243   Batch #:  30 loss:  0.13020459\n",
      "Epoch #:  436 global step 29253   Batch #:  40 loss:  0.06788324\n",
      "Epoch #:  436 global step 29263   Batch #:  50 loss:  0.06908791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 87%|████████▋ | 437/500 [14:49<02:08,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  436 global step 29273   Batch #:  60 loss:  0.026766907\n",
      "Epoch #:  437 global step 29280   Batch #:  0 loss:  0.036691207\n",
      "Epoch #:  437 global step 29290   Batch #:  10 loss:  0.03674656\n",
      "Epoch #:  437 global step 29300   Batch #:  20 loss:  0.05592337\n",
      "Epoch #:  437 global step 29310   Batch #:  30 loss:  0.12968953\n",
      "Epoch #:  437 global step 29320   Batch #:  40 loss:  0.067171544\n",
      "Epoch #:  437 global step 29330   Batch #:  50 loss:  0.06962279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 438/500 [14:51<02:06,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  437 global step 29340   Batch #:  60 loss:  0.026946578\n",
      "Epoch #:  438 global step 29347   Batch #:  0 loss:  0.0372325\n",
      "Epoch #:  438 global step 29357   Batch #:  10 loss:  0.037160303\n",
      "Epoch #:  438 global step 29367   Batch #:  20 loss:  0.055619646\n",
      "Epoch #:  438 global step 29377   Batch #:  30 loss:  0.13273036\n",
      "Epoch #:  438 global step 29387   Batch #:  40 loss:  0.06797172\n",
      "Epoch #:  438 global step 29397   Batch #:  50 loss:  0.06794305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 439/500 [14:53<02:04,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  438 global step 29407   Batch #:  60 loss:  0.026556931\n",
      "Epoch #:  439 global step 29414   Batch #:  0 loss:  0.03238502\n",
      "Epoch #:  439 global step 29424   Batch #:  10 loss:  0.037563205\n",
      "Epoch #:  439 global step 29434   Batch #:  20 loss:  0.055797208\n",
      "Epoch #:  439 global step 29444   Batch #:  30 loss:  0.12577808\n",
      "Epoch #:  439 global step 29454   Batch #:  40 loss:  0.06801565\n",
      "Epoch #:  439 global step 29464   Batch #:  50 loss:  0.06817842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 440/500 [14:56<02:02,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  439 global step 29474   Batch #:  60 loss:  0.026409237\n",
      "Epoch #:  440 global step 29481   Batch #:  0 loss:  0.035794344\n",
      "Epoch #:  440 global step 29491   Batch #:  10 loss:  0.037387043\n",
      "Epoch #:  440 global step 29501   Batch #:  20 loss:  0.055346724\n",
      "Epoch #:  440 global step 29511   Batch #:  30 loss:  0.12199695\n",
      "Epoch #:  440 global step 29521   Batch #:  40 loss:  0.07513264\n",
      "Epoch #:  440 global step 29531   Batch #:  50 loss:  0.067737445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 441/500 [14:58<02:00,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  440 global step 29541   Batch #:  60 loss:  0.026409272\n",
      "Epoch #:  441 global step 29548   Batch #:  0 loss:  0.032596998\n",
      "Epoch #:  441 global step 29558   Batch #:  10 loss:  0.037432306\n",
      "Epoch #:  441 global step 29568   Batch #:  20 loss:  0.05622429\n",
      "Epoch #:  441 global step 29578   Batch #:  30 loss:  0.12644759\n",
      "Epoch #:  441 global step 29588   Batch #:  40 loss:  0.075823374\n",
      "Epoch #:  441 global step 29598   Batch #:  50 loss:  0.06760804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 442/500 [15:00<01:58,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  441 global step 29608   Batch #:  60 loss:  0.02660634\n",
      "Epoch #:  442 global step 29615   Batch #:  0 loss:  0.03182279\n",
      "Epoch #:  442 global step 29625   Batch #:  10 loss:  0.03941848\n",
      "Epoch #:  442 global step 29635   Batch #:  20 loss:  0.055343058\n",
      "Epoch #:  442 global step 29645   Batch #:  30 loss:  0.12560008\n",
      "Epoch #:  442 global step 29655   Batch #:  40 loss:  0.07478914\n",
      "Epoch #:  442 global step 29665   Batch #:  50 loss:  0.06771463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 89%|████████▊ | 443/500 [15:02<01:56,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  442 global step 29675   Batch #:  60 loss:  0.026311269\n",
      "Epoch #:  443 global step 29682   Batch #:  0 loss:  0.03232898\n",
      "Epoch #:  443 global step 29692   Batch #:  10 loss:  0.03711313\n",
      "Epoch #:  443 global step 29702   Batch #:  20 loss:  0.055819925\n",
      "Epoch #:  443 global step 29712   Batch #:  30 loss:  0.12297753\n",
      "Epoch #:  443 global step 29722   Batch #:  40 loss:  0.07479043\n",
      "Epoch #:  443 global step 29732   Batch #:  50 loss:  0.066890016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 89%|████████▉ | 444/500 [15:04<01:54,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  443 global step 29742   Batch #:  60 loss:  0.026363418\n",
      "Epoch #:  444 global step 29749   Batch #:  0 loss:  0.032026175\n",
      "Epoch #:  444 global step 29759   Batch #:  10 loss:  0.037499104\n",
      "Epoch #:  444 global step 29769   Batch #:  20 loss:  0.05575435\n",
      "Epoch #:  444 global step 29779   Batch #:  30 loss:  0.12078578\n",
      "Epoch #:  444 global step 29789   Batch #:  40 loss:  0.07374443\n",
      "Epoch #:  444 global step 29799   Batch #:  50 loss:  0.06982704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 89%|████████▉ | 445/500 [15:06<01:52,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  444 global step 29809   Batch #:  60 loss:  0.026201969\n",
      "Epoch #:  445 global step 29816   Batch #:  0 loss:  0.042342633\n",
      "Epoch #:  445 global step 29826   Batch #:  10 loss:  0.036651075\n",
      "Epoch #:  445 global step 29836   Batch #:  20 loss:  0.054939784\n",
      "Epoch #:  445 global step 29846   Batch #:  30 loss:  0.12718472\n",
      "Epoch #:  445 global step 29856   Batch #:  40 loss:  0.063876934\n",
      "Epoch #:  445 global step 29866   Batch #:  50 loss:  0.06963074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 89%|████████▉ | 446/500 [15:08<01:49,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  445 global step 29876   Batch #:  60 loss:  0.026673058\n",
      "Epoch #:  446 global step 29883   Batch #:  0 loss:  0.031836778\n",
      "Epoch #:  446 global step 29893   Batch #:  10 loss:  0.03693202\n",
      "Epoch #:  446 global step 29903   Batch #:  20 loss:  0.04861605\n",
      "Epoch #:  446 global step 29913   Batch #:  30 loss:  0.123920105\n",
      "Epoch #:  446 global step 29923   Batch #:  40 loss:  0.06170042\n",
      "Epoch #:  446 global step 29933   Batch #:  50 loss:  0.066103496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 89%|████████▉ | 447/500 [15:10<01:47,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  446 global step 29943   Batch #:  60 loss:  0.032040685\n",
      "Epoch #:  447 global step 29950   Batch #:  0 loss:  0.03211561\n",
      "Epoch #:  447 global step 29960   Batch #:  10 loss:  0.03989825\n",
      "Epoch #:  447 global step 29970   Batch #:  20 loss:  0.04853139\n",
      "Epoch #:  447 global step 29980   Batch #:  30 loss:  0.1256033\n",
      "Epoch #:  447 global step 29990   Batch #:  40 loss:  0.06445042\n",
      "Epoch #:  447 global step 30000   Batch #:  50 loss:  0.06602362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 90%|████████▉ | 448/500 [15:12<01:45,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  447 global step 30010   Batch #:  60 loss:  0.03203738\n",
      "Epoch #:  448 global step 30017   Batch #:  0 loss:  0.029676124\n",
      "Epoch #:  448 global step 30027   Batch #:  10 loss:  0.037962478\n",
      "Epoch #:  448 global step 30037   Batch #:  20 loss:  0.046081167\n",
      "Epoch #:  448 global step 30047   Batch #:  30 loss:  0.1252141\n",
      "Epoch #:  448 global step 30057   Batch #:  40 loss:  0.062270347\n",
      "Epoch #:  448 global step 30067   Batch #:  50 loss:  0.06671057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 90%|████████▉ | 449/500 [15:14<01:43,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  448 global step 30077   Batch #:  60 loss:  0.03213421\n",
      "Epoch #:  449 global step 30084   Batch #:  0 loss:  0.03031386\n",
      "Epoch #:  449 global step 30094   Batch #:  10 loss:  0.036555447\n",
      "Epoch #:  449 global step 30104   Batch #:  20 loss:  0.046088774\n",
      "Epoch #:  449 global step 30114   Batch #:  30 loss:  0.12616737\n",
      "Epoch #:  449 global step 30124   Batch #:  40 loss:  0.062351402\n",
      "Epoch #:  449 global step 30134   Batch #:  50 loss:  0.0687321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 90%|█████████ | 450/500 [15:16<01:41,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  449 global step 30144   Batch #:  60 loss:  0.031915095\n",
      "Epoch #:  450 global step 30151   Batch #:  0 loss:  0.031035893\n",
      "Epoch #:  450 global step 30161   Batch #:  10 loss:  0.037124358\n",
      "Epoch #:  450 global step 30171   Batch #:  20 loss:  0.047927517\n",
      "Epoch #:  450 global step 30181   Batch #:  30 loss:  0.122271396\n",
      "Epoch #:  450 global step 30191   Batch #:  40 loss:  0.06250926\n",
      "Epoch #:  450 global step 30201   Batch #:  50 loss:  0.068255655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 90%|█████████ | 451/500 [15:18<01:39,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  450 global step 30211   Batch #:  60 loss:  0.03209583\n",
      "Epoch #:  451 global step 30218   Batch #:  0 loss:  0.0337504\n",
      "Epoch #:  451 global step 30228   Batch #:  10 loss:  0.037081745\n",
      "Epoch #:  451 global step 30238   Batch #:  20 loss:  0.04791363\n",
      "Epoch #:  451 global step 30248   Batch #:  30 loss:  0.120483845\n",
      "Epoch #:  451 global step 30258   Batch #:  40 loss:  0.06154852\n",
      "Epoch #:  451 global step 30268   Batch #:  50 loss:  0.06858998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 90%|█████████ | 452/500 [15:20<01:37,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  451 global step 30278   Batch #:  60 loss:  0.032063697\n",
      "Epoch #:  452 global step 30285   Batch #:  0 loss:  0.030814972\n",
      "Epoch #:  452 global step 30295   Batch #:  10 loss:  0.036649887\n",
      "Epoch #:  452 global step 30305   Batch #:  20 loss:  0.045695774\n",
      "Epoch #:  452 global step 30315   Batch #:  30 loss:  0.0327363\n",
      "Epoch #:  452 global step 30325   Batch #:  40 loss:  0.06352021\n",
      "Epoch #:  452 global step 30335   Batch #:  50 loss:  0.07424799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 91%|█████████ | 453/500 [15:22<01:35,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  452 global step 30345   Batch #:  60 loss:  0.032174125\n",
      "Epoch #:  453 global step 30352   Batch #:  0 loss:  0.032627176\n",
      "Epoch #:  453 global step 30362   Batch #:  10 loss:  0.037376344\n",
      "Epoch #:  453 global step 30372   Batch #:  20 loss:  0.049668662\n",
      "Epoch #:  453 global step 30382   Batch #:  30 loss:  0.03738353\n",
      "Epoch #:  453 global step 30392   Batch #:  40 loss:  0.060721036\n",
      "Epoch #:  453 global step 30402   Batch #:  50 loss:  0.07323293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 91%|█████████ | 454/500 [15:24<01:33,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  453 global step 30412   Batch #:  60 loss:  0.032309115\n",
      "Epoch #:  454 global step 30419   Batch #:  0 loss:  0.030003386\n",
      "Epoch #:  454 global step 30429   Batch #:  10 loss:  0.037650228\n",
      "Epoch #:  454 global step 30439   Batch #:  20 loss:  0.05176156\n",
      "Epoch #:  454 global step 30449   Batch #:  30 loss:  0.03347744\n",
      "Epoch #:  454 global step 30459   Batch #:  40 loss:  0.061475262\n",
      "Epoch #:  454 global step 30469   Batch #:  50 loss:  0.0735159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 91%|█████████ | 455/500 [15:26<01:31,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  454 global step 30479   Batch #:  60 loss:  0.032069102\n",
      "Epoch #:  455 global step 30486   Batch #:  0 loss:  0.035195667\n",
      "Epoch #:  455 global step 30496   Batch #:  10 loss:  0.03640741\n",
      "Epoch #:  455 global step 30506   Batch #:  20 loss:  0.05218333\n",
      "Epoch #:  455 global step 30516   Batch #:  30 loss:  0.03514364\n",
      "Epoch #:  455 global step 30526   Batch #:  40 loss:  0.062978834\n",
      "Epoch #:  455 global step 30536   Batch #:  50 loss:  0.07375013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 91%|█████████ | 456/500 [15:28<01:29,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  455 global step 30546   Batch #:  60 loss:  0.0321353\n",
      "Epoch #:  456 global step 30553   Batch #:  0 loss:  0.033854578\n",
      "Epoch #:  456 global step 30563   Batch #:  10 loss:  0.04200709\n",
      "Epoch #:  456 global step 30573   Batch #:  20 loss:  0.0550756\n",
      "Epoch #:  456 global step 30583   Batch #:  30 loss:  0.03507886\n",
      "Epoch #:  456 global step 30593   Batch #:  40 loss:  0.06175743\n",
      "Epoch #:  456 global step 30603   Batch #:  50 loss:  0.07225144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 91%|█████████▏| 457/500 [15:30<01:27,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  456 global step 30613   Batch #:  60 loss:  0.032013956\n",
      "Epoch #:  457 global step 30620   Batch #:  0 loss:  0.035773117\n",
      "Epoch #:  457 global step 30630   Batch #:  10 loss:  0.04088411\n",
      "Epoch #:  457 global step 30640   Batch #:  20 loss:  0.052570723\n",
      "Epoch #:  457 global step 30650   Batch #:  30 loss:  0.036213297\n",
      "Epoch #:  457 global step 30660   Batch #:  40 loss:  0.061209004\n",
      "Epoch #:  457 global step 30670   Batch #:  50 loss:  0.07425866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 458/500 [15:32<01:25,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  457 global step 30680   Batch #:  60 loss:  0.03193845\n",
      "Epoch #:  458 global step 30687   Batch #:  0 loss:  0.034147285\n",
      "Epoch #:  458 global step 30697   Batch #:  10 loss:  0.03936565\n",
      "Epoch #:  458 global step 30707   Batch #:  20 loss:  0.052271802\n",
      "Epoch #:  458 global step 30717   Batch #:  30 loss:  0.032856114\n",
      "Epoch #:  458 global step 30727   Batch #:  40 loss:  0.061516497\n",
      "Epoch #:  458 global step 30737   Batch #:  50 loss:  0.07351832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 459/500 [15:34<01:23,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  458 global step 30747   Batch #:  60 loss:  0.032248583\n",
      "Epoch #:  459 global step 30754   Batch #:  0 loss:  0.02934648\n",
      "Epoch #:  459 global step 30764   Batch #:  10 loss:  0.059012588\n",
      "Epoch #:  459 global step 30774   Batch #:  20 loss:  0.11127284\n",
      "Epoch #:  459 global step 30784   Batch #:  30 loss:  0.14018713\n",
      "Epoch #:  459 global step 30794   Batch #:  40 loss:  0.09311602\n",
      "Epoch #:  459 global step 30804   Batch #:  50 loss:  0.0906028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 460/500 [15:36<01:21,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  459 global step 30814   Batch #:  60 loss:  0.057280943\n",
      "Epoch #:  460 global step 30821   Batch #:  0 loss:  0.08147355\n",
      "Epoch #:  460 global step 30831   Batch #:  10 loss:  0.04387122\n",
      "Epoch #:  460 global step 30841   Batch #:  20 loss:  0.17977393\n",
      "Epoch #:  460 global step 30851   Batch #:  30 loss:  0.13699313\n",
      "Epoch #:  460 global step 30861   Batch #:  40 loss:  0.077948555\n",
      "Epoch #:  460 global step 30871   Batch #:  50 loss:  0.08932594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 461/500 [15:38<01:19,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  460 global step 30881   Batch #:  60 loss:  0.056093074\n",
      "Epoch #:  461 global step 30888   Batch #:  0 loss:  0.05140491\n",
      "Epoch #:  461 global step 30898   Batch #:  10 loss:  0.099379614\n",
      "Epoch #:  461 global step 30908   Batch #:  20 loss:  0.12216656\n",
      "Epoch #:  461 global step 30918   Batch #:  30 loss:  0.058699343\n",
      "Epoch #:  461 global step 30928   Batch #:  40 loss:  0.16348769\n",
      "Epoch #:  461 global step 30938   Batch #:  50 loss:  0.15399082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 462/500 [15:40<01:17,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  461 global step 30948   Batch #:  60 loss:  0.04325764\n",
      "Epoch #:  462 global step 30955   Batch #:  0 loss:  0.132882\n",
      "Epoch #:  462 global step 30965   Batch #:  10 loss:  0.08227516\n",
      "Epoch #:  462 global step 30975   Batch #:  20 loss:  0.066042334\n",
      "Epoch #:  462 global step 30985   Batch #:  30 loss:  0.069741935\n",
      "Epoch #:  462 global step 30995   Batch #:  40 loss:  0.097446226\n",
      "Epoch #:  462 global step 31005   Batch #:  50 loss:  0.11819295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 93%|█████████▎| 463/500 [15:42<01:15,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  462 global step 31015   Batch #:  60 loss:  0.047441695\n",
      "Epoch #:  463 global step 31022   Batch #:  0 loss:  0.072313644\n",
      "Epoch #:  463 global step 31032   Batch #:  10 loss:  0.068494484\n",
      "Epoch #:  463 global step 31042   Batch #:  20 loss:  0.066655435\n",
      "Epoch #:  463 global step 31052   Batch #:  30 loss:  0.6121538\n",
      "Epoch #:  463 global step 31062   Batch #:  40 loss:  0.07165685\n",
      "Epoch #:  463 global step 31072   Batch #:  50 loss:  0.11989798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 93%|█████████▎| 464/500 [15:44<01:13,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  463 global step 31082   Batch #:  60 loss:  0.12553577\n",
      "Epoch #:  464 global step 31089   Batch #:  0 loss:  0.05743639\n",
      "Epoch #:  464 global step 31099   Batch #:  10 loss:  0.03456941\n",
      "Epoch #:  464 global step 31109   Batch #:  20 loss:  0.093324445\n",
      "Epoch #:  464 global step 31119   Batch #:  30 loss:  0.0605633\n",
      "Epoch #:  464 global step 31129   Batch #:  40 loss:  0.066463396\n",
      "Epoch #:  464 global step 31139   Batch #:  50 loss:  0.06973269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 93%|█████████▎| 465/500 [15:46<01:11,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  464 global step 31149   Batch #:  60 loss:  0.12582953\n",
      "Epoch #:  465 global step 31156   Batch #:  0 loss:  0.06551932\n",
      "Epoch #:  465 global step 31166   Batch #:  10 loss:  0.03538124\n",
      "Epoch #:  465 global step 31176   Batch #:  20 loss:  0.07489686\n",
      "Epoch #:  465 global step 31186   Batch #:  30 loss:  0.058741905\n",
      "Epoch #:  465 global step 31196   Batch #:  40 loss:  0.07390297\n",
      "Epoch #:  465 global step 31206   Batch #:  50 loss:  0.07373751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 93%|█████████▎| 466/500 [15:48<01:09,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  465 global step 31216   Batch #:  60 loss:  0.123144865\n",
      "Epoch #:  466 global step 31223   Batch #:  0 loss:  0.063227825\n",
      "Epoch #:  466 global step 31233   Batch #:  10 loss:  0.04084111\n",
      "Epoch #:  466 global step 31243   Batch #:  20 loss:  0.040564395\n",
      "Epoch #:  466 global step 31253   Batch #:  30 loss:  0.056621265\n",
      "Epoch #:  466 global step 31263   Batch #:  40 loss:  0.07006481\n",
      "Epoch #:  466 global step 31273   Batch #:  50 loss:  0.07008662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 93%|█████████▎| 467/500 [15:50<01:07,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  466 global step 31283   Batch #:  60 loss:  0.12702511\n",
      "Epoch #:  467 global step 31290   Batch #:  0 loss:  0.06569214\n",
      "Epoch #:  467 global step 31300   Batch #:  10 loss:  0.041028816\n",
      "Epoch #:  467 global step 31310   Batch #:  20 loss:  0.051895782\n",
      "Epoch #:  467 global step 31320   Batch #:  30 loss:  0.056995813\n",
      "Epoch #:  467 global step 31330   Batch #:  40 loss:  0.068470694\n",
      "Epoch #:  467 global step 31340   Batch #:  50 loss:  0.071369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 94%|█████████▎| 468/500 [15:53<01:05,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  467 global step 31350   Batch #:  60 loss:  0.12002435\n",
      "Epoch #:  468 global step 31357   Batch #:  0 loss:  0.04763467\n",
      "Epoch #:  468 global step 31367   Batch #:  10 loss:  0.04213694\n",
      "Epoch #:  468 global step 31377   Batch #:  20 loss:  0.039827924\n",
      "Epoch #:  468 global step 31387   Batch #:  30 loss:  0.051638808\n",
      "Epoch #:  468 global step 31397   Batch #:  40 loss:  0.06479852\n",
      "Epoch #:  468 global step 31407   Batch #:  50 loss:  0.07225005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 94%|█████████▍| 469/500 [15:55<01:03,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  468 global step 31417   Batch #:  60 loss:  0.11844304\n",
      "Epoch #:  469 global step 31424   Batch #:  0 loss:  0.043577857\n",
      "Epoch #:  469 global step 31434   Batch #:  10 loss:  0.039595034\n",
      "Epoch #:  469 global step 31444   Batch #:  20 loss:  0.039490327\n",
      "Epoch #:  469 global step 31454   Batch #:  30 loss:  0.056069497\n",
      "Epoch #:  469 global step 31464   Batch #:  40 loss:  0.068172395\n",
      "Epoch #:  469 global step 31474   Batch #:  50 loss:  0.06352501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 94%|█████████▍| 470/500 [15:57<01:01,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  469 global step 31484   Batch #:  60 loss:  0.120000824\n",
      "Epoch #:  470 global step 31491   Batch #:  0 loss:  0.056672603\n",
      "Epoch #:  470 global step 31501   Batch #:  10 loss:  0.035521567\n",
      "Epoch #:  470 global step 31511   Batch #:  20 loss:  0.04536435\n",
      "Epoch #:  470 global step 31521   Batch #:  30 loss:  0.058240615\n",
      "Epoch #:  470 global step 31531   Batch #:  40 loss:  0.06535651\n",
      "Epoch #:  470 global step 31541   Batch #:  50 loss:  0.0770612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 94%|█████████▍| 471/500 [15:59<00:59,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  470 global step 31551   Batch #:  60 loss:  0.118531935\n",
      "Epoch #:  471 global step 31558   Batch #:  0 loss:  0.050901696\n",
      "Epoch #:  471 global step 31568   Batch #:  10 loss:  0.034654234\n",
      "Epoch #:  471 global step 31578   Batch #:  20 loss:  0.03847651\n",
      "Epoch #:  471 global step 31588   Batch #:  30 loss:  0.05215529\n",
      "Epoch #:  471 global step 31598   Batch #:  40 loss:  0.06304423\n",
      "Epoch #:  471 global step 31608   Batch #:  50 loss:  0.082858264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 94%|█████████▍| 472/500 [16:01<00:57,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  471 global step 31618   Batch #:  60 loss:  0.12160708\n",
      "Epoch #:  472 global step 31625   Batch #:  0 loss:  0.04992739\n",
      "Epoch #:  472 global step 31635   Batch #:  10 loss:  0.033824325\n",
      "Epoch #:  472 global step 31645   Batch #:  20 loss:  0.038282838\n",
      "Epoch #:  472 global step 31655   Batch #:  30 loss:  0.04346599\n",
      "Epoch #:  472 global step 31665   Batch #:  40 loss:  0.06270872\n",
      "Epoch #:  472 global step 31675   Batch #:  50 loss:  0.06129372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 95%|█████████▍| 473/500 [16:03<00:54,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  472 global step 31685   Batch #:  60 loss:  0.021014826\n",
      "Epoch #:  473 global step 31692   Batch #:  0 loss:  0.046635617\n",
      "Epoch #:  473 global step 31702   Batch #:  10 loss:  0.033168424\n",
      "Epoch #:  473 global step 31712   Batch #:  20 loss:  0.037210472\n",
      "Epoch #:  473 global step 31722   Batch #:  30 loss:  0.03921867\n",
      "Epoch #:  473 global step 31732   Batch #:  40 loss:  0.06229175\n",
      "Epoch #:  473 global step 31742   Batch #:  50 loss:  0.06671325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 95%|█████████▍| 474/500 [16:05<00:52,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  473 global step 31752   Batch #:  60 loss:  0.02845414\n",
      "Epoch #:  474 global step 31759   Batch #:  0 loss:  0.050452124\n",
      "Epoch #:  474 global step 31769   Batch #:  10 loss:  0.034217637\n",
      "Epoch #:  474 global step 31779   Batch #:  20 loss:  0.036494453\n",
      "Epoch #:  474 global step 31789   Batch #:  30 loss:  0.042086884\n",
      "Epoch #:  474 global step 31799   Batch #:  40 loss:  0.061914396\n",
      "Epoch #:  474 global step 31809   Batch #:  50 loss:  0.06510254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 95%|█████████▌| 475/500 [16:07<00:50,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  474 global step 31819   Batch #:  60 loss:  0.02684698\n",
      "Epoch #:  475 global step 31826   Batch #:  0 loss:  0.051686343\n",
      "Epoch #:  475 global step 31836   Batch #:  10 loss:  0.03631224\n",
      "Epoch #:  475 global step 31846   Batch #:  20 loss:  0.036494747\n",
      "Epoch #:  475 global step 31856   Batch #:  30 loss:  0.04048298\n",
      "Epoch #:  475 global step 31866   Batch #:  40 loss:  0.06291574\n",
      "Epoch #:  475 global step 31876   Batch #:  50 loss:  0.06423414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 95%|█████████▌| 476/500 [16:09<00:48,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  475 global step 31886   Batch #:  60 loss:  0.020035576\n",
      "Epoch #:  476 global step 31893   Batch #:  0 loss:  0.04508155\n",
      "Epoch #:  476 global step 31903   Batch #:  10 loss:  0.030964212\n",
      "Epoch #:  476 global step 31913   Batch #:  20 loss:  0.071597695\n",
      "Epoch #:  476 global step 31923   Batch #:  30 loss:  0.045913544\n",
      "Epoch #:  476 global step 31933   Batch #:  40 loss:  0.0690022\n",
      "Epoch #:  476 global step 31943   Batch #:  50 loss:  0.0698794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 95%|█████████▌| 477/500 [16:11<00:46,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  476 global step 31953   Batch #:  60 loss:  0.02653058\n",
      "Epoch #:  477 global step 31960   Batch #:  0 loss:  0.049673002\n",
      "Epoch #:  477 global step 31970   Batch #:  10 loss:  0.030680064\n",
      "Epoch #:  477 global step 31980   Batch #:  20 loss:  0.036404222\n",
      "Epoch #:  477 global step 31990   Batch #:  30 loss:  0.043194618\n",
      "Epoch #:  477 global step 32000   Batch #:  40 loss:  0.065864384\n",
      "Epoch #:  477 global step 32010   Batch #:  50 loss:  0.06964573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 96%|█████████▌| 478/500 [16:13<00:44,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  477 global step 32020   Batch #:  60 loss:  0.030594097\n",
      "Epoch #:  478 global step 32027   Batch #:  0 loss:  0.049531214\n",
      "Epoch #:  478 global step 32037   Batch #:  10 loss:  0.037405953\n",
      "Epoch #:  478 global step 32047   Batch #:  20 loss:  0.04229502\n",
      "Epoch #:  478 global step 32057   Batch #:  30 loss:  0.043860063\n",
      "Epoch #:  478 global step 32067   Batch #:  40 loss:  0.06495423\n",
      "Epoch #:  478 global step 32077   Batch #:  50 loss:  0.06942622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 96%|█████████▌| 479/500 [16:15<00:42,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  478 global step 32087   Batch #:  60 loss:  0.025068771\n",
      "Epoch #:  479 global step 32094   Batch #:  0 loss:  0.049837846\n",
      "Epoch #:  479 global step 32104   Batch #:  10 loss:  0.038233124\n",
      "Epoch #:  479 global step 32114   Batch #:  20 loss:  0.042465728\n",
      "Epoch #:  479 global step 32124   Batch #:  30 loss:  0.048410673\n",
      "Epoch #:  479 global step 32134   Batch #:  40 loss:  0.06546383\n",
      "Epoch #:  479 global step 32144   Batch #:  50 loss:  0.082587115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 96%|█████████▌| 480/500 [16:17<00:40,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  479 global step 32154   Batch #:  60 loss:  0.025296682\n",
      "Epoch #:  480 global step 32161   Batch #:  0 loss:  0.049053356\n",
      "Epoch #:  480 global step 32171   Batch #:  10 loss:  0.037479628\n",
      "Epoch #:  480 global step 32181   Batch #:  20 loss:  0.045431163\n",
      "Epoch #:  480 global step 32191   Batch #:  30 loss:  0.049770854\n",
      "Epoch #:  480 global step 32201   Batch #:  40 loss:  0.06893538\n",
      "Epoch #:  480 global step 32211   Batch #:  50 loss:  0.08776743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 96%|█████████▌| 481/500 [16:19<00:38,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  480 global step 32221   Batch #:  60 loss:  0.025108902\n",
      "Epoch #:  481 global step 32228   Batch #:  0 loss:  0.048589412\n",
      "Epoch #:  481 global step 32238   Batch #:  10 loss:  0.047977448\n",
      "Epoch #:  481 global step 32248   Batch #:  20 loss:  0.0422151\n",
      "Epoch #:  481 global step 32258   Batch #:  30 loss:  0.054086436\n",
      "Epoch #:  481 global step 32268   Batch #:  40 loss:  0.0696704\n",
      "Epoch #:  481 global step 32278   Batch #:  50 loss:  0.08636509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 96%|█████████▋| 482/500 [16:21<00:36,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  481 global step 32288   Batch #:  60 loss:  0.024853654\n",
      "Epoch #:  482 global step 32295   Batch #:  0 loss:  0.049004577\n",
      "Epoch #:  482 global step 32305   Batch #:  10 loss:  0.05332798\n",
      "Epoch #:  482 global step 32315   Batch #:  20 loss:  0.042638645\n",
      "Epoch #:  482 global step 32325   Batch #:  30 loss:  0.050644856\n",
      "Epoch #:  482 global step 32335   Batch #:  40 loss:  0.06949585\n",
      "Epoch #:  482 global step 32345   Batch #:  50 loss:  0.06767341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 97%|█████████▋| 483/500 [16:23<00:34,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  482 global step 32355   Batch #:  60 loss:  0.024006426\n",
      "Epoch #:  483 global step 32362   Batch #:  0 loss:  0.04874128\n",
      "Epoch #:  483 global step 32372   Batch #:  10 loss:  0.045377485\n",
      "Epoch #:  483 global step 32382   Batch #:  20 loss:  0.04317043\n",
      "Epoch #:  483 global step 32392   Batch #:  30 loss:  0.049318954\n",
      "Epoch #:  483 global step 32402   Batch #:  40 loss:  0.069309555\n",
      "Epoch #:  483 global step 32412   Batch #:  50 loss:  0.06767208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 97%|█████████▋| 484/500 [16:25<00:32,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  483 global step 32422   Batch #:  60 loss:  0.02344348\n",
      "Epoch #:  484 global step 32429   Batch #:  0 loss:  0.0474689\n",
      "Epoch #:  484 global step 32439   Batch #:  10 loss:  0.050850343\n",
      "Epoch #:  484 global step 32449   Batch #:  20 loss:  0.04172113\n",
      "Epoch #:  484 global step 32459   Batch #:  30 loss:  0.059097186\n",
      "Epoch #:  484 global step 32469   Batch #:  40 loss:  0.06943627\n",
      "Epoch #:  484 global step 32479   Batch #:  50 loss:  0.067527264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 97%|█████████▋| 485/500 [16:27<00:30,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  484 global step 32489   Batch #:  60 loss:  0.023316426\n",
      "Epoch #:  485 global step 32496   Batch #:  0 loss:  0.0471995\n",
      "Epoch #:  485 global step 32506   Batch #:  10 loss:  0.045469366\n",
      "Epoch #:  485 global step 32516   Batch #:  20 loss:  0.041548006\n",
      "Epoch #:  485 global step 32526   Batch #:  30 loss:  0.055548348\n",
      "Epoch #:  485 global step 32536   Batch #:  40 loss:  0.069365256\n",
      "Epoch #:  485 global step 32546   Batch #:  50 loss:  0.06936692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 97%|█████████▋| 486/500 [16:29<00:28,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  485 global step 32556   Batch #:  60 loss:  0.023076018\n",
      "Epoch #:  486 global step 32563   Batch #:  0 loss:  0.047781102\n",
      "Epoch #:  486 global step 32573   Batch #:  10 loss:  0.053119227\n",
      "Epoch #:  486 global step 32583   Batch #:  20 loss:  0.042082097\n",
      "Epoch #:  486 global step 32593   Batch #:  30 loss:  0.057966214\n",
      "Epoch #:  486 global step 32603   Batch #:  40 loss:  0.06619992\n",
      "Epoch #:  486 global step 32613   Batch #:  50 loss:  0.06830156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 97%|█████████▋| 487/500 [16:31<00:26,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  486 global step 32623   Batch #:  60 loss:  0.022842461\n",
      "Epoch #:  487 global step 32630   Batch #:  0 loss:  0.04732375\n",
      "Epoch #:  487 global step 32640   Batch #:  10 loss:  0.045004286\n",
      "Epoch #:  487 global step 32650   Batch #:  20 loss:  0.04326873\n",
      "Epoch #:  487 global step 32660   Batch #:  30 loss:  0.054953694\n",
      "Epoch #:  487 global step 32670   Batch #:  40 loss:  0.06901398\n",
      "Epoch #:  487 global step 32680   Batch #:  50 loss:  0.088138066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 98%|█████████▊| 488/500 [16:33<00:24,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  487 global step 32690   Batch #:  60 loss:  0.02225343\n",
      "Epoch #:  488 global step 32697   Batch #:  0 loss:  0.047112547\n",
      "Epoch #:  488 global step 32707   Batch #:  10 loss:  0.046870496\n",
      "Epoch #:  488 global step 32717   Batch #:  20 loss:  0.041918088\n",
      "Epoch #:  488 global step 32727   Batch #:  30 loss:  0.04403698\n",
      "Epoch #:  488 global step 32737   Batch #:  40 loss:  0.07306264\n",
      "Epoch #:  488 global step 32747   Batch #:  50 loss:  0.06543093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 98%|█████████▊| 489/500 [16:35<00:22,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  488 global step 32757   Batch #:  60 loss:  0.01605041\n",
      "Epoch #:  489 global step 32764   Batch #:  0 loss:  0.03717704\n",
      "Epoch #:  489 global step 32774   Batch #:  10 loss:  0.025691377\n",
      "Epoch #:  489 global step 32784   Batch #:  20 loss:  0.03718541\n",
      "Epoch #:  489 global step 32794   Batch #:  30 loss:  0.03672877\n",
      "Epoch #:  489 global step 32804   Batch #:  40 loss:  0.050688155\n",
      "Epoch #:  489 global step 32814   Batch #:  50 loss:  0.06522672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 98%|█████████▊| 490/500 [16:37<00:20,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  489 global step 32824   Batch #:  60 loss:  0.031450037\n",
      "Epoch #:  490 global step 32831   Batch #:  0 loss:  0.045743138\n",
      "Epoch #:  490 global step 32841   Batch #:  10 loss:  0.032549087\n",
      "Epoch #:  490 global step 32851   Batch #:  20 loss:  0.042847116\n",
      "Epoch #:  490 global step 32861   Batch #:  30 loss:  0.031262793\n",
      "Epoch #:  490 global step 32871   Batch #:  40 loss:  0.055797283\n",
      "Epoch #:  490 global step 32881   Batch #:  50 loss:  0.061978526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 98%|█████████▊| 491/500 [16:39<00:18,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  490 global step 32891   Batch #:  60 loss:  0.02127987\n",
      "Epoch #:  491 global step 32898   Batch #:  0 loss:  0.045926545\n",
      "Epoch #:  491 global step 32908   Batch #:  10 loss:  0.042270917\n",
      "Epoch #:  491 global step 32918   Batch #:  20 loss:  0.040906295\n",
      "Epoch #:  491 global step 32928   Batch #:  30 loss:  0.048694707\n",
      "Epoch #:  491 global step 32938   Batch #:  40 loss:  0.06719082\n",
      "Epoch #:  491 global step 32948   Batch #:  50 loss:  0.06778554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 98%|█████████▊| 492/500 [16:41<00:16,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  491 global step 32958   Batch #:  60 loss:  0.023128375\n",
      "Epoch #:  492 global step 32965   Batch #:  0 loss:  0.049005385\n",
      "Epoch #:  492 global step 32975   Batch #:  10 loss:  0.056418948\n",
      "Epoch #:  492 global step 32985   Batch #:  20 loss:  0.042669058\n",
      "Epoch #:  492 global step 32995   Batch #:  30 loss:  0.04177537\n",
      "Epoch #:  492 global step 33005   Batch #:  40 loss:  0.061536413\n",
      "Epoch #:  492 global step 33015   Batch #:  50 loss:  0.06186506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 99%|█████████▊| 493/500 [16:43<00:14,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  492 global step 33025   Batch #:  60 loss:  0.023169942\n",
      "Epoch #:  493 global step 33032   Batch #:  0 loss:  0.04247914\n",
      "Epoch #:  493 global step 33042   Batch #:  10 loss:  0.032853063\n",
      "Epoch #:  493 global step 33052   Batch #:  20 loss:  0.04056641\n",
      "Epoch #:  493 global step 33062   Batch #:  30 loss:  0.045051597\n",
      "Epoch #:  493 global step 33072   Batch #:  40 loss:  0.061732564\n",
      "Epoch #:  493 global step 33082   Batch #:  50 loss:  0.063188516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 99%|█████████▉| 494/500 [16:45<00:12,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  493 global step 33092   Batch #:  60 loss:  0.020808417\n",
      "Epoch #:  494 global step 33099   Batch #:  0 loss:  0.041402243\n",
      "Epoch #:  494 global step 33109   Batch #:  10 loss:  0.04199578\n",
      "Epoch #:  494 global step 33119   Batch #:  20 loss:  0.04009006\n",
      "Epoch #:  494 global step 33129   Batch #:  30 loss:  0.043907974\n",
      "Epoch #:  494 global step 33139   Batch #:  40 loss:  0.061952412\n",
      "Epoch #:  494 global step 33149   Batch #:  50 loss:  0.0613675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 99%|█████████▉| 495/500 [16:47<00:10,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  494 global step 33159   Batch #:  60 loss:  0.01684849\n",
      "Epoch #:  495 global step 33166   Batch #:  0 loss:  0.045548968\n",
      "Epoch #:  495 global step 33176   Batch #:  10 loss:  0.056833602\n",
      "Epoch #:  495 global step 33186   Batch #:  20 loss:  0.039637003\n",
      "Epoch #:  495 global step 33196   Batch #:  30 loss:  0.047873434\n",
      "Epoch #:  495 global step 33206   Batch #:  40 loss:  0.0650345\n",
      "Epoch #:  495 global step 33216   Batch #:  50 loss:  0.075446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 99%|█████████▉| 496/500 [16:49<00:08,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  495 global step 33226   Batch #:  60 loss:  0.016572116\n",
      "Epoch #:  496 global step 33233   Batch #:  0 loss:  0.04818808\n",
      "Epoch #:  496 global step 33243   Batch #:  10 loss:  0.0607616\n",
      "Epoch #:  496 global step 33253   Batch #:  20 loss:  0.041804377\n",
      "Epoch #:  496 global step 33263   Batch #:  30 loss:  0.052794337\n",
      "Epoch #:  496 global step 33273   Batch #:  40 loss:  0.0668153\n",
      "Epoch #:  496 global step 33283   Batch #:  50 loss:  0.07485932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 99%|█████████▉| 497/500 [16:52<00:06,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  496 global step 33293   Batch #:  60 loss:  0.01648308\n",
      "Epoch #:  497 global step 33300   Batch #:  0 loss:  0.04835625\n",
      "Epoch #:  497 global step 33310   Batch #:  10 loss:  0.05280124\n",
      "Epoch #:  497 global step 33320   Batch #:  20 loss:  0.039411124\n",
      "Epoch #:  497 global step 33330   Batch #:  30 loss:  0.048379336\n",
      "Epoch #:  497 global step 33340   Batch #:  40 loss:  0.067058444\n",
      "Epoch #:  497 global step 33350   Batch #:  50 loss:  0.07447727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|█████████▉| 498/500 [16:54<00:04,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  497 global step 33360   Batch #:  60 loss:  0.016320357\n",
      "Epoch #:  498 global step 33367   Batch #:  0 loss:  0.04622831\n",
      "Epoch #:  498 global step 33377   Batch #:  10 loss:  0.05588819\n",
      "Epoch #:  498 global step 33387   Batch #:  20 loss:  0.04219137\n",
      "Epoch #:  498 global step 33397   Batch #:  30 loss:  0.04884086\n",
      "Epoch #:  498 global step 33407   Batch #:  40 loss:  0.06514139\n",
      "Epoch #:  498 global step 33417   Batch #:  50 loss:  0.07489022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|█████████▉| 499/500 [16:56<00:02,  2.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  498 global step 33427   Batch #:  60 loss:  0.016277159\n",
      "Epoch #:  499 global step 33434   Batch #:  0 loss:  0.046856638\n",
      "Epoch #:  499 global step 33444   Batch #:  10 loss:  0.051102415\n",
      "Epoch #:  499 global step 33454   Batch #:  20 loss:  0.041720465\n",
      "Epoch #:  499 global step 33464   Batch #:  30 loss:  0.04880312\n",
      "Epoch #:  499 global step 33474   Batch #:  40 loss:  0.06710541\n",
      "Epoch #:  499 global step 33484   Batch #:  50 loss:  0.07501257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|██████████| 500/500 [16:58<00:00,  2.04s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  499 global step 33494   Batch #:  60 loss:  0.016197084\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "saver, sess, global_step = tpl.train(train_X, train_ids, test_X, test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_loc = tpl.save_model(saver, sess, global_step)\n",
    "# print(\"model saved ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [n.name for n in sess.graph_def.node]\n",
    "\n",
    "graph = sess.graph\n",
    "x = graph.get_tensor_by_name('placehold_x:0')\n",
    "oper_restore = graph.get_tensor_by_name('inference:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "embdedding_dim=10\n",
    "embed_train = np.empty((0,embdedding_dim))\n",
    "embed_test = np.empty((0,embdedding_dim))\n",
    "\n",
    "batch_size=256\n",
    "\n",
    "def convert_(data,batch_size,sess,oper_restore,x,embdedding_dim):\n",
    "#     embdedding_dim=128\n",
    "    embed_train = np.empty((0,embdedding_dim))\n",
    "    for idx in range(0,len(data),batch_size):\n",
    "        batch_id = range(idx,(min(idx+batch_size,len(data))))\n",
    "        number = data[batch_id]\n",
    "        prediction = sess.run(oper_restore, feed_dict={x: number})\n",
    "        embed_train = np.r_[embed_train,prediction]\n",
    "    return embed_train\n",
    "\n",
    "train_embeding = convert_(train_X,batch_size,sess,oper_restore,x,embdedding_dim)\n",
    "test_emdesing = convert_(test_X,batch_size,sess,oper_restore,x,embdedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1932, 10)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_emdesing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate the low dimensional embedding from the saved model and save with class id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train a mlp / svm to judge the video-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17383/17383 [==============================] - 6s 350us/step - loss: 1.8026 - acc: 0.2952\n",
      "Epoch 2/10\n",
      "17383/17383 [==============================] - 4s 221us/step - loss: 1.7341 - acc: 0.3147\n",
      "Epoch 3/10\n",
      "17383/17383 [==============================] - 4s 225us/step - loss: 1.7278 - acc: 0.3136\n",
      "Epoch 4/10\n",
      "17383/17383 [==============================] - 4s 222us/step - loss: 1.7210 - acc: 0.3166\n",
      "Epoch 5/10\n",
      "17383/17383 [==============================] - 4s 222us/step - loss: 1.7151 - acc: 0.3214\n",
      "Epoch 6/10\n",
      "17383/17383 [==============================] - 4s 225us/step - loss: 1.7104 - acc: 0.3213\n",
      "Epoch 7/10\n",
      "17383/17383 [==============================] - 4s 225us/step - loss: 1.7100 - acc: 0.3239\n",
      "Epoch 8/10\n",
      "17383/17383 [==============================] - 4s 223us/step - loss: 1.7028 - acc: 0.3273\n",
      "Epoch 9/10\n",
      "17383/17383 [==============================] - 4s 224us/step - loss: 1.6984 - acc: 0.3271\n",
      "Epoch 10/10\n",
      "17383/17383 [==============================] - 4s 225us/step - loss: 1.7028 - acc: 0.3233\n",
      "1932/1932 [==============================] - 1s 324us/step\n",
      "[INFO] your final reported test accuracy score is 33.44% on 1932 samples having 7 classes \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f1bd5b184a8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.train_and_report(train_embeding, train_ids,test_emdesing,test_ids,algo_name='mlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. read the video\n",
    "2. get the c3d encoding\n",
    "3. PCA with train settings\n",
    "5. pass through the siamese model to get the embedding\n",
    "6. pass through the video classification model to get the class id\n",
    "7. Load encodings for all videos corresponding the judged class id\n",
    "8. Calculate distance between the query video encodings and judged video encodings\n",
    "9. take top video-id for each ecoding\n",
    "10. whichever video id repeats most becomes the recommended video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_video_embdedding = None\n",
    "indexed_video_embdedding = None\n",
    "indexed_video_id = None\n",
    "\n",
    "assert len(indexed_video_embdedding)== len(indexed_video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = query_video_embdedding.dot(indexed_video_embdedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_least = 1\n",
    "sorted_idx = np.argsort(distance,axis=1)[:,:n_least]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_to_id = np.apply_along_axis(lambda vid_id : indexed_video_id[vid_id] , 1, sorted_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_recommendation=1\n",
    "from scipy.stats import itemfreq\n",
    "recommended_vid_id = itemfreq(clip_to_id)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
